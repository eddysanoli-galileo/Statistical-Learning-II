{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Clase 9 - Backpropagation\r\n",
    "\r\n",
    "## Ejercicio 1\r\n",
    "\r\n",
    "Dado el siguiente diagrama y asumiendo que las neuronas de salida tienen errores de 3 y 10 respectivamente, calcule el término de error (delta minúscula) simplificado para cada una de las neuronas del diagrama.\r\n",
    "\r\n",
    "![error_simplificado](Imagenes/back-propagation-1.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Capa 2**\r\n",
    "\r\n",
    "- Delta Neurona 1: 3*(-0.23) + 10*(0.9) = 8.31\r\n",
    "- Delta Neurona 2: 3*(0.22) + 10*(0.88) = 9.46\r\n",
    "- Delta Neurona 3: 3*(0.77) + 10*(-0.4) = -1.69\r\n",
    "\r\n",
    "**Capa 1**\r\n",
    "\r\n",
    "- Delta Neurona 1: 8.31*(-0.3) + 9.46*(0.45) - 1.69*(0.69) = 0.5979\r\n",
    "- Delta Neurona 2: 8.31*(0.62) + 9.46*(0.57) - 1.69*(0.58) = 9.5642\r\n",
    "- Delta Neurona 3: 8.31*(0.45) + 9.46*(0.48) - 1.69*(-0.45) = 9.0408\r\n",
    "\r\n",
    "**Capa 0 (Entradas)** \r\n",
    "\r\n",
    "- Delta Neurona 1: 0.5979*(0.3) + 9.5642*(0.22) + 9.0408*(0.65) = 8.16\r\n",
    "- Delta Neurona 2: 0.5979*(0.46) + 9.5642*(-0.7) + 9.0408*(0.9) = 1.7168\r\n",
    "- Delta Neurona 3: 0.5979*(0.02) + 9.5642*(0.65) + 9.0408*(0.34) = 9.3026\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ejercicio 2: Entrenamiento Completo de XOR con NN\r\n",
    "\r\n",
    "Previamente se había diseñado la fase de forward propagation de una compuerta XOR. Ahora se realiza el proceso completo de entrenamiento de una red encargada de aproximar la función XOR. Dicho aproximador debe contar con dos capas intermedias: La primera con al menos 2 neuronas y la segunda siempre con 2 neuronas. Para ambas emplear la función de activación ReLu. No acoplar ningún tipo de función de activación en la salida. Para esto se debe utilizar Numpy únicamente.\r\n",
    "\r\n",
    "<center>\r\n",
    "    <img src=\"Imagenes/XOR_nn_backprop.PNG\" alt=\"XOR_nn\" width=\"600px\" alignment=\"center\">\r\n",
    "</center>\r\n",
    "\r\n",
    "En total se deben realizar 5 experimentos. En cada experimento:\r\n",
    "\r\n",
    "- Inicializar los parámetros aleatoriamente con distribución normal centrada en 0 y desviación estándar de 0.1.\r\n",
    "- Retornar la representación intermedia de la segunda capa oculta.\r\n",
    "\r\n",
    "Graficar las 5 representaciones intermedias, comparar, comentar y/o concluir."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "class NeuralNetXOR():\r\n",
    "\r\n",
    "    # Método: Ejecutado al crear una instancia de la clase\r\n",
    "    def __init__(self, first_hiddenLayer_neurons = 2) -> None:\r\n",
    "\r\n",
    "        # Se inicializan los pesos y biases con valores normalmente distribuidos\r\n",
    "        # centrados en 0 y con una desviación estándar de 0.1.\r\n",
    "\r\n",
    "        # ----------\r\n",
    "        # CAPA 1\r\n",
    "        # ----------\r\n",
    "\r\n",
    "        # Dims X: (Nx2)\r\n",
    "        # Dims Wc1: (2x3) o (2 Entradas x 3 Neuronas en Primera Capa Intermedia)\r\n",
    "        # NOTA: El número de neuronas en la primera capa intermedia puede variar\r\n",
    "        self.Wc1 = np.random.normal(loc=0, scale=0.1, size=(2, first_hiddenLayer_neurons))\r\n",
    "\r\n",
    "        # Bias de capa 1\r\n",
    "        self.Bc1 = np.random.normal(loc=0, scale=0.1, size=(1, first_hiddenLayer_neurons))\r\n",
    "\r\n",
    "        # ----------\r\n",
    "        # CAPA 2\r\n",
    "        # ----------\r\n",
    "\r\n",
    "        # Dims Wc2: (3x2) o (3 Neuronas en Primera Capa Intermedia x 2 Neuronas en Segunda Capa Intermedia)\r\n",
    "        # NOTA: El número de neuronas en la primera capa intermedia puede variar\r\n",
    "        self.Wc2 = np.random.normal(loc=0, scale=0.1, size=(first_hiddenLayer_neurons, 2))\r\n",
    "\r\n",
    "        # Bias de capa 2\r\n",
    "        self.Bc2 = np.random.normal(loc=0, scale=0.1, size=(1, 2))\r\n",
    "\r\n",
    "        # ----------\r\n",
    "        # CAPA 3\r\n",
    "        # ----------\r\n",
    "\r\n",
    "        # Dims Wc3: (2x1) o (2 Neuronas en Segunda Capa Intermedia x 1 Neurona de Salida)\r\n",
    "        self.Wc3 = np.random.normal(loc=0, scale=0.1, size=(2, 1))\r\n",
    "\r\n",
    "        # Bias de capa 3\r\n",
    "        self.Bc3 = np.random.normal(loc=0, scale=0.1, size=(1, 1))\r\n",
    "\r\n",
    "        # ----------\r\n",
    "        # LOGITS\r\n",
    "        # ----------\r\n",
    "\r\n",
    "        # Salidas de neurona antes de pasar por la función de activación\r\n",
    "        self.Z1 = 0\r\n",
    "        self.Z2 = 0\r\n",
    "        self.Z3 = 0\r\n",
    "\r\n",
    "        # ----------\r\n",
    "        # ACTIVACIONES\r\n",
    "        # ----------\r\n",
    "\r\n",
    "        # Salidas de neurona luego de pasar por la función de activación\r\n",
    "        self.A1 = 0\r\n",
    "        self.A2 = 0\r\n",
    "\r\n",
    "    # Método: Forward Propagation de la Red\r\n",
    "    def forwardProp(self, X):\r\n",
    "        \r\n",
    "        # Función de activación: ReLu\r\n",
    "        ReLu = lambda x: (abs(x) + x) / 2\r\n",
    "\r\n",
    "        # Función de activación: Lineal\r\n",
    "        Linear = lambda x: x\r\n",
    "\r\n",
    "        # ------------\r\n",
    "        # FORWARD PROP\r\n",
    "        # ------------\r\n",
    "        \r\n",
    "        # Dims Z1: (Nx2)(2x3) = (Nx3)\r\n",
    "        self.Z1 = X @ self.Wc1 + self.Bc1\r\n",
    "        self.A1 = ReLu(self.Z1)\r\n",
    "\r\n",
    "        # Dims Z2: (Nx3)(3x2) = (Nx2)\r\n",
    "        self.Z2 = self.A1 @ self.Wc2 + self.Bc2\r\n",
    "        self.A2 = ReLu(self.Z2)\r\n",
    "\r\n",
    "        # Dims Z3: (Nx2)(2x1) = (Nx1)\r\n",
    "        self.Z3 = self.A2 @ self.Wc3 + self.Bc3\r\n",
    "        y_pred = Linear(self.Z3)\r\n",
    "\r\n",
    "        # Retorna la salida y las activaciones de la segunda capa\r\n",
    "        return y_pred\r\n",
    "\r\n",
    "    # Método: Backward Propagation de la Red\r\n",
    "    def backwardProp(self, X, y, y_pred, lr):\r\n",
    "        \r\n",
    "        # Función de costo: MSE\r\n",
    "        Cost = lambda y, y_pred: np.mean((y - y_pred)**2)\r\n",
    "\r\n",
    "        # Derivada de función de costo: MSE\r\n",
    "        Cost_prime = lambda y, y_pred: -2 * np.mean(y - y_pred, axis=1, keepdims=True)\r\n",
    "\r\n",
    "        # Derivada de función de activación: ReLu\r\n",
    "        ReLu_prime = lambda z: (z > 0) * 1\r\n",
    "\r\n",
    "        # Derivada de función de activación: Lineal\r\n",
    "        Linear_prime = lambda z: 1\r\n",
    "\r\n",
    "        # ------------\r\n",
    "        # ERROR\r\n",
    "        # ------------\r\n",
    "\r\n",
    "        # Se calcula el error de la predicción y se promedia\r\n",
    "        error = Cost(y, y_pred)\r\n",
    "\r\n",
    "        # ------------\r\n",
    "        # BACKWARD PROP\r\n",
    "        # ------------\r\n",
    "\r\n",
    "        # Nota: Todas las cantidades que tienen \"N\" en sus dimensiones, deben promediarse\r\n",
    "        # a lo largo de todas las muestras. Todas las Z's (Z1, Z2, Z3), A's y X deben estar\r\n",
    "        # sujetas a esto o se obtendrá un juego de pesos diferente para cada muestra. Debido\r\n",
    "        # a esto una matriz de (Nx1) se convierte en una de (1x1). Luego todos se convierten \r\n",
    "        # a vectores columna.\r\n",
    "        #self.Z1 = np.mean(self.Z1, axis=0, keepdims=True).T           # (Nx3) -> (3x1)\r\n",
    "        #self.Z2 = np.mean(self.Z2, axis=0, keepdims=True).T           # (Nx2) -> (2x1)\r\n",
    "        #self.Z3 = np.mean(self.Z3, axis=0, keepdims=True).T           # (Nx1) -> (1x1)\r\n",
    "\r\n",
    "        #self.A1 = np.mean(self.A1, axis=0, keepdims=True).T           # (Nx3) -> (3x1)\r\n",
    "        #self.A2 = np.mean(self.A2, axis=0, keepdims=True).T           # (Nx2) -> (2x1)\r\n",
    "\r\n",
    "        #X = np.mean(X, axis=0, keepdims=True).T                       # (Nx2) -> (2x1)\r\n",
    "\r\n",
    "        # dC/dy: Derivada parcial del costo con respecto de las salidas de la red (y_pred)\r\n",
    "        # Dims: (1x1). Se transpone para convertirlo en un vector columna (es fila).\r\n",
    "        dC_dy = Cost_prime(y, y_pred).T\r\n",
    "        # (Nx1)\r\n",
    "\r\n",
    "        # Delta3: dC/dy * ReLu'(Z3)\r\n",
    "        # Dims: (1x1) * (1x1) = (1x1)\r\n",
    "        Delta3 = dC_dy * Linear_prime(self.Z3)\r\n",
    "        # (Nx1) * (Nx1) = (Nx1)\r\n",
    "\r\n",
    "        # Delta2: (Wc3)(Delta3) * ReLu'(Z2)\r\n",
    "        # Dims: (2x1)(1x1) * (2x1) = (2x1)\r\n",
    "        Delta2 = self.Wc3 @ Delta3 * ReLu_prime(self.Z2)\r\n",
    "        # (Nx1)(2x1)T * (Nx2) = (Nx2)\r\n",
    "        # Delta3 @ self.Wc3 * ReLu_prime(self.Z2)\r\n",
    "\r\n",
    "        # Delta 1: (Wc2)(Delta2) * ReLu'(Z1)\r\n",
    "        # Dims: (3x2)(2x1) * (3x1) = (3x1)\r\n",
    "        Delta1 = self.Wc2 @ Delta2 * ReLu_prime(self.Z1)\r\n",
    "        # (Nx2)(3x2)T * (Nx3) = (Nx3)\r\n",
    "\r\n",
    "        # Valores para actualizar los biases\r\n",
    "        # dC/dB: Derivada parcial del costo respecto a los biases\r\n",
    "        # Se transpone para convertir el vector columna en fila.\r\n",
    "        dC_dBc1 = Delta1.T\r\n",
    "        dC_dBc2 = Delta2.T\r\n",
    "        dC_dBc3 = Delta3.T\r\n",
    "        # (Nx3) = Promediado (Nx3)\r\n",
    "        # (Nx2)\r\n",
    "        # (Nx1)\r\n",
    "\r\n",
    "        # Valores para actualizar los pesos\r\n",
    "        # dC/dW: Derivada parcial del costo respecto de los pesos\r\n",
    "        dC_dWc1 =       X @ Delta1.T            # (2x1)(3x1)^T = (2x3) = Dims Wc1\r\n",
    "        dC_dWc2 = self.A1 @ Delta2.T            # (3x1)(2x1)^T = (3x2) = Dims Wc2\r\n",
    "        dC_dWc3 = self.A2 @ Delta3.T            # (2x1)(1x1)^T = (2x1) = Dims Wc3\r\n",
    "        # (Nx2)T (Nx3) = (2x3)\r\n",
    "        # (Nx3)T (Nx2) = (3x2)\r\n",
    "        # (Nx2)T (Nx1) = (2x1)\r\n",
    "\r\n",
    "        # Se actualizan los pesos usando line search\r\n",
    "        self.Wc1 = self.Wc1 - lr * dC_dWc1\r\n",
    "        self.Wc2 = self.Wc2 - lr * dC_dWc2\r\n",
    "        self.Wc3 = self.Wc3 - lr * dC_dWc3\r\n",
    "\r\n",
    "        # Se actualizan los biases usando line search\r\n",
    "        self.Bc1 = self.Bc1 - lr * dC_dBc1\r\n",
    "        self.Bc2 = self.Bc2 - lr * dC_dBc2\r\n",
    "        self.Bc3 = self.Bc3 - lr * dC_dBc3\r\n",
    "\r\n",
    "        return error\r\n",
    "\r\n",
    "    # Método: Entrenar a la Red Neuronal\r\n",
    "    def fit(self, X, y, epsilon=0.01, max_iter=200, lr=0.0001, verbose=True):\r\n",
    "        \r\n",
    "        # Historial del error del modelo\r\n",
    "        error_historial = []\r\n",
    "\r\n",
    "        # Inicialmente el error es infinito\r\n",
    "        error = np.Inf\r\n",
    "\r\n",
    "        # El número de iteración se inicializa en 0\r\n",
    "        iter = 0\r\n",
    "\r\n",
    "        # Mientras el error sea mayor al epsilon deseado o no se haya alcanzado \r\n",
    "        # el número máximo de iteraciones\r\n",
    "        while (error > epsilon) and (iter < max_iter):\r\n",
    "\r\n",
    "            # Se realiza el paso de forward propagation\r\n",
    "            y_pred = self.forwardProp(X)\r\n",
    "\r\n",
    "            # Se actualizan los pesos utilizando backward propagation\r\n",
    "            error = self.backwardProp(X, y, y_pred, lr)\r\n",
    "\r\n",
    "            # Se incrementa el número de iteración\r\n",
    "            iter += 1\r\n",
    "\r\n",
    "            # Se agrega un elemento al historial de errores\r\n",
    "            error_historial.append(error)\r\n",
    "\r\n",
    "            # Imprimir cada cierta cantidad de iteraciones\r\n",
    "            if (iter % 10 == 0) and verbose:\r\n",
    "                print(f\"Iteración: {iter} | Error: {error}\")\r\n",
    "\r\n",
    "        print(\"Proceso de Entrenamiento Finalizado\")\r\n",
    "        return error_historial\r\n",
    "\r\n",
    "    # Método: Predecir utilizando los parámetros entrenados\r\n",
    "    def predict(self, X): \r\n",
    "        \r\n",
    "        # Se retornan los resultados obtenidos al realizar un forward pass\r\n",
    "        return self.forwardProp(X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se emplea el modelo anterior para entrenar a un aproximador de una función XOR"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Tabla de verdad de XOR\r\n",
    "# Entradas del XOR\r\n",
    "X = np.array([[0,0],\r\n",
    "              [0,1],\r\n",
    "              [1,0],\r\n",
    "              [1,1]])\r\n",
    "\r\n",
    "# Salidas del XOR\r\n",
    "y = np.array([[0, 1, 1, 0]]).T\r\n",
    "\r\n",
    "# Modelo y entrenamiento de red neuronal\r\n",
    "nn = NeuralNetXOR(first_hiddenLayer_neurons=4)\r\n",
    "error = nn.fit(X, y, lr=0.01, max_iter=400, verbose=False)\r\n",
    "\r\n",
    "# Predicción de la red neuronal\r\n",
    "y_hat = nn.predict(X)\r\n",
    "\r\n",
    "# Se grafica el error\r\n",
    "plt.plot(error)\r\n",
    "plt.xlabel(\"Epoch\")\r\n",
    "plt.ylabel(\"Error\")\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Proceso de Entrenamiento Finalizado\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se comparan las salidas reales de un XOR, con las del aproximador."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Se concatenan los datos en un array y se convierten a un dataframe\r\n",
    "DataArray = np.hstack((X, y, y_hat, y == y_hat))\r\n",
    "df = pd.DataFrame(DataArray, columns=['Input 1', ' Input 2', 'Output Real', 'Output Predicho', 'Correcto'])\r\n",
    "\r\n",
    "# Se presentan los resultados de la predicción\r\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input 1</th>\n",
       "      <th>Input 2</th>\n",
       "      <th>Output Real</th>\n",
       "      <th>Output Predicho</th>\n",
       "      <th>Correcto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499521</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.499785</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.499893</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500203</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Input 1   Input 2  Output Real  Output Predicho  Correcto\n",
       "0      0.0       0.0          0.0         0.499521       0.0\n",
       "1      0.0       1.0          1.0         0.499785       0.0\n",
       "2      1.0       0.0          1.0         0.499893       0.0\n",
       "3      1.0       1.0          0.0         0.500203       0.0"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "658dc12c475a3a8caebf03b24f414cffa2901ebd330ffd26b9c22f028a90850c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}