{"nbformat":4,"nbformat_minor":2,"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.1"},"colab":{"name":"Clase_09_MLPs_ejemplo_Sentiment_Classification_Projects.ipynb","provenance":[],"collapsed_sections":["GqFpWaa0NFld","qUZYYi80NFlm","Xt3ymcciNFln","Ur2aGCM7NFlr","lxjRsU1PNFlu","NHuo5bKaNFl2","CMqtFnRRNFl8"]}},"cells":[{"cell_type":"markdown","source":["# Sentiment Classification From Text & How To \"Frame Problems\" for a Neural Network\n","\n","Material basado(con modificaciones personalizadas) en: \n","Sentiment Classification & How To \"Frame Problems for a Neural Network\" de Udacity\n","* Parte de \"deep learning nanodegree\" de udacity.\n","* Instructor: Andrew Trask"],"metadata":{"id":"sB3OCWenNFlU"}},{"cell_type":"markdown","source":["### What You Should Already Know\r\n","\r\n","- neural networks, forward and back-propagation\r\n","- stochastic gradient descent\r\n","- loss functions: mean squared error, cross-entropy\r\n","- and train/test splits\r\n","\r\n","### Tutorial Outline:\r\n","\r\n","- Intro: The Importance of \"Framing a Problem\" (this lesson)\r\n","\r\n","- [Curate a Dataset](#lesson_1)\r\n","- [Developing a \"Predictive Theory\"](#lesson_2)\r\n","- [**PROJECT 1**: Quick Theory Validation](#project_1)\r\n","\r\n","\r\n","- [Transforming Text to Numbers](#lesson_3)\r\n","- [**PROJECT 2**: Creating the Input/Output Data](#project_2)\r\n","\r\n","\r\n","- Putting it all together in a Neural Network (video only - nothing in notebook)\r\n","- [**PROJECT 3**: Building our Neural Network](#project_3)\r\n","\r\n","\r\n","- [Understanding Neural Noise](#lesson_4)\r\n","- [**PROJECT 4**: Making Learning Faster by Reducing Noise](#project_4)\r\n","\r\n","\r\n","- [Analyzing Inefficiencies in our Network](#lesson_5)\r\n","- [**PROJECT 5**: Making our Network Train and Run Faster](#project_5)\r\n","\r\n","\r\n","- [Further Noise Reduction](#lesson_6)\r\n","- [**PROJECT 6**: Reducing Noise by Strategically Reducing the Vocabulary](#project_6)\r\n","\r\n","\r\n","- [Analysis: What's going on in the weights?](#lesson_7)"],"metadata":{"id":"7SibLmA0NFlV"}},{"cell_type":"code","execution_count":null,"source":["import base64\r\n","import requests"],"outputs":[],"metadata":{"id":"oEaXjYpvO1HV"}},{"cell_type":"markdown","source":["# Lesson: Curate a Dataset<a id='lesson_1'></a>\n"],"metadata":{"nbpresent":{"id":"56bb3cba-260c-4ebe-9ed6-b995b4c72aa3"},"id":"uItygGAhNFlV"}},{"cell_type":"code","execution_count":null,"source":["reviews_url = \"https://raw.githubusercontent.com/llealgt/moview_review_sentiment_prediction_neural_network/master/reviews.txt\"\r\n","req = requests.get(reviews_url)\r\n","reviews_raw = req.text\r\n","\r\n","reviews = reviews_raw.split(\"\\n\")"],"outputs":[],"metadata":{"id":"w2he2Rg9O4Z4"}},{"cell_type":"code","execution_count":null,"source":["labels_url = \"https://raw.githubusercontent.com/llealgt/moview_review_sentiment_prediction_neural_network/master/labels.txt\"\r\n","req = requests.get(labels_url)\r\n","labels_raw = req.text.upper()\r\n","\r\n","labels = labels_raw.split(\"\\n\")"],"outputs":[],"metadata":{"id":"npVTvMVEPO1I"}},{"cell_type":"code","execution_count":null,"source":["def pretty_print_review_and_label(i):\r\n","    print(labels[i] + \"\\t:\\t\" + reviews[i][:80] + \"...\")\r\n"],"outputs":[],"metadata":{"collapsed":true,"nbpresent":{"id":"eba2b193-0419-431e-8db9-60f34dd3fe83"},"id":"5DIjlpq_NFlW"}},{"cell_type":"markdown","source":["**Note:** The data in `reviews.txt` we're using has already been preprocessed a bit and contains only lower case characters. If we were working from raw data, where we didn't know it was all lower case, we would want to add a step here to convert it. That's so we treat different variations of the same word, like `The`, `the`, and `THE`, all the same way."],"metadata":{"id":"kkfeJEvBNFlW"}},{"cell_type":"markdown","source":["## Get an idea of how the data looks like"],"metadata":{"id":"fZ6jtmoNNFlW"}},{"cell_type":"code","execution_count":null,"source":["len(reviews),len(labels)"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["(25001, 25001)"]},"metadata":{},"execution_count":5}],"metadata":{"id":"cp6S1_D_NFlX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337035176,"user_tz":300,"elapsed":66,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"580d7712-d056-4078-c68a-b071d037a15e"}},{"cell_type":"code","execution_count":null,"source":["reviews[0]"],"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   '"]},"metadata":{},"execution_count":6}],"metadata":{"nbpresent":{"id":"bb95574b-21a0-4213-ae50-34363cf4f87f"},"id":"F1cda-zONFlX","colab":{"base_uri":"https://localhost:8080/","height":120},"executionInfo":{"status":"ok","timestamp":1629337035178,"user_tz":300,"elapsed":64,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"f690bf1e-8d09-4313-f23e-7dc74b25ead1"}},{"cell_type":"code","execution_count":null,"source":["labels[0]"],"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'POSITIVE'"]},"metadata":{},"execution_count":7}],"metadata":{"nbpresent":{"id":"e0408810-c424-4ed4-afb9-1735e9ddbd0a"},"id":"UXMtBC9iNFlY","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1629337035191,"user_tz":300,"elapsed":69,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"0d5d61fb-96f0-472a-c2f5-5dd8c8e301d4"}},{"cell_type":"code","execution_count":null,"source":["pretty_print_review_and_label(2)"],"outputs":[{"output_type":"stream","name":"stdout","text":["POSITIVE\t:\thomelessness  or houselessness as george carlin stated  has been an issue for ye...\n"]}],"metadata":{"id":"m6574X9_NFlc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337035193,"user_tz":300,"elapsed":64,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"650b072d-b39d-4e2e-ad74-f59cabb4c650"}},{"cell_type":"markdown","source":["# Lesson: Develop a Predictive Theory<a id='lesson_2'></a>"],"metadata":{"id":"UX1gPa9jNFlc"}},{"cell_type":"code","execution_count":null,"source":["print(\"labels.txt \\t : \\t reviews.txt\\n\")\r\n","pretty_print_review_and_label(2137)\r\n","pretty_print_review_and_label(12816)\r\n","pretty_print_review_and_label(6267)\r\n","pretty_print_review_and_label(21934)\r\n","pretty_print_review_and_label(5297)\r\n","pretty_print_review_and_label(4998)"],"outputs":[{"output_type":"stream","name":"stdout","text":["labels.txt \t : \t reviews.txt\n","\n","NEGATIVE\t:\tthis movie is terrible but it has some good effects .  ...\n","POSITIVE\t:\tadrian pasdar is excellent is this film . he makes a fascinating woman .  ...\n","NEGATIVE\t:\tcomment this movie is impossible . is terrible  very improbable  bad interpretat...\n","POSITIVE\t:\texcellent episode movie ala pulp fiction .  days   suicides . it doesnt get more...\n","NEGATIVE\t:\tif you haven  t seen this  it  s terrible . it is pure trash . i saw this about ...\n","POSITIVE\t:\tthis schiffer guy is a real genius  the movie is of excellent quality and both e...\n"]}],"metadata":{"nbpresent":{"id":"e67a709f-234f-4493-bae6-4fb192141ee0"},"id":"mTBnXd6tNFlc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337035197,"user_tz":300,"elapsed":59,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"1d650836-0079-4e93-eba6-af6e7ec7eba0"}},{"cell_type":"markdown","source":["# Project 1: Quick Theory Validation<a id='project_1'></a>\n","\n","You'll find the [Counter](https://docs.python.org/2/library/collections.html#collections.Counter) class to be useful in this exercise, as well as the [numpy](https://docs.scipy.org/doc/numpy/reference/) library."],"metadata":{"id":"GqFpWaa0NFld"}},{"cell_type":"code","execution_count":null,"source":["from collections import Counter\r\n","import numpy as np"],"outputs":[],"metadata":{"collapsed":true,"id":"Qcw9VsroNFld"}},{"cell_type":"markdown","source":["We'll create three `Counter` objects, one for words from postive reviews, one for words from negative reviews, and one for all the words."],"metadata":{"id":"vhlWwXKLNFld"}},{"cell_type":"code","execution_count":null,"source":["# Create three Counter objects to store positive, negative and total counts\r\n","positive_counts = Counter()\r\n","negative_counts = Counter()\r\n","total_counts = Counter()"],"outputs":[],"metadata":{"collapsed":true,"id":"BUL0R365NFld"}},{"cell_type":"markdown","source":["**TODO:** Examine all the reviews. For each word in a positive review, increase the count for that word in both your positive counter and the total words counter; likewise, for each word in a negative review, increase the count for that word in both your negative counter and the total words counter.\n","\n","**Note:** Throughout these projects, you should use `split(' ')` to divide a piece of text (such as a review) into individual words. If you use `split()` instead, you'll get slightly different results than what the videos and solutions show."],"metadata":{"id":"0F3ryK7cNFld"}},{"cell_type":"code","execution_count":null,"source":["# TODO: Loop over all the words in all the reviews and increment the counts in the appropriate counter objects\r\n","for index,label in enumerate(labels):\r\n","    words = reviews[index].split(' ')\r\n","    if label == 'POSITIVE':\r\n","        for word in words:\r\n","            positive_counts[word]+=1\r\n","            total_counts[word]+=1\r\n","    else:\r\n","        for word in words:\r\n","            negative_counts[word]+=1\r\n","            total_counts[word]+=1"],"outputs":[],"metadata":{"collapsed":true,"id":"SIwfeg8hNFle"}},{"cell_type":"markdown","source":["Run the following two cells to list the words used in positive reviews and negative reviews, respectively, ordered from most to least commonly used. "],"metadata":{"id":"uDBq37rKNFle"}},{"cell_type":"code","execution_count":null,"source":["# Examine the counts of the most common words in positive reviews\r\n","positive_counts.most_common()[:100]"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('', 550468),\n"," ('the', 173324),\n"," ('.', 159654),\n"," ('and', 89722),\n"," ('a', 83688),\n"," ('of', 76855),\n"," ('to', 66746),\n"," ('is', 57245),\n"," ('in', 50215),\n"," ('br', 49235),\n"," ('it', 48025),\n"," ('i', 40743),\n"," ('that', 35630),\n"," ('this', 35080),\n"," ('s', 33815),\n"," ('as', 26308),\n"," ('with', 23247),\n"," ('for', 22416),\n"," ('was', 21917),\n"," ('film', 20937),\n"," ('but', 20822),\n"," ('movie', 19074),\n"," ('his', 17227),\n"," ('on', 17008),\n"," ('you', 16681),\n"," ('he', 16282),\n"," ('are', 14807),\n"," ('not', 14272),\n"," ('t', 13720),\n"," ('one', 13655),\n"," ('have', 12587),\n"," ('be', 12416),\n"," ('by', 11997),\n"," ('all', 11942),\n"," ('who', 11464),\n"," ('an', 11294),\n"," ('at', 11234),\n"," ('from', 10767),\n"," ('her', 10474),\n"," ('they', 9895),\n"," ('has', 9186),\n"," ('so', 9154),\n"," ('like', 9038),\n"," ('about', 8313),\n"," ('very', 8305),\n"," ('out', 8134),\n"," ('there', 8057),\n"," ('she', 7779),\n"," ('what', 7737),\n"," ('or', 7732),\n"," ('good', 7720),\n"," ('more', 7521),\n"," ('when', 7456),\n"," ('some', 7441),\n"," ('if', 7285),\n"," ('just', 7152),\n"," ('can', 7001),\n"," ('story', 6780),\n"," ('time', 6515),\n"," ('my', 6488),\n"," ('great', 6419),\n"," ('well', 6405),\n"," ('up', 6321),\n"," ('which', 6267),\n"," ('their', 6107),\n"," ('see', 6026),\n"," ('also', 5550),\n"," ('we', 5531),\n"," ('really', 5476),\n"," ('would', 5400),\n"," ('will', 5218),\n"," ('me', 5167),\n"," ('had', 5148),\n"," ('only', 5137),\n"," ('him', 5018),\n"," ('even', 4964),\n"," ('most', 4864),\n"," ('other', 4858),\n"," ('were', 4782),\n"," ('first', 4755),\n"," ('than', 4736),\n"," ('much', 4685),\n"," ('its', 4622),\n"," ('no', 4574),\n"," ('into', 4544),\n"," ('people', 4479),\n"," ('best', 4319),\n"," ('love', 4301),\n"," ('get', 4272),\n"," ('how', 4213),\n"," ('life', 4199),\n"," ('been', 4189),\n"," ('because', 4079),\n"," ('way', 4036),\n"," ('do', 3941),\n"," ('made', 3823),\n"," ('films', 3813),\n"," ('them', 3805),\n"," ('after', 3800),\n"," ('many', 3766)]"]},"metadata":{},"execution_count":13}],"metadata":{"id":"YOiLu29hNFle","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337040686,"user_tz":300,"elapsed":120,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"5ab5c699-72b9-446c-feaa-e704603435f0"}},{"cell_type":"code","execution_count":null,"source":["# Examine the counts of the most common words in negative reviews\r\n","negative_counts.most_common()[:100]"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('', 561463),\n"," ('.', 167538),\n"," ('the', 163389),\n"," ('a', 79321),\n"," ('and', 74385),\n"," ('of', 69009),\n"," ('to', 68974),\n"," ('br', 52637),\n"," ('is', 50083),\n"," ('it', 48327),\n"," ('i', 46880),\n"," ('in', 43753),\n"," ('this', 40920),\n"," ('that', 37615),\n"," ('s', 31546),\n"," ('was', 26291),\n"," ('movie', 24965),\n"," ('for', 21927),\n"," ('but', 21781),\n"," ('with', 20878),\n"," ('as', 20625),\n"," ('t', 20361),\n"," ('film', 19218),\n"," ('you', 17549),\n"," ('on', 17192),\n"," ('not', 16354),\n"," ('have', 15144),\n"," ('are', 14623),\n"," ('be', 14541),\n"," ('he', 13856),\n"," ('one', 13134),\n"," ('they', 13011),\n"," ('at', 12279),\n"," ('his', 12147),\n"," ('all', 12036),\n"," ('so', 11463),\n"," ('like', 11238),\n"," ('there', 10775),\n"," ('just', 10619),\n"," ('by', 10549),\n"," ('or', 10272),\n"," ('an', 10266),\n"," ('who', 9969),\n"," ('from', 9731),\n"," ('if', 9518),\n"," ('about', 9061),\n"," ('out', 8979),\n"," ('what', 8422),\n"," ('some', 8306),\n"," ('no', 8143),\n"," ('her', 7947),\n"," ('even', 7687),\n"," ('can', 7653),\n"," ('has', 7604),\n"," ('good', 7423),\n"," ('bad', 7401),\n"," ('would', 7036),\n"," ('up', 6970),\n"," ('only', 6781),\n"," ('more', 6730),\n"," ('when', 6726),\n"," ('she', 6444),\n"," ('really', 6262),\n"," ('time', 6209),\n"," ('had', 6142),\n"," ('my', 6015),\n"," ('were', 6001),\n"," ('which', 5780),\n"," ('very', 5764),\n"," ('me', 5606),\n"," ('see', 5452),\n"," ('don', 5336),\n"," ('we', 5328),\n"," ('their', 5278),\n"," ('do', 5236),\n"," ('story', 5208),\n"," ('than', 5183),\n"," ('been', 5100),\n"," ('much', 5078),\n"," ('get', 5037),\n"," ('because', 4966),\n"," ('people', 4806),\n"," ('then', 4761),\n"," ('make', 4722),\n"," ('how', 4688),\n"," ('could', 4686),\n"," ('any', 4658),\n"," ('into', 4567),\n"," ('made', 4541),\n"," ('first', 4306),\n"," ('other', 4305),\n"," ('well', 4254),\n"," ('too', 4174),\n"," ('them', 4165),\n"," ('plot', 4154),\n"," ('movies', 4080),\n"," ('acting', 4056),\n"," ('will', 3993),\n"," ('way', 3989),\n"," ('most', 3919)]"]},"metadata":{},"execution_count":14}],"metadata":{"id":"kw0KBQuZNFle","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337040688,"user_tz":300,"elapsed":116,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"b19fdf84-dba5-4754-a139-fa8982a1ecef"}},{"cell_type":"markdown","source":["As you can see, common words like \"the\" appear very often in both positive and negative reviews. Instead of finding the most common words in positive or negative reviews, what you really want are the words found in positive reviews more often than in negative reviews, and vice versa. To accomplish this, you'll need to calculate the **ratios** of word usage between positive and negative reviews.\n","\n","**TODO:** Check all the words you've seen and calculate the ratio of postive to negative uses and store that ratio in `pos_neg_ratios`. \n",">Hint: the positive-to-negative ratio for a given word can be calculated with `positive_counts[word] / float(negative_counts[word]+1)`. Notice the `+1` in the denominator – that ensures we don't divide by zero for words that are only seen in positive reviews."],"metadata":{"id":"PiLs4EouNFlf"}},{"cell_type":"code","execution_count":null,"source":["# Create Counter object to store positive/negative ratios\r\n","pos_neg_ratios = Counter()\r\n","\r\n","#  Calculate the ratios of positive and negative uses of the most common words\r\n","#       Consider words to be \"common\" if they've been used at least 100 times\r\n","#  If a word is common, calculate its \"positive\" ratio\r\n","\r\n","for word,count in total_counts.most_common():\r\n","    if count >= 100:\r\n","        positive_count = positive_counts[word]\r\n","        negative_count = negative_counts[word] +1 #(+1 to avoid division by zero)\r\n","        \r\n","        word_positive_ratio = positive_count / negative_count\r\n","        \r\n","        pos_neg_ratios[word] = word_positive_ratio"],"outputs":[],"metadata":{"collapsed":true,"id":"Xv254NaVNFlf"}},{"cell_type":"markdown","source":["Examine the ratios you've calculated for a few words:"],"metadata":{"id":"nC-f0uQGNFlk"}},{"cell_type":"code","execution_count":null,"source":["print(\"Pos-to-neg ratio for 'the' = {}\".format(pos_neg_ratios[\"the\"]))\r\n","print(\"Pos-to-neg ratio for 'amazing' = {}\".format(pos_neg_ratios[\"amazing\"]))\r\n","print(\"Pos-to-neg ratio for 'terrible' = {}\".format(pos_neg_ratios[\"terrible\"]))"],"outputs":[{"output_type":"stream","name":"stdout","text":["Pos-to-neg ratio for 'the' = 1.0607993145235326\n","Pos-to-neg ratio for 'amazing' = 4.022813688212928\n","Pos-to-neg ratio for 'terrible' = 0.17744252873563218\n"]}],"metadata":{"id":"SUwgda04NFlk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337040690,"user_tz":300,"elapsed":114,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"c3328708-85f5-442d-e40b-2f6817de1330"}},{"cell_type":"markdown","source":["Looking closely at the values you just calculated, we see the following:\n","\n","* Words that you would expect to see more often in positive reviews – like \"amazing\" – have a ratio greater than 1. The more skewed a word is toward postive, the farther from 1 its positive-to-negative ratio  will be.\n","* Words that you would expect to see more often in negative reviews – like \"terrible\" – have positive values that are less than 1. The more skewed a word is toward negative, the closer to zero its positive-to-negative ratio will be.\n","* Neutral words, which don't really convey any sentiment because you would expect to see them in all sorts of reviews – like \"the\" – have values very close to 1. A perfectly neutral word – one that was used in exactly the same number of positive reviews as negative reviews – would be almost exactly 1. The `+1` we suggested you add to the denominator slightly biases words toward negative, but it won't matter because it will be a tiny bias and later we'll be ignoring words that are too close to neutral anyway.\n","\n","Ok, the ratios tell us which words are used more often in postive or negative reviews, but the specific values we've calculated are a bit difficult to work with. A very positive word like \"amazing\" has a value above 4, whereas a very negative word like \"terrible\" has a value around 0.18. Those values aren't easy to compare for a couple of reasons:\n","\n","* Right now, 1 is considered neutral, but the absolute value of the postive-to-negative rations of very postive words is larger than the absolute value of the ratios for the very negative words. So there is no way to directly compare two numbers and see if one word conveys the same magnitude of positive sentiment as another word conveys negative sentiment. So we should center all the values around netural so the absolute value fro neutral of the postive-to-negative ratio for a word would indicate how much sentiment (positive or negative) that word conveys.\n","* When comparing absolute values it's easier to do that around zero than one. \n","\n","To fix these issues, we'll convert all of our ratios to new values using logarithms.\n","\n","**TODO:** Go through all the ratios you calculated and convert their values using the following formulas:\n","> * For any postive words, convert the ratio using `np.log(ratio)`\n","> * For any negative words, convert the ratio using `-np.log(1/(ratio + 0.01))`\n","\n","That second equation may look strange, but what it's doing is dividing one by a very small number, which will produce a larger positive number. Then, it takes the `log` of that, which produces numbers similar to the ones for the postive words. Finally, we negate the values by adding that minus sign up front. In the end, extremely positive and extremely negative words will have positive-to-negative ratios with similar magnitudes but oppositite signs."],"metadata":{"id":"Ln-fZ8nsNFll"}},{"cell_type":"code","execution_count":null,"source":["# TODO: Convert ratios to logs\r\n","# Note to myself: i think for negative words a simple -1 * (ratio)**-1 would do but...\r\n","\r\n","for word in pos_neg_ratios:\r\n","    ratio = pos_neg_ratios[word]\r\n","    \r\n","    if ratio > 1:\r\n","        new_ratio  = np.log(ratio)\r\n","    else:\r\n","        new_ratio = -np.log(1/(ratio +0.001))\r\n","    \r\n","    pos_neg_ratios[word] = new_ratio"],"outputs":[],"metadata":{"collapsed":true,"id":"lE8r8wEKNFll"}},{"cell_type":"markdown","source":["Examine the new ratios you've calculated for the same words from before:"],"metadata":{"id":"A0y6-CQtNFll"}},{"cell_type":"code","execution_count":null,"source":["print(\"Pos-to-neg ratio for 'the' = {}\".format(pos_neg_ratios[\"the\"]))\r\n","print(\"Pos-to-neg ratio for 'amazing' = {}\".format(pos_neg_ratios[\"amazing\"]))\r\n","print(\"Pos-to-neg ratio for 'terrible' = {}\".format(pos_neg_ratios[\"terrible\"]))"],"outputs":[{"output_type":"stream","name":"stdout","text":["Pos-to-neg ratio for 'the' = 0.05902269426102881\n","Pos-to-neg ratio for 'amazing' = 1.3919815802404802\n","Pos-to-neg ratio for 'terrible' = -1.723488697472832\n"]}],"metadata":{"id":"G9emSd7yNFll","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337040691,"user_tz":300,"elapsed":105,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"f1cf6b5f-eefd-48f6-e3fa-5f21706de835"}},{"cell_type":"markdown","source":["If everything worked, now you should see neutral words with values close to zero. In this case, \"the\" is near zero but slightly positive, so it was probably used in more positive reviews than negative reviews. But look at \"amazing\"'s ratio - it's above `1`, showing it is clearly a word with positive sentiment. And \"terrible\" has a similar score, but in the opposite direction, so it's below `-1`. It's now clear that both of these words are associated with specific, opposing sentiments.\n","\n","Now run the following cells to see more ratios. \n","\n","The first cell displays all the words, ordered by how associated they are with postive reviews. (Your notebook will most likely truncate the output so you won't actually see *all* the words in the list.)\n","\n","The second cell displays the 30 words most associated with negative reviews by reversing the order of the first list and then looking at the first 30 words. (If you want the second cell to display all the words, ordered by how associated they are with negative reviews, you could just write `reversed(pos_neg_ratios.most_common())`.)\n","\n","You should continue to see values similar to the earlier ones we checked – neutral words will be close to `0`, words will get more positive as their ratios approach and go above `1`, and words will get more negative as their ratios approach and go below `-1`. That's why we decided to use the logs instead of the raw ratios."],"metadata":{"id":"P8qH80MsNFlm"}},{"cell_type":"code","execution_count":null,"source":["# words most frequently seen in a review with a \"POSITIVE\" label\r\n","pos_neg_ratios.most_common()[:30]"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('edie', 4.6913478822291435),\n"," ('paulie', 4.07753744390572),\n"," ('felix', 3.152736022363656),\n"," ('polanski', 2.8233610476132043),\n"," ('matthau', 2.80672172860924),\n"," ('victoria', 2.681021528714291),\n"," ('mildred', 2.6026896854443837),\n"," ('gandhi', 2.538973871058276),\n"," ('flawless', 2.451005098112319),\n"," ('superbly', 2.26002547857525),\n"," ('perfection', 2.159484249353372),\n"," ('astaire', 2.1400661634962708),\n"," ('captures', 2.038619547159581),\n"," ('voight', 2.030170492673053),\n"," ('wonderfully', 2.0218960560332353),\n"," ('powell', 1.978345424808467),\n"," ('brosnan', 1.9547990964725592),\n"," ('lily', 1.9203768470501485),\n"," ('bakshi', 1.9029851043382795),\n"," ('lincoln', 1.9014583864844796),\n"," ('refreshing', 1.8551812956655511),\n"," ('breathtaking', 1.8481124057791867),\n"," ('bourne', 1.8478489358790986),\n"," ('lemmon', 1.8458266904983307),\n"," ('delightful', 1.8002701588959635),\n"," ('flynn', 1.7996646487351682),\n"," ('andrews', 1.7764919970972666),\n"," ('homer', 1.7692866133759964),\n"," ('beautifully', 1.7626953362841438),\n"," ('soccer', 1.7578579175523736)]"]},"metadata":{},"execution_count":19}],"metadata":{"id":"t2S9MH0sNFlm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337040691,"user_tz":300,"elapsed":103,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"fc3b2464-da7d-4560-cb72-9e3aba21f02c"}},{"cell_type":"code","execution_count":null,"source":["# words most frequently seen in a review with a \"NEGATIVE\" label\r\n","list(reversed(pos_neg_ratios.most_common()))[0:30]\r\n","\r\n","# Note: \r\n","#       If you explore the documentation for the Counter class, \r\n","#       you will see you could also find the 30 least common\r\n","#       words like this: pos_neg_ratios.most_common()[:-31:-1]"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('boll', -4.835282406618394),\n"," ('uwe', -4.527846102553548),\n"," ('seagal', -3.606606956743819),\n"," ('unwatchable', -3.232428791272904),\n"," ('stinker', -3.1843768086123894),\n"," ('mst', -2.931339111817795),\n"," ('incoherent', -2.918210222585477),\n"," ('unfunny', -2.677582826320177),\n"," ('waste', -2.6057506568316997),\n"," ('blah', -2.5574420885289504),\n"," ('horrid', -2.4729780789227265),\n"," ('pointless', -2.443723518768643),\n"," ('atrocious', -2.4146593168481547),\n"," ('redeeming', -2.3576171050548607),\n"," ('prom', -2.35030978724235),\n"," ('drivel', -2.33663658094709),\n"," ('lousy', -2.2975727999267512),\n"," ('worst', -2.2771908066767406),\n"," ('laughable', -2.2547849053935245),\n"," ('awful', -2.2179631752505466),\n"," ('poorly', -2.2115829815780015),\n"," ('wasting', -2.1955788734265296),\n"," ('remotely', -2.1882648359647474),\n"," ('existent', -2.0714733720306593),\n"," ('boredom', -1.987774353154012),\n"," ('miserably', -1.9851235895077681),\n"," ('sucks', -1.9798005773223373),\n"," ('uninspired', -1.9760572894714397),\n"," ('lame', -1.9745380983043672),\n"," ('insult', -1.9711406722511042)]"]},"metadata":{},"execution_count":20}],"metadata":{"id":"oiJZVMA7NFlm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337040692,"user_tz":300,"elapsed":102,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"911a38e2-8d83-423c-bdfb-cb03da0cb5db"}},{"cell_type":"markdown","source":["# End of Project 1. \n","\n","\n","# Transforming Text into Numbers<a id='lesson_3'></a>\n"],"metadata":{"id":"qUZYYi80NFlm"}},{"cell_type":"code","execution_count":null,"source":["from IPython.display import Image\r\n","\r\n","review = \"This was a horrible, terrible movie.\"\r\n","\r\n","#Image(filename='https://raw.githubusercontent.com/llealgt/moview_review_sentiment_prediction_neural_network/master/sentiment_network.png')"],"outputs":[],"metadata":{"id":"ZF4SoxLvNFln"}},{"cell_type":"markdown","source":["<img src=\"https://raw.githubusercontent.com/llealgt/moview_review_sentiment_prediction_neural_network/master/sentiment_network.png\">"],"metadata":{"id":"sS3OmRJwN9Nc"}},{"cell_type":"code","execution_count":null,"source":["review = \"The movie was excellent\"\r\n","\r\n","#Image(filename='sentiment_network_pos.png')"],"outputs":[],"metadata":{"id":"iyB256jANFln"}},{"cell_type":"markdown","source":["<img src=\"https://raw.githubusercontent.com/llealgt/moview_review_sentiment_prediction_neural_network/master/sentiment_network_pos.png\">"],"metadata":{"id":"JtLNQhPlONy6"}},{"cell_type":"markdown","source":["# Project 2: Creating the Input/Output Data<a id='project_2'></a>\n","\n","**TODO:** Create a [set](https://docs.python.org/3/tutorial/datastructures.html#sets) named `vocab` that contains every word in the vocabulary."],"metadata":{"id":"Xt3ymcciNFln"}},{"cell_type":"code","execution_count":null,"source":["# TODO: Create set named \"vocab\" containing all of the words from all of the reviews\r\n","\r\n","#All the words are already in the total_counts Counter , i dont need to go to every review\r\n","vocab = set(total_counts.keys())"],"outputs":[],"metadata":{"collapsed":true,"id":"lGroGrYBNFln"}},{"cell_type":"markdown","source":["Run the following cell to check your vocabulary size. If everything worked correctly, it should print **74074**"],"metadata":{"id":"KzaGazxZNFln"}},{"cell_type":"code","execution_count":null,"source":["vocab_size = len(vocab)\r\n","print(vocab_size)"],"outputs":[{"output_type":"stream","name":"stdout","text":["74074\n"]}],"metadata":{"id":"5whqfNuMNFln","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337040696,"user_tz":300,"elapsed":102,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"bb0f5526-9544-4084-add3-ac0a4869ecd7"}},{"cell_type":"markdown","source":["Take a look at the following image. It represents the layers of the neural network you'll be building throughout this notebook. `layer_0` is the input layer, `layer_1` is a hidden layer, and `layer_2` is the output layer.\n","\n","<img src=\"https://raw.githubusercontent.com/llealgt/moview_review_sentiment_prediction_neural_network/master/sentiment_network_2.png\">"],"metadata":{"id":"uBMkDTx1NFlo"}},{"cell_type":"markdown","source":["**TODO:** Create a numpy array called `layer_0` and initialize it to all zeros. You will find the [zeros](https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros.html) function particularly helpful here. Be sure you create `layer_0` as a 2-dimensional matrix with 1 row and `vocab_size` columns. "],"metadata":{"id":"ybPMnktzNFlo"}},{"cell_type":"code","execution_count":null,"source":["# TODO: Create layer_0 matrix with dimensions 1 by vocab_size, initially filled with zeros\r\n","layer_0 = np.array(np.zeros((1,vocab_size)))"],"outputs":[],"metadata":{"collapsed":true,"id":"QURuMDBQNFlo"}},{"cell_type":"markdown","source":["Run the following cell. It should display `(1, 74074)`"],"metadata":{"id":"iUhJk_BeNFlo"}},{"cell_type":"code","execution_count":null,"source":["layer_0.shape"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 74074)"]},"metadata":{},"execution_count":26}],"metadata":{"id":"sTXnjn-pNFlo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337040697,"user_tz":300,"elapsed":99,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"0568e1bf-6110-45e2-b618-476bad36358e"}},{"cell_type":"markdown","source":["<img src=\"https://raw.githubusercontent.com/llealgt/moview_review_sentiment_prediction_neural_network/master/sentiment_network.png\">"],"metadata":{"id":"R83AqrzMW-8o"}},{"cell_type":"markdown","source":["`layer_0` contains one entry for every word in the vocabulary, as shown in the above image. We need to make sure we know the index of each word, so run the following cell to create a lookup table that stores the index of every word."],"metadata":{"id":"a0klsi-xNFlp"}},{"cell_type":"code","execution_count":null,"source":["# Create a dictionary of words in the vocabulary mapped to index positions\r\n","# (to be used in layer_0)\r\n","word2index = {}\r\n","for i,word in enumerate(vocab):\r\n","    word2index[word] = i\r\n","    \r\n","# display the map of words to indices\r\n","word2index"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'': 0,\n"," 'rookies': 1,\n"," 'charade': 2,\n"," 'endorsed': 3,\n"," 'advocacy': 4,\n"," 'spoliers': 5,\n"," 'salaam': 6,\n"," 'mabuse': 7,\n"," 'awww': 8,\n"," 'conpiricy': 9,\n"," 'jindabyne': 10,\n"," 'ballgames': 11,\n"," 'basket': 12,\n"," 'continued': 13,\n"," 'elizabethan': 14,\n"," 'ghungroo': 15,\n"," 'baffle': 16,\n"," 'camra': 17,\n"," 'abhays': 18,\n"," 'luana': 19,\n"," 'hashmi': 20,\n"," 'mvp': 21,\n"," 'unoriginality': 22,\n"," 'highly': 23,\n"," 'detatched': 24,\n"," 'wilkinson': 25,\n"," 'absurdness': 26,\n"," 'viability': 27,\n"," 'chickboxer': 28,\n"," 'roget': 29,\n"," 'teens': 30,\n"," 'villainous': 31,\n"," 'approval': 32,\n"," 'demagogue': 33,\n"," 'egyptologistic': 34,\n"," 'johnstone': 35,\n"," 'brechtian': 36,\n"," 'fuing': 37,\n"," 'tyrants': 38,\n"," 'intrinsically': 39,\n"," 'loooooooooooong': 40,\n"," 'spoiler': 41,\n"," 'poland': 42,\n"," 'independents': 43,\n"," 'highlighting': 44,\n"," 'vilifies': 45,\n"," 'dinosaur': 46,\n"," 'bejesus': 47,\n"," 'slicing': 48,\n"," 'saree': 49,\n"," 'geishas': 50,\n"," 'weathered': 51,\n"," 'liana': 52,\n"," 'sarafian': 53,\n"," 'holst': 54,\n"," 'apparel': 55,\n"," 'kristoffersons': 56,\n"," 'store': 57,\n"," 'soh': 58,\n"," 'kerosene': 59,\n"," 'insensitivity': 60,\n"," 'sonya': 61,\n"," 'exxon': 62,\n"," 'rainmakers': 63,\n"," 'grushenka': 64,\n"," 'beaubian': 65,\n"," 'goodies': 66,\n"," 'flippin': 67,\n"," 'massacre': 68,\n"," 'disqualifying': 69,\n"," 'overblow': 70,\n"," 'grendelif': 71,\n"," 'nambi': 72,\n"," 'waft': 73,\n"," 'palace': 74,\n"," 'powering': 75,\n"," 'caan': 76,\n"," 'ahhhhhhhhh': 77,\n"," 'cusamanos': 78,\n"," 'habitually': 79,\n"," 'taker': 80,\n"," 'taranitar': 81,\n"," 'euphemizing': 82,\n"," 'esquire': 83,\n"," 'haitian': 84,\n"," 'functions': 85,\n"," 'legalised': 86,\n"," 'visuel': 87,\n"," 'enliven': 88,\n"," 'affluence': 89,\n"," 'amount': 90,\n"," 'higham': 91,\n"," 'escadrille': 92,\n"," 'completes': 93,\n"," 'sarro': 94,\n"," 'heartpounding': 95,\n"," 'orleans': 96,\n"," 'herbivores': 97,\n"," 'ailtan': 98,\n"," 'hither': 99,\n"," 'bizniss': 100,\n"," 'banco': 101,\n"," 'tughlaq': 102,\n"," 'grimstead': 103,\n"," 'murmur': 104,\n"," 'savitch': 105,\n"," 'rebels': 106,\n"," 'relation': 107,\n"," 'pessimistic': 108,\n"," 'trampling': 109,\n"," 'materially': 110,\n"," 'matchup': 111,\n"," 'electrons': 112,\n"," 'matchstick': 113,\n"," 'trekdeep': 114,\n"," 'bits': 115,\n"," 'miyako': 116,\n"," 'havoc': 117,\n"," 'careys': 118,\n"," 'glovers': 119,\n"," 'guidance': 120,\n"," 'spite': 121,\n"," 'alvin': 122,\n"," 'mcgann': 123,\n"," 'slats': 124,\n"," 'banana': 125,\n"," 'balearic': 126,\n"," 'crasher': 127,\n"," 'masquerading': 128,\n"," 'menfolk': 129,\n"," 'oriented': 130,\n"," 'cebuano': 131,\n"," 'coherency': 132,\n"," 'hexploitation': 133,\n"," 'irredeemable': 134,\n"," 'giraffe': 135,\n"," 'saleslady': 136,\n"," 'plum': 137,\n"," 'wollter': 138,\n"," 'nother': 139,\n"," 'sookie': 140,\n"," 'garners': 141,\n"," 'uppermost': 142,\n"," 'irritated': 143,\n"," 'biarkan': 144,\n"," 'grappled': 145,\n"," 'balanchine': 146,\n"," 'stromboli': 147,\n"," 'throughing': 148,\n"," 'reboots': 149,\n"," 'mayne': 150,\n"," 'ezzat': 151,\n"," 'mingle': 152,\n"," 'strode': 153,\n"," 'cw': 154,\n"," 'groin': 155,\n"," 'alyce': 156,\n"," 'warmest': 157,\n"," 'deth': 158,\n"," 'seasoned': 159,\n"," 'thaws': 160,\n"," 'premonition': 161,\n"," 'colorfully': 162,\n"," 'crazies': 163,\n"," 'reve': 164,\n"," 'buffered': 165,\n"," 'abut': 166,\n"," 'improvement': 167,\n"," 'salisbury': 168,\n"," 'curiousity': 169,\n"," 'borrowing': 170,\n"," 'sampled': 171,\n"," 'mooching': 172,\n"," 'guarded': 173,\n"," 'grayce': 174,\n"," 'activating': 175,\n"," 'comprehended': 176,\n"," 'dummies': 177,\n"," 'technicolour': 178,\n"," 'weirdness': 179,\n"," 'slitting': 180,\n"," 'stowe': 181,\n"," 'orderd': 182,\n"," 'bookworm': 183,\n"," 'scholars': 184,\n"," 'request': 185,\n"," 'rona': 186,\n"," 'beaver': 187,\n"," 'invesment': 188,\n"," 'associations': 189,\n"," 'liszt': 190,\n"," 'vandenberg': 191,\n"," 'tlc': 192,\n"," 'barrio': 193,\n"," 'sweet': 194,\n"," 'wordless': 195,\n"," 'amigos': 196,\n"," 'mooted': 197,\n"," 'grasps': 198,\n"," 'lethargy': 199,\n"," 'noor': 200,\n"," 'pt': 201,\n"," 'quatier': 202,\n"," 'abuelita': 203,\n"," 'juices': 204,\n"," 'gurukant': 205,\n"," 'eek': 206,\n"," 'hilarious': 207,\n"," 'cauldron': 208,\n"," 'overnight': 209,\n"," 'peckenpah': 210,\n"," 'rothrock': 211,\n"," 'curiously': 212,\n"," 'mishaps': 213,\n"," 'beethtoven': 214,\n"," 'micael': 215,\n"," 'wheeler': 216,\n"," 'ahhhhhh': 217,\n"," 'olaf': 218,\n"," 'lunacy': 219,\n"," 'jinn': 220,\n"," 'worshiped': 221,\n"," 'sorte': 222,\n"," 'ansen': 223,\n"," 'dildo': 224,\n"," 'refreshingly': 225,\n"," 'ruggedly': 226,\n"," 'nominates': 227,\n"," 'conserved': 228,\n"," 'organizing': 229,\n"," 'aji': 230,\n"," 'thaxter': 231,\n"," 'retire': 232,\n"," 'ordo': 233,\n"," 'bullfight': 234,\n"," 'resemblence': 235,\n"," 'voil': 236,\n"," 'mark': 237,\n"," 'bloom': 238,\n"," 'misawa': 239,\n"," 'tinder': 240,\n"," 'vile': 241,\n"," 'peugeot': 242,\n"," 'tammi': 243,\n"," 'beefed': 244,\n"," 'mumbler': 245,\n"," 'unambiguously': 246,\n"," 'anxiously': 247,\n"," 'up': 248,\n"," 'synopses': 249,\n"," 'vainglorious': 250,\n"," 'singhs': 251,\n"," 'deadens': 252,\n"," 'downloaders': 253,\n"," 'safe': 254,\n"," 'indignity': 255,\n"," 'simpleminded': 256,\n"," 'hallan': 257,\n"," 'earns': 258,\n"," 'mayoral': 259,\n"," 'benton': 260,\n"," 'incinerate': 261,\n"," 'charactures': 262,\n"," 'higly': 263,\n"," 'perspicacious': 264,\n"," 'mamabolo': 265,\n"," 'unheard': 266,\n"," 'catapulted': 267,\n"," 'badie': 268,\n"," 'thomajan': 269,\n"," 'phenomenons': 270,\n"," 'unsubstantial': 271,\n"," 'goodall': 272,\n"," 'verandah': 273,\n"," 'presses': 274,\n"," 'constructing': 275,\n"," 'atmosphereic': 276,\n"," 'cubbi': 277,\n"," 'marushka': 278,\n"," 'wrapping': 279,\n"," 'diverted': 280,\n"," 'trounce': 281,\n"," 'masterton': 282,\n"," 'crab': 283,\n"," 'watchable': 284,\n"," 'nearby': 285,\n"," 'neighbour': 286,\n"," 'occuped': 287,\n"," 'kafkaesque': 288,\n"," 'pageant': 289,\n"," 'rokkuchan': 290,\n"," 'vichy': 291,\n"," 'appalling': 292,\n"," 'terkovsky': 293,\n"," 'destructo': 294,\n"," 'comedys': 295,\n"," 'urbisci': 296,\n"," 'demean': 297,\n"," 'puny': 298,\n"," 'americanised': 299,\n"," 'disintegrating': 300,\n"," 'sher': 301,\n"," 'nuzzles': 302,\n"," 'dodekakuple': 303,\n"," 'gaming': 304,\n"," 'ruined': 305,\n"," 'virtually': 306,\n"," 'menstruation': 307,\n"," 'stickler': 308,\n"," 'desaturate': 309,\n"," 'vato': 310,\n"," 'scaley': 311,\n"," 'this': 312,\n"," 'putty': 313,\n"," 'coneheads': 314,\n"," 'greatly': 315,\n"," 'nemec': 316,\n"," 'bliss': 317,\n"," 'sympathizing': 318,\n"," 'docos': 319,\n"," 'purples': 320,\n"," 'witchblade': 321,\n"," 'brothel': 322,\n"," 'piggy': 323,\n"," 'firefly': 324,\n"," 'hookers': 325,\n"," 'frustrations': 326,\n"," 'slaughtering': 327,\n"," 'knoller': 328,\n"," 'protest': 329,\n"," 'inhaler': 330,\n"," 'unawares': 331,\n"," 'factions': 332,\n"," 'encyclopidie': 333,\n"," 'tenacity': 334,\n"," 'boffo': 335,\n"," 'movieeven': 336,\n"," 'clory': 337,\n"," 'coolness': 338,\n"," 'deafening': 339,\n"," 'phisique': 340,\n"," 'frankenscience': 341,\n"," 'snippers': 342,\n"," 'chompers': 343,\n"," 'coterie': 344,\n"," 'charu': 345,\n"," 'uncompelling': 346,\n"," 'facets': 347,\n"," 'validate': 348,\n"," 'wai': 349,\n"," 'videodisc': 350,\n"," 'deaf': 351,\n"," 'ouedraogo': 352,\n"," 'benumbed': 353,\n"," 'deedlit': 354,\n"," 'prudence': 355,\n"," 'lester': 356,\n"," 'vivants': 357,\n"," 'ambling': 358,\n"," 'crowbar': 359,\n"," 'tears': 360,\n"," 'seinfield': 361,\n"," 'brands': 362,\n"," 'subnormal': 363,\n"," 'clmenti': 364,\n"," 'splinter': 365,\n"," 'empower': 366,\n"," 'camouflaged': 367,\n"," 'pandemic': 368,\n"," 'immorally': 369,\n"," 'blatch': 370,\n"," 'ritterkreuz': 371,\n"," 'katch': 372,\n"," 'lapses': 373,\n"," 'savanna': 374,\n"," 'sly': 375,\n"," 'lemoraa': 376,\n"," 'youthfulness': 377,\n"," 'analytical': 378,\n"," 'originate': 379,\n"," 'macrabe': 380,\n"," 'primetime': 381,\n"," 'grilo': 382,\n"," 'mendel': 383,\n"," 'prairies': 384,\n"," 'wonderfalls': 385,\n"," 'strut': 386,\n"," 'flesh': 387,\n"," 'crackpot': 388,\n"," 'waterboy': 389,\n"," 'sucessful': 390,\n"," 'over': 391,\n"," 'explainable': 392,\n"," 'fer': 393,\n"," 'compromised': 394,\n"," 'unconnected': 395,\n"," 'grumpier': 396,\n"," 'difford': 397,\n"," 'escalation': 398,\n"," 'answering': 399,\n"," 'bound': 400,\n"," 'enzyme': 401,\n"," 'discomusic': 402,\n"," 'darstardy': 403,\n"," 'aproned': 404,\n"," 'outnumbers': 405,\n"," 'picnicking': 406,\n"," 'distributors': 407,\n"," 'sttos': 408,\n"," 'fijian': 409,\n"," 'aerial': 410,\n"," 'rushed': 411,\n"," 'theyre': 412,\n"," 'breasts': 413,\n"," 'emulated': 414,\n"," 'anyway': 415,\n"," 'ironsides': 416,\n"," 'westley': 417,\n"," 'inflections': 418,\n"," 'unbilled': 419,\n"," 'involuntary': 420,\n"," 'elainor': 421,\n"," 'dass': 422,\n"," 'discipline': 423,\n"," 'restitution': 424,\n"," 'wallachchristopher': 425,\n"," 'gala': 426,\n"," 'sydow': 427,\n"," 'entombment': 428,\n"," 'tipps': 429,\n"," 'foundational': 430,\n"," 'hawks': 431,\n"," 'standards': 432,\n"," 'technician': 433,\n"," 'consummation': 434,\n"," 'hurtles': 435,\n"," 'eves': 436,\n"," 'shingles': 437,\n"," 'extinguisher': 438,\n"," 'fruedian': 439,\n"," 'mallorquins': 440,\n"," 'dsire': 441,\n"," 'materializer': 442,\n"," 'funnel': 443,\n"," 'hunt': 444,\n"," 'weightlifting': 445,\n"," 'wusa': 446,\n"," 'settee': 447,\n"," 'charendoff': 448,\n"," 'mild': 449,\n"," 'loony': 450,\n"," 'kampen': 451,\n"," 'my': 452,\n"," 'lex': 453,\n"," 'inequality': 454,\n"," 'technologist': 455,\n"," 'crocks': 456,\n"," 'sel': 457,\n"," 'silvano': 458,\n"," 'pelting': 459,\n"," 'fictionalising': 460,\n"," 'torturro': 461,\n"," 'embarassing': 462,\n"," 'unpatriotic': 463,\n"," 'watchosky': 464,\n"," 'during': 465,\n"," 'rotter': 466,\n"," 'unconditional': 467,\n"," 'objectiveness': 468,\n"," 'balooned': 469,\n"," 'unbeatable': 470,\n"," 'pleasently': 471,\n"," 'vegetating': 472,\n"," 'goodfellas': 473,\n"," 'executioners': 474,\n"," 'cinemaphotography': 475,\n"," 'chic': 476,\n"," 'ginny': 477,\n"," 'deliberately': 478,\n"," 'uears': 479,\n"," 'yourself': 480,\n"," 'atheism': 481,\n"," 'hahn': 482,\n"," 'incubus': 483,\n"," 'unanticipated': 484,\n"," 'emperor': 485,\n"," 'merchants': 486,\n"," 'coveted': 487,\n"," 'el': 488,\n"," 'grow': 489,\n"," 'mantis': 490,\n"," 'osment': 491,\n"," 'illudere': 492,\n"," 'crapulastic': 493,\n"," 'gibberish': 494,\n"," 'serrano': 495,\n"," 'curtain': 496,\n"," 'atem': 497,\n"," 'triumphs': 498,\n"," 'louvre': 499,\n"," 'airstrip': 500,\n"," 'rachael': 501,\n"," 'spinning': 502,\n"," 'dismembering': 503,\n"," 'permit': 504,\n"," 'leia': 505,\n"," 'weta': 506,\n"," 'harmed': 507,\n"," 'smartassy': 508,\n"," 'skinhead': 509,\n"," 'expresion': 510,\n"," 'verne': 511,\n"," 'clap': 512,\n"," 'urdhu': 513,\n"," 'cutscenes': 514,\n"," 'strolling': 515,\n"," 'farrely': 516,\n"," 'unisten': 517,\n"," 'pumb': 518,\n"," 'gu': 519,\n"," 'unfunnily': 520,\n"," 'sumire': 521,\n"," 'grady': 522,\n"," 'calculate': 523,\n"," 'mapping': 524,\n"," 'glam': 525,\n"," 'sitting': 526,\n"," 'leisen': 527,\n"," 'lowers': 528,\n"," 'scrawny': 529,\n"," 'eragorn': 530,\n"," 'klum': 531,\n"," 'viru': 532,\n"," 'winslet': 533,\n"," 'katic': 534,\n"," 'married': 535,\n"," 'tanger': 536,\n"," 'pufnstuf': 537,\n"," 'croydon': 538,\n"," 'counterbalanced': 539,\n"," 'romping': 540,\n"," 'arctic': 541,\n"," 'ohtar': 542,\n"," 'mankinds': 543,\n"," 'medias': 544,\n"," 'usaffe': 545,\n"," 'sachin': 546,\n"," 'ceiling': 547,\n"," 'limbs': 548,\n"," 'rummaging': 549,\n"," 'avalanches': 550,\n"," 'seminara': 551,\n"," 'tac': 552,\n"," 'joey': 553,\n"," 'clu': 554,\n"," 'dagoba': 555,\n"," 'pembrook': 556,\n"," 'externally': 557,\n"," 'customary': 558,\n"," 'roxy': 559,\n"," 'blobs': 560,\n"," 'revive': 561,\n"," 'siri': 562,\n"," 'resort': 563,\n"," 'gentry': 564,\n"," 'cgs': 565,\n"," 'florence': 566,\n"," 'harmtriumph': 567,\n"," 'francine': 568,\n"," 'sterilized': 569,\n"," 'hoped': 570,\n"," 'istanbul': 571,\n"," 'impervious': 572,\n"," 'adelaide': 573,\n"," 'pranksters': 574,\n"," 'derivatives': 575,\n"," 'whoopdedoodles': 576,\n"," 'kuala': 577,\n"," 'clarksburg': 578,\n"," 'darr': 579,\n"," 'upa': 580,\n"," 'becouse': 581,\n"," 'reb': 582,\n"," 'favor': 583,\n"," 'erotica': 584,\n"," 'implement': 585,\n"," 'saat': 586,\n"," 'eeuurrgghh': 587,\n"," 'draught': 588,\n"," 'jovan': 589,\n"," 'criticisers': 590,\n"," 'peruse': 591,\n"," 'quotable': 592,\n"," 'disase': 593,\n"," 'prospect': 594,\n"," 'soooooo': 595,\n"," 'sick': 596,\n"," 'arguments': 597,\n"," 'harassed': 598,\n"," 'cuckold': 599,\n"," 'flipping': 600,\n"," 'agreeing': 601,\n"," 'hatosy': 602,\n"," 'revise': 603,\n"," 'improvise': 604,\n"," 'inspecting': 605,\n"," 'stringing': 606,\n"," 'traitors': 607,\n"," 'terrence': 608,\n"," 'mssr': 609,\n"," 'similarities': 610,\n"," 'braik': 611,\n"," 'conserving': 612,\n"," 'tunics': 613,\n"," 'aflame': 614,\n"," 'joiner': 615,\n"," 'checkbook': 616,\n"," 'magon': 617,\n"," 'inevitable': 618,\n"," 'boatswain': 619,\n"," 'grindhouses': 620,\n"," 'oracle': 621,\n"," 'estevez': 622,\n"," 'amasses': 623,\n"," 'punster': 624,\n"," 'healthier': 625,\n"," 'emissary': 626,\n"," 'sentiment': 627,\n"," 'excavations': 628,\n"," 'connerey': 629,\n"," 'mayhem': 630,\n"," 'studies': 631,\n"," 'estelle': 632,\n"," 'husks': 633,\n"," 'barnyard': 634,\n"," 'hallier': 635,\n"," 'harmony': 636,\n"," 'boltay': 637,\n"," 'alcott': 638,\n"," 'grod': 639,\n"," 'anaglyph': 640,\n"," 'zira': 641,\n"," 'dinsdale': 642,\n"," 'outerspace': 643,\n"," 'egyptin': 644,\n"," 'levy': 645,\n"," 'alteration': 646,\n"," 'wagter': 647,\n"," 'destination': 648,\n"," 'scarlatti': 649,\n"," 'levelheaded': 650,\n"," 'wcw': 651,\n"," 'rigorously': 652,\n"," 'nipar': 653,\n"," 'chautard': 654,\n"," 'flushes': 655,\n"," 'saturated': 656,\n"," 'vani': 657,\n"," 'inna': 658,\n"," 'latest': 659,\n"," 'abstinence': 660,\n"," 'numbs': 661,\n"," 'unfortunatly': 662,\n"," 'ahh': 663,\n"," 'brutish': 664,\n"," 'vietcong': 665,\n"," 'lynched': 666,\n"," 'responsability': 667,\n"," 'pakis': 668,\n"," 'kobayashis': 669,\n"," 'morvern': 670,\n"," 'mattes': 671,\n"," 'despite': 672,\n"," 'admirer': 673,\n"," 'shooting': 674,\n"," 'lambasting': 675,\n"," 'jmv': 676,\n"," 'carlise': 677,\n"," 'marquand': 678,\n"," 'washing': 679,\n"," 'mesoamericans': 680,\n"," 'amma': 681,\n"," 'fumbled': 682,\n"," 'medicinal': 683,\n"," 'disparagement': 684,\n"," 'rienforcation': 685,\n"," 'leporidae': 686,\n"," 'sabotages': 687,\n"," 'beaches': 688,\n"," 'pictorially': 689,\n"," 'tinges': 690,\n"," 'gorefest': 691,\n"," 'okavango': 692,\n"," 'tenterhooks': 693,\n"," 'innane': 694,\n"," 'pineapples': 695,\n"," 'tuous': 696,\n"," 'shirely': 697,\n"," 'lamonte': 698,\n"," 'wrenchingly': 699,\n"," 'cleverless': 700,\n"," 'lamppost': 701,\n"," 'felecia': 702,\n"," 'wince': 703,\n"," 'viciously': 704,\n"," 'suppress': 705,\n"," 'sicko': 706,\n"," 'menage': 707,\n"," 'goggle': 708,\n"," 'espe': 709,\n"," 'amicable': 710,\n"," 'richart': 711,\n"," 'binkie': 712,\n"," 'bottin': 713,\n"," 'zowee': 714,\n"," 'zapped': 715,\n"," 'manner': 716,\n"," 'descovered': 717,\n"," 'chitchat': 718,\n"," 'created': 719,\n"," 'appetite': 720,\n"," 'foreplay': 721,\n"," 'foolproof': 722,\n"," 'set': 723,\n"," 'deodatto': 724,\n"," 'undetectable': 725,\n"," 'yoghurt': 726,\n"," 'horrifies': 727,\n"," 'verson': 728,\n"," 'noche': 729,\n"," 'ratatouille': 730,\n"," 'beachfront': 731,\n"," 'grasshoppers': 732,\n"," 'dehumanizes': 733,\n"," 'waltzes': 734,\n"," 'desperation': 735,\n"," 'infos': 736,\n"," 'goomba': 737,\n"," 'quantico': 738,\n"," 'donato': 739,\n"," 'consenting': 740,\n"," 'modus': 741,\n"," 'palate': 742,\n"," 'tiresome': 743,\n"," 'madhubala': 744,\n"," 'loom': 745,\n"," 'camouflage': 746,\n"," 'evinces': 747,\n"," 'orry': 748,\n"," 'mayweather': 749,\n"," 'diversified': 750,\n"," 'olds': 751,\n"," 'rhetorician': 752,\n"," 'harassment': 753,\n"," 'proclaiming': 754,\n"," 'fleecing': 755,\n"," 'aya': 756,\n"," 'bayonet': 757,\n"," 'toni': 758,\n"," 'proceed': 759,\n"," 'reily': 760,\n"," 'delmer': 761,\n"," 'poitier': 762,\n"," 'shire': 763,\n"," 'venerate': 764,\n"," 'fleeing': 765,\n"," 'mugged': 766,\n"," 'adapting': 767,\n"," 'temptingly': 768,\n"," 'sachdev': 769,\n"," 'cyclist': 770,\n"," 'shirou': 771,\n"," 'bedraggled': 772,\n"," 'fuhrer': 773,\n"," 'tanga': 774,\n"," 'itunes': 775,\n"," 'tarazu': 776,\n"," 'clmence': 777,\n"," 'rance': 778,\n"," 'henrikson': 779,\n"," 'duhs': 780,\n"," 'pooh': 781,\n"," 'cyberspace': 782,\n"," 'grope': 783,\n"," 'mezrich': 784,\n"," 'gangly': 785,\n"," 'subjecting': 786,\n"," 'galleries': 787,\n"," 'fundamentals': 788,\n"," 'ordination': 789,\n"," 'fuchsberger': 790,\n"," 'prostate': 791,\n"," 'elicot': 792,\n"," 'tawa': 793,\n"," 'darnedest': 794,\n"," 'urecal': 795,\n"," 'bahumbag': 796,\n"," 'japes': 797,\n"," 'misfire': 798,\n"," 'lenge': 799,\n"," 'damningly': 800,\n"," 'madhuri': 801,\n"," 'valdez': 802,\n"," 'serbs': 803,\n"," 'motorboat': 804,\n"," 'examplary': 805,\n"," 'sienna': 806,\n"," 'swaps': 807,\n"," 'nite': 808,\n"," 'cimino': 809,\n"," 'nymphomania': 810,\n"," 'workshop': 811,\n"," 'bumblebum': 812,\n"," 'delivered': 813,\n"," 'casnoff': 814,\n"," 'sole': 815,\n"," 'dagon': 816,\n"," 'medal': 817,\n"," 'overstyling': 818,\n"," 'fawning': 819,\n"," 'kicha': 820,\n"," 'cohesive': 821,\n"," 'humanitas': 822,\n"," 'mopes': 823,\n"," 'hitlists': 824,\n"," 'propagates': 825,\n"," 'understand': 826,\n"," 'televangelist': 827,\n"," 'conversations': 828,\n"," 'loyal': 829,\n"," 'molasses': 830,\n"," 'rapper': 831,\n"," 'induced': 832,\n"," 'symphonies': 833,\n"," 'amara': 834,\n"," 'deepak': 835,\n"," 'drawn': 836,\n"," 'retellings': 837,\n"," 'unacurate': 838,\n"," 'abdul': 839,\n"," 'disappoints': 840,\n"," 'strangler': 841,\n"," 'areas': 842,\n"," 'idiosyncratically': 843,\n"," 'lehrman': 844,\n"," 'burbank': 845,\n"," 'dunham': 846,\n"," 'preens': 847,\n"," 'newswriter': 848,\n"," 'tumour': 849,\n"," 'dhiraj': 850,\n"," 'mola': 851,\n"," 'compile': 852,\n"," 'nevermore': 853,\n"," 'adolf': 854,\n"," 'underscripted': 855,\n"," 'defilement': 856,\n"," 'shoot': 857,\n"," 'mccaughan': 858,\n"," 'suckered': 859,\n"," 'amorphous': 860,\n"," 'petrn': 861,\n"," 'reaso': 862,\n"," 'mcreedy': 863,\n"," 'grandes': 864,\n"," 'shead': 865,\n"," 'scalped': 866,\n"," 'clues': 867,\n"," 'mancori': 868,\n"," 'persuading': 869,\n"," 'pertwees': 870,\n"," 'rubano': 871,\n"," 'dissuade': 872,\n"," 'isint': 873,\n"," 'kajawari': 874,\n"," 'ramps': 875,\n"," 'vouched': 876,\n"," 'granter': 877,\n"," 'physicist': 878,\n"," 'tros': 879,\n"," 'samways': 880,\n"," 'prays': 881,\n"," 'azimov': 882,\n"," 'migrations': 883,\n"," 'unresisting': 884,\n"," 'internalist': 885,\n"," 'digger': 886,\n"," 'slobbery': 887,\n"," 'batarda': 888,\n"," 'jardyce': 889,\n"," 'infecting': 890,\n"," 'acrobat': 891,\n"," 'harvard': 892,\n"," 'karva': 893,\n"," 'cyber': 894,\n"," 'romanced': 895,\n"," 'spree': 896,\n"," 'sketch': 897,\n"," 'swashbucklers': 898,\n"," 'epater': 899,\n"," 'disintegration': 900,\n"," 'foods': 901,\n"," 'intruders': 902,\n"," 'zipped': 903,\n"," 'ancients': 904,\n"," 'metropoly': 905,\n"," 'bachlor': 906,\n"," 'contest': 907,\n"," 'barsat': 908,\n"," 'fluctuations': 909,\n"," 'rocked': 910,\n"," 'imbue': 911,\n"," 'caldicott': 912,\n"," 'inversely': 913,\n"," 'eye': 914,\n"," 'periods': 915,\n"," 'viviane': 916,\n"," 'navarre': 917,\n"," 'blackend': 918,\n"," 'prize': 919,\n"," 'shortland': 920,\n"," 'crimefighting': 921,\n"," 'howarth': 922,\n"," 'seagulls': 923,\n"," 'aired': 924,\n"," 'beckinsale': 925,\n"," 'caterers': 926,\n"," 'picasso': 927,\n"," 'karlsson': 928,\n"," 'africa': 929,\n"," 'frustrationfest': 930,\n"," 'tami': 931,\n"," 'roughneck': 932,\n"," 'synonomous': 933,\n"," 'sweltering': 934,\n"," 'intermingle': 935,\n"," 'haggle': 936,\n"," 'ainley': 937,\n"," 'cutely': 938,\n"," 'surer': 939,\n"," 'artbox': 940,\n"," 'libretto': 941,\n"," 'moodily': 942,\n"," 'spiteful': 943,\n"," 'untie': 944,\n"," 'layover': 945,\n"," 'himalayas': 946,\n"," 'tohma': 947,\n"," 'kiddies': 948,\n"," 'disharmonious': 949,\n"," 'froth': 950,\n"," 'punch': 951,\n"," 'geritan': 952,\n"," 'trodden': 953,\n"," 'lumberjack': 954,\n"," 'characterless': 955,\n"," 'guayabera': 956,\n"," 'devgans': 957,\n"," 'opaqueness': 958,\n"," 'unsaid': 959,\n"," 'talladega': 960,\n"," 'overdid': 961,\n"," 'warmhearted': 962,\n"," 'scholarly': 963,\n"," 'politicization': 964,\n"," 'redeaming': 965,\n"," 'parvenu': 966,\n"," 'danzel': 967,\n"," 'bostid': 968,\n"," 'nintendo': 969,\n"," 'winterbolt': 970,\n"," 'kicky': 971,\n"," 'suiters': 972,\n"," 'ans': 973,\n"," 'santell': 974,\n"," 'nore': 975,\n"," 'gents': 976,\n"," 'peracaula': 977,\n"," 'atypical': 978,\n"," 'moors': 979,\n"," 'outcroppings': 980,\n"," 'fastidiously': 981,\n"," 'padruig': 982,\n"," 'subversions': 983,\n"," 'ribbons': 984,\n"," 'goeffrey': 985,\n"," 'ldssingles': 986,\n"," 'puffy': 987,\n"," 'somersault': 988,\n"," 'compelling': 989,\n"," 'sighted': 990,\n"," 'desserts': 991,\n"," 'nauseates': 992,\n"," 'dedicates': 993,\n"," 'procreating': 994,\n"," 'summation': 995,\n"," 'erect': 996,\n"," 'speer': 997,\n"," 'buddwing': 998,\n"," 'navokov': 999,\n"," ...}"]},"metadata":{},"execution_count":27}],"metadata":{"id":"V-hI78bnNFlp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337040698,"user_tz":300,"elapsed":97,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"009986c9-01c6-454f-fa46-5c2422191573"}},{"cell_type":"markdown","source":["**TODO:**  Complete the implementation of `update_input_layer`. It should count \n","          how many times each word is used in the given review, and then store\n","          those counts at the appropriate indices inside `layer_0`."],"metadata":{"id":"Wb5cxMn5NFlp"}},{"cell_type":"code","execution_count":null,"source":["def update_input_layer(review):\r\n","    \"\"\" Modify the global layer_0 to represent the vector form of review.\r\n","    The element at a given index of layer_0 should represent\r\n","    how many times the given word occurs in the review.\r\n","    Args:\r\n","        review(string) - the string of the review\r\n","    Returns:\r\n","        None\r\n","    \"\"\"\r\n","    global layer_0\r\n","    # clear out previous state by resetting the layer to be all 0s\r\n","    layer_0 *= 0\r\n","    \r\n","    # TODO: count how many times each word is used in the given review and store the results in layer_0\r\n","    counter = Counter(review.split(' '))\r\n","    for word in counter:\r\n","        word_index = word2index[word]\r\n","        layer_0[0,word_index] = counter[word]"],"outputs":[],"metadata":{"collapsed":true,"id":"wTYXlfFoNFlp"}},{"cell_type":"markdown","source":["Run the following cell to test updating the input layer with the first review. The indices assigned may not be the same as in the solution, but hopefully you'll see some non-zero values in `layer_0`.  "],"metadata":{"id":"fUS0FtcNNFlp"}},{"cell_type":"code","execution_count":null,"source":["update_input_layer(reviews[0])\r\n","layer_0"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[18.,  0.,  0., ...,  0.,  0.,  0.]])"]},"metadata":{},"execution_count":29}],"metadata":{"id":"nYUGGnlJNFlq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337040699,"user_tz":300,"elapsed":87,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"84da79d4-2e96-4821-9423-1d2597403a27"}},{"cell_type":"markdown","source":["**TODO:** Complete the implementation of `get_target_for_labels`. It should return `0` or `1`, \n","          depending on whether the given label is `NEGATIVE` or `POSITIVE`, respectively."],"metadata":{"id":"SCapP0TPNFlq"}},{"cell_type":"code","execution_count":null,"source":["def get_target_for_label(label):\r\n","    \"\"\"Convert a label to `0` or `1`.\r\n","    Args:\r\n","        label(string) - Either \"POSITIVE\" or \"NEGATIVE\".\r\n","    Returns:\r\n","        `0` or `1`.\r\n","    \"\"\"\r\n","    # TODO: Your code here\r\n","    return 0 if label == 'NEGATIVE' else 1"],"outputs":[],"metadata":{"collapsed":true,"id":"QFIZSViONFlq"}},{"cell_type":"markdown","source":["Run the following two cells. They should print out`'POSITIVE'` and `1`, respectively."],"metadata":{"id":"Wz-Ze4opNFlq"}},{"cell_type":"code","execution_count":null,"source":["labels[0]"],"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'POSITIVE'"]},"metadata":{},"execution_count":31}],"metadata":{"id":"6ZnNcdJtNFlq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337040701,"user_tz":300,"elapsed":86,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"7a7e9f8e-ae92-4425-8e29-73a7957556b6"}},{"cell_type":"code","execution_count":null,"source":["get_target_for_label(labels[0])"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":32}],"metadata":{"id":"0BZ2daHHNFlq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337040702,"user_tz":300,"elapsed":84,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"7d41894b-a8ec-4648-bb6c-57374652750a"}},{"cell_type":"markdown","source":["Run the following two cells. They should print out `'NEGATIVE'` and `0`, respectively."],"metadata":{"id":"RJqg87lzNFlr"}},{"cell_type":"code","execution_count":null,"source":["labels[1]"],"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'NEGATIVE'"]},"metadata":{},"execution_count":33}],"metadata":{"id":"uzS6FCBZNFlr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337040702,"user_tz":300,"elapsed":82,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"e02d2b6f-f346-40c4-e05d-400fc4f9a276"}},{"cell_type":"code","execution_count":null,"source":["get_target_for_label(labels[1])"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":34}],"metadata":{"id":"6Mf2cfLiNFlr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337040703,"user_tz":300,"elapsed":80,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"6c9d3835-f50e-4300-fcd4-e400d7a9a3cc"}},{"cell_type":"markdown","source":["# End of Project 2. \n"],"metadata":{"id":"Ur2aGCM7NFlr"}},{"cell_type":"markdown","source":["# Project 3: Building a Neural Network<a id='project_3'></a>\n","\n","Antes de entrar a detalles, veamos un modelo similar en keras"],"metadata":{"id":"9gNosdhLNFlr"}},{"cell_type":"code","execution_count":null,"source":["import tensorflow as tf\r\n","\r\n","red_neuronal = tf.keras.models.Sequential([\r\n","    tf.keras.layers.Dense(units = 10,activation=\"sigmoid\",kernel_initializer=tf.keras.initializers.GlorotNormal()),\r\n","    tf.keras.layers.Dense(units = 1,activation=\"sigmoid\",kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01))\r\n","])"],"outputs":[],"metadata":{"id":"6FtLySUjXppj"}},{"cell_type":"code","execution_count":null,"source":["red_neuronal.compile(optimizer=\"sgd\",loss=\"categorical_crossentropy\")"],"outputs":[],"metadata":{"id":"djsIYED7YjTX"}},{"cell_type":"markdown","source":["**TODO:** We've included the framework of a class called `SentimentNetork`. Implement all of the items marked `TODO` in the code. These include doing the following:\n","- Create a basic neural network much like the networks you've seen in earlier lessons and in Project 1, with an input layer, a hidden layer, and an output layer. \n","- Do **not** add a non-linearity in the hidden layer. That is, do not use an activation function when calculating the hidden layer outputs.\n","- Re-use the code from earlier in this notebook to create the training data (see `TODO`s in the code)\n","- Implement the `pre_process_data` function to create the vocabulary for our training data generating functions\n","- Ensure `train` trains over the entire corpus"],"metadata":{"id":"4Y5BgvboNFlr"}},{"cell_type":"code","execution_count":null,"source":["import time\r\n","import sys\r\n","import numpy as np\r\n","\r\n","# Encapsulate our neural network in a class\r\n","class SentimentNetwork:\r\n","    def __init__(self, reviews, labels, hidden_nodes = 10, learning_rate = 0.1):\r\n","        \"\"\"Create a SentimenNetwork with the given settings\r\n","        Args:\r\n","            reviews(list) - List of reviews used for training\r\n","            labels(list) - List of POSITIVE/NEGATIVE labels associated with the given reviews\r\n","            hidden_nodes(int) - Number of nodes to create in the hidden layer\r\n","            learning_rate(float) - Learning rate to use while training\r\n","        \r\n","        \"\"\"\r\n","        # Assign a seed to our random number generator to ensure we get\r\n","        # reproducable results during development \r\n","        np.random.seed(1)\r\n","\r\n","        # process the reviews and their associated labels so that everything\r\n","        # is ready for training\r\n","        self.pre_process_data(reviews, labels)\r\n","        \r\n","        # Build the network to have the number of hidden nodes and the learning rate that\r\n","        # were passed into this initializer. Make the same number of input nodes as\r\n","        # there are vocabulary words and create a single output node.\r\n","        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\r\n","\r\n","    def pre_process_data(self, reviews, labels):\r\n","        \r\n","        review_vocab = set()\r\n","        # TODO: populate review_vocab with all of the words in the given reviews\r\n","        #       Remember to split reviews into individual words \r\n","        #       using \"split(' ')\" instead of \"split()\".\r\n","        \r\n","        for review in reviews:\r\n","            words = review.split(' ')\r\n","            for word in words:\r\n","                review_vocab.add(word)\r\n","        # Convert the vocabulary set to a list so we can access words via indices\r\n","        self.review_vocab = list(review_vocab)\r\n","        \r\n","        label_vocab = set()\r\n","        # TODO: populate label_vocab with all of the words in the given labels.\r\n","        #       There is no need to split the labels because each one is a single word.\r\n","        \r\n","        for label in labels:\r\n","            label_vocab.add(label)\r\n","        # Convert the label vocabulary set to a list so we can access labels via indices\r\n","        self.label_vocab = list(label_vocab)\r\n","        \r\n","        # Store the sizes of the review and label vocabularies.\r\n","        self.review_vocab_size = len(self.review_vocab)\r\n","        self.label_vocab_size = len(self.label_vocab)\r\n","        \r\n","        # Create a dictionary of words in the vocabulary mapped to index positions\r\n","        self.word2index = {}\r\n","        # TODO: populate self.word2index with indices for all the words in self.review_vocab\r\n","        #       like you saw earlier in the notebook\r\n","        for index,word in enumerate(self.review_vocab):\r\n","            self.word2index[word] = index\r\n","        # Create a dictionary of labels mapped to index positions\r\n","        self.label2index = {}\r\n","        # TODO: do the same thing you did for self.word2index and self.review_vocab, \r\n","        #       but for self.label2index and self.label_vocab instead\r\n","        for index,label in enumerate(self.label_vocab):\r\n","            self.label2index[label] = index\r\n","            \r\n","        \r\n","    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\r\n","        # Store the number of nodes in input, hidden, and output layers.\r\n","        self.input_nodes = input_nodes\r\n","        self.hidden_nodes = hidden_nodes\r\n","        self.output_nodes = output_nodes\r\n","\r\n","        # Store the learning rate\r\n","        self.learning_rate = learning_rate\r\n","\r\n","        # Initialize weights\r\n","        \r\n","        # TODO: initialize self.weights_0_1 as a matrix of zeros. These are the weights between\r\n","        #       the input layer and the hidden layer.\r\n","        self.weights_0_1 = np.random.normal(0.0, np.sqrt(1/input_nodes),\r\n","                                            (input_nodes,hidden_nodes))\r\n","        \r\n","        # TODO: initialize self.weights_1_2 as a matrix of random values. \r\n","        #       These are the weights between the hidden layer and the output layer.\r\n","        self.weights_1_2 = np.random.normal(0.0, np.sqrt(1/hidden_nodes), \r\n","                                                (self.hidden_nodes, self.output_nodes))\r\n","        \r\n","        # TODO: Create the input layer, a two-dimensional matrix with shape \r\n","        #       1 x input_nodes, with all values initialized to zero\r\n","        self.layer_0 = np.zeros((1,input_nodes))\r\n","    \r\n","        \r\n","    def update_input_layer(self,review):\r\n","        # TODO: You can copy most of the code you wrote for update_input_layer \r\n","        #       earlier in this notebook. \r\n","        #\r\n","        #       However, MAKE SURE YOU CHANGE ALL VARIABLES TO REFERENCE\r\n","        #       THE VERSIONS STORED IN THIS OBJECT, NOT THE GLOBAL OBJECTS.\r\n","        #       For example, replace \"layer_0 *= 0\" with \"self.layer_0 *= 0\"\r\n","        self.layer_0*=0\r\n","        counter = Counter(review.split(' '))\r\n","        for word in counter:\r\n","            if word in self.word2index.keys():\r\n","                word_count = counter[word]\r\n","                word_index = self.word2index[word]\r\n","                self.layer_0[0,word_index] = word_count\r\n","                \r\n","    def get_target_for_label(self,label):\r\n","        # TODO: Copy the code you wrote for get_target_for_label \r\n","        #       earlier in this notebook. \r\n","        return 0 if label == 'NEGATIVE' else 1\r\n","        \r\n","    def sigmoid(self,x):\r\n","        # TODO: Return the result of calculating the sigmoid activation function\r\n","        #       shown in the lectures\r\n","        return 1 / ( 1 + np.exp(-x))\r\n","    \r\n","    def sigmoid_output_2_derivative(self,output):\r\n","        # TODO: Return the derivative of the sigmoid activation function, \r\n","        #       where \"output\" is the original output from the sigmoid fucntion \r\n","        return output * (1 - output)\r\n","\r\n","    def sigmoid_prime(self,output):\r\n","        # TODO: Return the derivative of the sigmoid activation function, \r\n","        return output * (1 - output)\r\n","\r\n","\r\n","    def train(self, training_reviews, training_labels):\r\n","        \r\n","        # make sure out we have a matching number of reviews and labels\r\n","        assert(len(training_reviews) == len(training_labels))\r\n","        \r\n","        # Keep track of correct predictions to display accuracy during training \r\n","        correct_so_far = 0\r\n","        \r\n","        # Remember when we started for printing time statistics\r\n","        start = time.time()\r\n","\r\n","        # loop through all the given reviews and run a forward and backward pass,\r\n","        # updating weights for every item\r\n","        for i in range(len(training_reviews)):\r\n","            \r\n","            # TODO: Get the next review and its correct label\r\n","            review = training_reviews[i]\r\n","            label = training_labels[i]\r\n","            # TODO: Implement the forward pass through the network. \r\n","            #       That means use the given review to update the input layer, \r\n","            #       then calculate values for the hidden layer,\r\n","            #       and finally calculate the output layer.\r\n","            # \r\n","            #       Do not use an activation function for the hidden layer,\r\n","            #       but use the sigmoid activation function for the output layer.\r\n","            self.update_input_layer(review)\r\n","            hidden_layer_logits = np.dot(self.layer_0,self.weights_0_1)\r\n","            hidden_layer_output = self.sigmoid(hidden_layer_logits)\r\n","            output_layer_logits = np.dot(hidden_layer_output,self.weights_1_2)\r\n","            output_layer_predictions = self.sigmoid(output_layer_logits)\r\n","            #print(\"output layer\",output_layer_predictions.shape)\r\n","            # TODO: Implement the back propagation pass here. \r\n","            #       That means calculate the error for the forward pass's prediction\r\n","            #       and update the weights in the network according to their\r\n","            #       contributions toward the error, as calculated via the\r\n","            #       gradient descent and back propagation algorithms you \r\n","            #       learned in class.\r\n","            error = output_layer_predictions - self.get_target_for_label(label) # dL/da2(derivada del costo respecto de la salida y_pred)\r\n","            #print(\"error\",error.shape)\r\n","            #calculate the error terms of each layer\r\n","\r\n","            #dL/dz2(derivada del costo respecto de la pre-activacion z2, el termino de error delta2)\r\n","            output_error_term = error*self.sigmoid_prime(output_layer_predictions) \r\n","            #print(\"output error term\",output_error_term.shape)\r\n","            #print(\"sigmoid prime(hidden)\",self.sigmoid_prime(hidden_layer_output).shape)\r\n","\r\n","            # dL/dz1 (derivada del costo respecto de la pre-activacion z1, el termino de error delta1)\r\n","            hidden_error_term = np.matmul(self.weights_1_2,output_error_term)*self.sigmoid_prime(hidden_layer_output).T\r\n","\r\n","            ## una vez calculados los terminos de error delta(derivadas respecto de z) los usamos para calcular las derivadas parciales respecto de los parametros usando #activacion entrante * error saliente\r\n","            grad_weights_h_o =  output_error_term * hidden_layer_output\r\n","            grad_weights_i_h = hidden_error_term * self.layer_0\r\n","\r\n","            ## una vez calculadas las derivadas respecto de los parametros aplicamos \"gradient descent\"\r\n","            self.weights_1_2-= (self.learning_rate*grad_weights_h_o).T\r\n","            self.weights_0_1-= (self.learning_rate*grad_weights_i_h).T\r\n","            # TODO: Keep track of correct predictions. To determine if the prediction was\r\n","            #       correct, check that the absolute value of the output error \r\n","            #       is less than 0.5. If so, add one to the correct_so_far count.\r\n","            #Note to myself: strange way to calc correctness hmmm\r\n","            if  np.abs(error) < 0.5:\r\n","                correct_so_far+=1\r\n","            \r\n","            # For debug purposes, print out our prediction accuracy and speed \r\n","            # throughout the training process. \r\n","\r\n","            elapsed_time = float(time.time() - start)\r\n","            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\r\n","            \r\n","            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] \\\r\n","                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\r\n","                             + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) \\\r\n","                             + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\r\n","            if(i % 2500 == 0):\r\n","                print(\"\")\r\n","    \r\n","    def test(self, testing_reviews, testing_labels):\r\n","        \"\"\"\r\n","        Attempts to predict the labels for the given testing_reviews,\r\n","        and uses the test_labels to calculate the accuracy of those predictions.\r\n","        \"\"\"\r\n","        \r\n","        # keep track of how many correct predictions we make\r\n","        correct = 0\r\n","\r\n","        # we'll time how many predictions per second we make\r\n","        start = time.time()\r\n","\r\n","        # Loop through each of the given reviews and call run to predict\r\n","        # its label. \r\n","        for i in range(len(testing_reviews)):\r\n","            pred = self.run(testing_reviews[i])\r\n","            if(pred == testing_labels[i]):\r\n","                correct += 1\r\n","            \r\n","            # For debug purposes, print out our prediction accuracy and speed \r\n","            # throughout the prediction process. \r\n","\r\n","            elapsed_time = float(time.time() - start)\r\n","            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\r\n","            \r\n","            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\r\n","                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\r\n","                             + \" #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) \\\r\n","                             + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\r\n","    \r\n","    def run(self, review):\r\n","        \"\"\"\r\n","        Returns a POSITIVE or NEGATIVE prediction for the given review.\r\n","        \"\"\"\r\n","        # TODO: Run a forward pass through the network, like you did in the\r\n","        #       \"train\" function. That means use the given review to \r\n","        #       update the input layer, then calculate values for the hidden layer,\r\n","        #       and finally calculate the output layer.\r\n","        #\r\n","        #       Note: The review passed into this function for prediction \r\n","        #             might come from anywhere, so you should convert it \r\n","        #             to lower case prior to using it.\r\n","        review = review.lower()\r\n","        self.update_input_layer(review)\r\n","        hidden_logits = np.dot(self.layer_0,self.weights_0_1)\r\n","        hidden_output = self.sigmoid(hidden_logits)\r\n","        output_logits = np.dot(hidden_output,self.weights_1_2)\r\n","        output = self.sigmoid(output_logits)\r\n","\r\n","        # TODO: The output layer should now contain a prediction. \r\n","        #       Return `POSITIVE` for predictions greater-than-or-equal-to `0.5`, \r\n","        #       and `NEGATIVE` otherwise.\r\n","        return \"POSITIVE\" if output >= 0.5 else \"NEGATIVE\"\r\n"],"outputs":[],"metadata":{"collapsed":true,"id":"AoLVD1FvNFlr"}},{"cell_type":"markdown","source":["Run the following cell to create a `SentimentNetwork` that will train on all but the last 1000 reviews (we're saving those for testing). Here we use a learning rate of `0.1`."],"metadata":{"id":"Jg8k8fyoNFls"}},{"cell_type":"code","execution_count":null,"source":["mlp = SentimentNetwork(reviews[:-1000],labels[:-1000], learning_rate=0.1)"],"outputs":[],"metadata":{"collapsed":true,"id":"fSPGMIkNNFls"}},{"cell_type":"markdown","source":["Run the following cell to test the network's performance against the last 1000 reviews (the ones we held out from our training set). \n","\n","**We have not trained the model yet, so the results should be about 50% as it will just be guessing and there are only two possible values to choose from.**"],"metadata":{"id":"IxeAqLu6NFls"}},{"cell_type":"code","execution_count":null,"source":["mlp.test(reviews[-1000:],labels[-1000:])"],"outputs":[{"output_type":"stream","name":"stdout","text":["Progress:99.9% Speed(reviews/sec):612.6 #Correct:500 #Tested:1000 Testing Accuracy:50.0%"]}],"metadata":{"id":"CPmG1VXeNFls","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337045919,"user_tz":300,"elapsed":1948,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"49de78ff-f527-44f4-8f71-ba42487f610f"}},{"cell_type":"markdown","source":["Run the following cell to actually train the network. During training, it will display the model's accuracy repeatedly as it trains so you can see how well it's doing."],"metadata":{"id":"teChZ1D-NFlt"}},{"cell_type":"code","execution_count":null,"source":["mlp.train(reviews[:-1000],labels[:-1000])"],"outputs":[{"output_type":"stream","name":"stdout","text":["Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%\n","Progress:10.4% Speed(reviews/sec):163.7 #Correct:1284 #Trained:2501 Training Accuracy:51.3%\n","Progress:20.8% Speed(reviews/sec):163.5 #Correct:2628 #Trained:5001 Training Accuracy:52.5%\n","Progress:31.2% Speed(reviews/sec):162.6 #Correct:4045 #Trained:7501 Training Accuracy:53.9%\n","Progress:41.6% Speed(reviews/sec):162.9 #Correct:5540 #Trained:10001 Training Accuracy:55.3%\n","Progress:52.0% Speed(reviews/sec):163.1 #Correct:7064 #Trained:12501 Training Accuracy:56.5%\n","Progress:62.4% Speed(reviews/sec):163.2 #Correct:8585 #Trained:15001 Training Accuracy:57.2%\n","Progress:72.9% Speed(reviews/sec):163.2 #Correct:9989 #Trained:17501 Training Accuracy:57.0%\n","Progress:83.3% Speed(reviews/sec):163.2 #Correct:11524 #Trained:20001 Training Accuracy:57.6%\n","Progress:93.7% Speed(reviews/sec):163.0 #Correct:13001 #Trained:22501 Training Accuracy:57.7%\n","Progress:99.9% Speed(reviews/sec):163.1 #Correct:13935 #Trained:24001 Training Accuracy:58.0%"]}],"metadata":{"id":"s0FOufJjNFlt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337192457,"user_tz":300,"elapsed":146562,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"851ff258-f8f1-4d34-db26-f1906dbfc48c"}},{"cell_type":"markdown","source":["That most likely didn't train very well. Part of the reason may be because the learning rate is too high. Run the following cell to recreate the network with a smaller learning rate, `0.01`, and then train the new network."],"metadata":{"id":"0SAri_6nNFlt"}},{"cell_type":"code","execution_count":null,"source":["mlp = SentimentNetwork(reviews[:-1000],labels[:-1000], learning_rate=0.01)\n","mlp.train(reviews[:-1000],labels[:-1000])"],"outputs":[{"output_type":"stream","name":"stdout","text":["Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%\n","Progress:10.4% Speed(reviews/sec):154.0 #Correct:1356 #Trained:2501 Training Accuracy:54.2%\n","Progress:20.8% Speed(reviews/sec):156.8 #Correct:2877 #Trained:5001 Training Accuracy:57.5%\n","Progress:31.2% Speed(reviews/sec):159.0 #Correct:4471 #Trained:7501 Training Accuracy:59.6%\n","Progress:41.6% Speed(reviews/sec):160.5 #Correct:6161 #Trained:10001 Training Accuracy:61.6%\n","Progress:52.0% Speed(reviews/sec):161.1 #Correct:7885 #Trained:12501 Training Accuracy:63.0%\n","Progress:62.4% Speed(reviews/sec):161.1 #Correct:9626 #Trained:15001 Training Accuracy:64.1%\n","Progress:72.9% Speed(reviews/sec):161.3 #Correct:11385 #Trained:17501 Training Accuracy:65.0%\n","Progress:83.3% Speed(reviews/sec):161.4 #Correct:13219 #Trained:20001 Training Accuracy:66.0%\n","Progress:93.7% Speed(reviews/sec):161.4 #Correct:15046 #Trained:22501 Training Accuracy:66.8%\n","Progress:99.9% Speed(reviews/sec):161.3 #Correct:16182 #Trained:24001 Training Accuracy:67.4%"]}],"metadata":{"id":"EIi23x52NFlt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337342736,"user_tz":300,"elapsed":150299,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"cc7dffc9-d964-4eae-eb86-63cc2e64b1bb"}},{"cell_type":"markdown","source":["That probably wasn't much different. Run the following cell to recreate the network one more time with an even smaller learning rate, `0.001`, and then train the new network."],"metadata":{"id":"rj6aqF7pNFlt"}},{"cell_type":"code","execution_count":null,"source":["mlp = SentimentNetwork(reviews[:-1000],labels[:-1000], learning_rate=0.001)\n","mlp.train(reviews[:-1000],labels[:-1000])"],"outputs":[{"output_type":"stream","name":"stdout","text":["Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%\n","Progress:10.4% Speed(reviews/sec):149.3 #Correct:1321 #Trained:2501 Training Accuracy:52.8%\n","Progress:20.8% Speed(reviews/sec):150.3 #Correct:2724 #Trained:5001 Training Accuracy:54.4%\n","Progress:31.2% Speed(reviews/sec):151.0 #Correct:4212 #Trained:7501 Training Accuracy:56.1%\n","Progress:41.6% Speed(reviews/sec):151.9 #Correct:5709 #Trained:10001 Training Accuracy:57.0%\n","Progress:52.0% Speed(reviews/sec):152.5 #Correct:7283 #Trained:12501 Training Accuracy:58.2%\n","Progress:62.4% Speed(reviews/sec):152.8 #Correct:8826 #Trained:15001 Training Accuracy:58.8%\n","Progress:72.9% Speed(reviews/sec):153.1 #Correct:10397 #Trained:17501 Training Accuracy:59.4%\n","Progress:83.3% Speed(reviews/sec):153.0 #Correct:12014 #Trained:20001 Training Accuracy:60.0%\n","Progress:93.7% Speed(reviews/sec):153.2 #Correct:13684 #Trained:22501 Training Accuracy:60.8%\n","Progress:99.9% Speed(reviews/sec):153.1 #Correct:14713 #Trained:24001 Training Accuracy:61.3%"]}],"metadata":{"id":"80zF5Cs_NFlt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337500927,"user_tz":300,"elapsed":158208,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"d83dd8bb-adda-433d-8289-718ad12f2528"}},{"cell_type":"markdown","source":["With a learning rate of `0.001`, the network should finall have started to improve during training. It's still not very good, but it shows that this solution has potential. We will improve it in the next lesson."],"metadata":{"id":"X9Pu9jSXNFlu"}},{"cell_type":"code","execution_count":null,"source":["mlp = SentimentNetwork(reviews[:-1000],labels[:-1000], learning_rate=0.0003)\n","mlp.train(reviews[:-1000],labels[:-1000])"],"outputs":[{"output_type":"stream","name":"stdout","text":["Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%\n","Progress:10.4% Speed(reviews/sec):144.5 #Correct:1266 #Trained:2501 Training Accuracy:50.6%\n","Progress:20.8% Speed(reviews/sec):149.6 #Correct:2572 #Trained:5001 Training Accuracy:51.4%\n","Progress:31.2% Speed(reviews/sec):152.0 #Correct:3945 #Trained:7501 Training Accuracy:52.5%\n","Progress:41.6% Speed(reviews/sec):152.7 #Correct:5328 #Trained:10001 Training Accuracy:53.2%\n","Progress:52.0% Speed(reviews/sec):152.3 #Correct:6757 #Trained:12501 Training Accuracy:54.0%\n","Progress:62.4% Speed(reviews/sec):152.2 #Correct:8182 #Trained:15001 Training Accuracy:54.5%\n","Progress:72.9% Speed(reviews/sec):152.2 #Correct:9609 #Trained:17501 Training Accuracy:54.9%\n","Progress:83.3% Speed(reviews/sec):152.7 #Correct:11113 #Trained:20001 Training Accuracy:55.5%\n","Progress:93.7% Speed(reviews/sec):153.0 #Correct:12600 #Trained:22501 Training Accuracy:55.9%\n","Progress:99.9% Speed(reviews/sec):153.3 #Correct:13549 #Trained:24001 Training Accuracy:56.4%"]}],"metadata":{"id":"4LwXLC0UNFlu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337659086,"user_tz":300,"elapsed":158188,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"9e2e1245-5e8a-418b-fe69-b86ed6853656"}},{"cell_type":"markdown","source":["# End of Project 3. "],"metadata":{"id":"lxjRsU1PNFlu"}},{"cell_type":"markdown","source":["# Understanding Neural Noise<a id='lesson_4'></a>\n"],"metadata":{"id":"qu3FiCGXNFlu"}},{"cell_type":"markdown","source":["<img src=\"https://raw.githubusercontent.com/llealgt/moview_review_sentiment_prediction_neural_network/master/sentiment_network.png\">"],"metadata":{"id":"3c6GSRbhoNk5"}},{"cell_type":"code","execution_count":null,"source":["def update_input_layer(review):\n","    \n","    global layer_0\n","    \n","    # clear out previous state, reset the layer to be all 0s\n","    layer_0 *= 0\n","    for word in review.split(\" \"):\n","        layer_0[0][word2index[word]] += 1\n","\n","update_input_layer(reviews[0])"],"outputs":[],"metadata":{"collapsed":true,"id":"J8jsbvMTNFlu"}},{"cell_type":"code","execution_count":null,"source":["layer_0"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[18.,  0.,  0., ...,  0.,  0.,  0.]])"]},"metadata":{},"execution_count":45}],"metadata":{"id":"d735W0RrNFlu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337659087,"user_tz":300,"elapsed":54,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"7a129ec2-d09c-449a-edef-3505d796865d"}},{"cell_type":"code","execution_count":null,"source":["review_counter = Counter()"],"outputs":[],"metadata":{"collapsed":true,"id":"pXhzRvmLNFlv"}},{"cell_type":"code","execution_count":null,"source":["for word in reviews[0].split(\" \"):\n","    review_counter[word] += 1"],"outputs":[],"metadata":{"collapsed":true,"id":"HUfY8rODNFlv"}},{"cell_type":"code","execution_count":null,"source":["review_counter.most_common()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('.', 27),\n"," ('', 18),\n"," ('the', 9),\n"," ('to', 6),\n"," ('high', 5),\n"," ('i', 5),\n"," ('bromwell', 4),\n"," ('is', 4),\n"," ('a', 4),\n"," ('teachers', 4),\n"," ('that', 4),\n"," ('of', 4),\n"," ('it', 2),\n"," ('at', 2),\n"," ('as', 2),\n"," ('school', 2),\n"," ('my', 2),\n"," ('in', 2),\n"," ('me', 2),\n"," ('students', 2),\n"," ('their', 2),\n"," ('student', 2),\n"," ('cartoon', 1),\n"," ('comedy', 1),\n"," ('ran', 1),\n"," ('same', 1),\n"," ('time', 1),\n"," ('some', 1),\n"," ('other', 1),\n"," ('programs', 1),\n"," ('about', 1),\n"," ('life', 1),\n"," ('such', 1),\n"," ('years', 1),\n"," ('teaching', 1),\n"," ('profession', 1),\n"," ('lead', 1),\n"," ('believe', 1),\n"," ('s', 1),\n"," ('satire', 1),\n"," ('much', 1),\n"," ('closer', 1),\n"," ('reality', 1),\n"," ('than', 1),\n"," ('scramble', 1),\n"," ('survive', 1),\n"," ('financially', 1),\n"," ('insightful', 1),\n"," ('who', 1),\n"," ('can', 1),\n"," ('see', 1),\n"," ('right', 1),\n"," ('through', 1),\n"," ('pathetic', 1),\n"," ('pomp', 1),\n"," ('pettiness', 1),\n"," ('whole', 1),\n"," ('situation', 1),\n"," ('all', 1),\n"," ('remind', 1),\n"," ('schools', 1),\n"," ('knew', 1),\n"," ('and', 1),\n"," ('when', 1),\n"," ('saw', 1),\n"," ('episode', 1),\n"," ('which', 1),\n"," ('repeatedly', 1),\n"," ('tried', 1),\n"," ('burn', 1),\n"," ('down', 1),\n"," ('immediately', 1),\n"," ('recalled', 1),\n"," ('classic', 1),\n"," ('line', 1),\n"," ('inspector', 1),\n"," ('m', 1),\n"," ('here', 1),\n"," ('sack', 1),\n"," ('one', 1),\n"," ('your', 1),\n"," ('welcome', 1),\n"," ('expect', 1),\n"," ('many', 1),\n"," ('adults', 1),\n"," ('age', 1),\n"," ('think', 1),\n"," ('far', 1),\n"," ('fetched', 1),\n"," ('what', 1),\n"," ('pity', 1),\n"," ('isn', 1),\n"," ('t', 1)]"]},"metadata":{},"execution_count":48}],"metadata":{"id":"SeJd9krQNFlv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337659090,"user_tz":300,"elapsed":35,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"2d047902-4e85-4a65-89a6-8c7cbe66b139"}},{"cell_type":"markdown","source":["# Project 4: Reducing Noise in Our Input Data<a id='project_4'></a>\n","\n","**TODO:** Attempt to reduce the noise in the input data like . Specifically, do the following:\n","* Copy the `SentimentNetwork` class you created earlier into the following cell.\n","* Modify `update_input_layer` so it does not count how many times each word is used, but rather just stores whether or not a word was used. "],"metadata":{"id":"_TyW_DwGNFlv"}},{"cell_type":"code","execution_count":null,"source":["# TODO: -Copy the SentimentNetwork class from Projet 3 lesson\n","#       -Modify it to reduce noise by setting 1(presence) or 0(ausence) instead of counts\n","import time\n","import sys\n","import numpy as np\n","\n","# Encapsulate our neural network in a class\n","class SentimentNetwork:\n","    def __init__(self, reviews, labels, hidden_nodes = 10, learning_rate = 0.1):\n","        \"\"\"Create a SentimenNetwork with the given settings\n","        Args:\n","            reviews(list) - List of reviews used for training\n","            labels(list) - List of POSITIVE/NEGATIVE labels associated with the given reviews\n","            hidden_nodes(int) - Number of nodes to create in the hidden layer\n","            learning_rate(float) - Learning rate to use while training\n","        \n","        \"\"\"\n","        # Assign a seed to our random number generator to ensure we get\n","        # reproducable results during development \n","        np.random.seed(1)\n","\n","        # process the reviews and their associated labels so that everything\n","        # is ready for training\n","        self.pre_process_data(reviews, labels)\n","        \n","        # Build the network to have the number of hidden nodes and the learning rate that\n","        # were passed into this initializer. Make the same number of input nodes as\n","        # there are vocabulary words and create a single output node.\n","        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n","\n","    def pre_process_data(self, reviews, labels):\n","        \n","        review_vocab = set()\n","        # TODO: populate review_vocab with all of the words in the given reviews\n","        #       Remember to split reviews into individual words \n","        #       using \"split(' ')\" instead of \"split()\".\n","        \n","        for review in reviews:\n","            words = review.split(' ')\n","            for word in words:\n","                review_vocab.add(word)\n","        # Convert the vocabulary set to a list so we can access words via indices\n","        self.review_vocab = list(review_vocab)\n","        \n","        label_vocab = set()\n","        # TODO: populate label_vocab with all of the words in the given labels.\n","        #       There is no need to split the labels because each one is a single word.\n","        \n","        for label in labels:\n","            label_vocab.add(label)\n","        # Convert the label vocabulary set to a list so we can access labels via indices\n","        self.label_vocab = list(label_vocab)\n","        \n","        # Store the sizes of the review and label vocabularies.\n","        self.review_vocab_size = len(self.review_vocab)\n","        self.label_vocab_size = len(self.label_vocab)\n","        \n","        # Create a dictionary of words in the vocabulary mapped to index positions\n","        self.word2index = {}\n","        # TODO: populate self.word2index with indices for all the words in self.review_vocab\n","        #       like you saw earlier in the notebook\n","        for index,word in enumerate(self.review_vocab):\n","            self.word2index[word] = index\n","        # Create a dictionary of labels mapped to index positions\n","        self.label2index = {}\n","        # TODO: do the same thing you did for self.word2index and self.review_vocab, \n","        #       but for self.label2index and self.label_vocab instead\n","        for index,label in enumerate(self.label_vocab):\n","            self.label2index[label] = index\n","            \n","        \n","    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n","        # Store the number of nodes in input, hidden, and output layers.\n","        self.input_nodes = input_nodes\n","        self.hidden_nodes = hidden_nodes\n","        self.output_nodes = output_nodes\n","\n","        # Store the learning rate\n","        self.learning_rate = learning_rate\n","\n","        # Initialize weights\n","        \n","        # TODO: initialize self.weights_0_1 as a matrix of zeros. These are the weights between\n","        #       the input layer and the hidden layer.\n","        self.weights_0_1 = np.random.normal(0.0, np.sqrt(1/input_nodes),\n","                                            (input_nodes,hidden_nodes))\n","        \n","        # TODO: initialize self.weights_1_2 as a matrix of random values. \n","        #       These are the weights between the hidden layer and the output layer.\n","        self.weights_1_2 = np.random.normal(0.0, np.sqrt(1/input_nodes), \n","                                                (self.hidden_nodes, self.output_nodes))\n","        \n","        # TODO: Create the input layer, a two-dimensional matrix with shape \n","        #       1 x input_nodes, with all values initialized to zero\n","        self.layer_0 = np.zeros((1,input_nodes))\n","    \n","        \n","    def update_input_layer(self,review):\n","        # TODO: You can copy most of the code you wrote for update_input_layer \n","        #       earlier in this notebook. \n","        #\n","        #       However, MAKE SURE YOU CHANGE ALL VARIABLES TO REFERENCE\n","        #       THE VERSIONS STORED IN THIS OBJECT, NOT THE GLOBAL OBJECTS.\n","        #       For example, replace \"layer_0 *= 0\" with \"self.layer_0 *= 0\"\n","        self.layer_0*=0\n","        for word in review.split(' '):\n","            if word in self.word2index.keys():\n","                word_index = self.word2index[word]\n","                self.layer_0[0,word_index] = 1\n","                \n","    def get_target_for_label(self,label):\n","        # TODO: Copy the code you wrote for get_target_for_label \n","        #       earlier in this notebook. \n","        return 0 if label == 'NEGATIVE' else 1\n","        \n","    def sigmoid(self,x):\n","        # TODO: Return the result of calculating the sigmoid activation function\n","        #       shown in the lectures\n","        return 1 / ( 1 + np.exp(-x))\n","    \n","    def sigmoid_output_2_derivative(self,output):\n","        # TODO: Return the derivative of the sigmoid activation function, \n","        #       where \"output\" is the original output from the sigmoid fucntion \n","        return output * (1 - output)\n","\n","    def sigmoid_prime(self,output):\n","        # TODO: Return the derivative of the sigmoid activation function, \n","        return output * (1 - output)\n","\n","\n","    def train(self, training_reviews, training_labels):\n","        \n","        # make sure out we have a matching number of reviews and labels\n","        assert(len(training_reviews) == len(training_labels))\n","        \n","        # Keep track of correct predictions to display accuracy during training \n","        correct_so_far = 0\n","        \n","        # Remember when we started for printing time statistics\n","        start = time.time()\n","\n","        # loop through all the given reviews and run a forward and backward pass,\n","        # updating weights for every item\n","        for i in range(len(training_reviews)):\n","            \n","            # TODO: Get the next review and its correct label\n","            review = training_reviews[i]\n","            label = training_labels[i]\n","            # TODO: Implement the forward pass through the network. \n","            #       That means use the given review to update the input layer, \n","            #       then calculate values for the hidden layer,\n","            #       and finally calculate the output layer.\n","            # \n","            #       Do not use an activation function for the hidden layer,\n","            #       but use the sigmoid activation function for the output layer.\n","            self.update_input_layer(review)\n","            hidden_layer_logits = np.dot(self.layer_0,self.weights_0_1)\n","            hidden_layer_output = self.sigmoid(hidden_layer_logits)\n","            output_layer_logits = np.dot(hidden_layer_output,self.weights_1_2)\n","            output_layer_predictions = self.sigmoid(output_layer_logits)\n","            #print(\"output layer\",output_layer_predictions.shape)\n","            # TODO: Implement the back propagation pass here. \n","            #       That means calculate the error for the forward pass's prediction\n","            #       and update the weights in the network according to their\n","            #       contributions toward the error, as calculated via the\n","            #       gradient descent and back propagation algorithms you \n","            #       learned in class.\n","            error = output_layer_predictions - self.get_target_for_label(label) # dL/da2(derivada del costo respecto de la salida y_pred)\n","            #print(\"error\",error.shape)\n","            #calculate the error terms of each layer\n","            output_error_term = error*self.sigmoid_prime(output_layer_predictions) #dL/dz2(derivada del costo respecto de la pre-activacion z2, el termino de error delta2)\n","            #print(\"output error term\",output_error_term.shape)\n","            #print(\"sigmoid prime(hidden)\",self.sigmoid_prime(hidden_layer_output).shape)\n","            hidden_error_term = np.matmul(self.weights_1_2,output_error_term)*self.sigmoid_prime(hidden_layer_output).T# dL/dz1 (derivada del costo respecto de la pre-activacion z1, el termino de error delta1)\n","            #print(\"hidden error term\",hidden_error_term.shape)\n","            #print(\"hidden layer output\",hidden_layer_output.shape)\n","            #calculate the delta on the weights of each layer\n","\n","            ## una vez calculados los terminos de error delta(derivadas respecto de z) los usamos para calcular las derivadas parciales respecto de los parametros usando #activacion entrante * error saliente\n","            grad_weights_h_o =  output_error_term * hidden_layer_output\n","            grad_weights_i_h = hidden_error_term * self.layer_0\n","            #print(\"calculated\",(self.learning_rate*delta_weights_h_o).shape)\n","            #print(\"weights\",self.weights_1_2.shape)\n","\n","            ## una vez calculadas las derivadas respecto de los parametros aplicamos \"gradient descent\"\n","            self.weights_1_2-= (self.learning_rate*grad_weights_h_o).T\n","            self.weights_0_1-= (self.learning_rate*grad_weights_i_h).T\n","            # TODO: Keep track of correct predictions. To determine if the prediction was\n","            #       correct, check that the absolute value of the output error \n","            #       is less than 0.5. If so, add one to the correct_so_far count.\n","            #Note to myself: strange way to calc correctness hmmm\n","            if  np.abs(error) < 0.5:\n","                correct_so_far+=1\n","            \n","            # For debug purposes, print out our prediction accuracy and speed \n","            # throughout the training process. \n","\n","            elapsed_time = float(time.time() - start)\n","            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n","            \n","            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] \\\n","                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n","                             + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) \\\n","                             + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n","            if(i % 2500 == 0):\n","                print(\"\")\n","    \n","    def test(self, testing_reviews, testing_labels):\n","        \"\"\"\n","        Attempts to predict the labels for the given testing_reviews,\n","        and uses the test_labels to calculate the accuracy of those predictions.\n","        \"\"\"\n","        \n","        # keep track of how many correct predictions we make\n","        correct = 0\n","\n","        # we'll time how many predictions per second we make\n","        start = time.time()\n","\n","        # Loop through each of the given reviews and call run to predict\n","        # its label. \n","        for i in range(len(testing_reviews)):\n","            pred = self.run(testing_reviews[i])\n","            if(pred == testing_labels[i]):\n","                correct += 1\n","            \n","            # For debug purposes, print out our prediction accuracy and speed \n","            # throughout the prediction process. \n","\n","            elapsed_time = float(time.time() - start)\n","            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n","            \n","            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n","                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n","                             + \" #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) \\\n","                             + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n","    \n","    def run(self, review):\n","        \"\"\"\n","        Returns a POSITIVE or NEGATIVE prediction for the given review.\n","        \"\"\"\n","        # TODO: Run a forward pass through the network, like you did in the\n","        #       \"train\" function. That means use the given review to \n","        #       update the input layer, then calculate values for the hidden layer,\n","        #       and finally calculate the output layer.\n","        #\n","        #       Note: The review passed into this function for prediction \n","        #             might come from anywhere, so you should convert it \n","        #             to lower case prior to using it.\n","        review = review.lower()\n","        self.update_input_layer(review)\n","        hidden_logits = np.dot(self.layer_0,self.weights_0_1)\n","        hidden_output = self.sigmoid(hidden_logits)\n","        output_logits = np.dot(hidden_output,self.weights_1_2)\n","        output = self.sigmoid(output_logits)\n","\n","        # TODO: The output layer should now contain a prediction. \n","        #       Return `POSITIVE` for predictions greater-than-or-equal-to `0.5`, \n","        #       and `NEGATIVE` otherwise.\n","        return \"POSITIVE\" if output >= 0.5 else \"NEGATIVE\"\n"],"outputs":[],"metadata":{"collapsed":true,"id":"zxAd0fcoNFlv"}},{"cell_type":"markdown","source":["Run the following cell to recreate the network and train it. Notice we've gone back to the higher learning rate of `0.1`."],"metadata":{"id":"bWQneEPDNFlw"}},{"cell_type":"code","execution_count":null,"source":["mlp = SentimentNetwork(reviews[:-1000],labels[:-1000], learning_rate=0.1)\n","mlp.train(reviews[:-1000],labels[:-1000])"],"outputs":[{"output_type":"stream","name":"stdout","text":["Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%\n","Progress:10.4% Speed(reviews/sec):152.1 #Correct:587 #Trained:2501 Training Accuracy:23.4%\n","Progress:20.8% Speed(reviews/sec):151.7 #Correct:2496 #Trained:5001 Training Accuracy:49.9%\n","Progress:31.2% Speed(reviews/sec):153.0 #Correct:4575 #Trained:7501 Training Accuracy:60.9%\n","Progress:41.6% Speed(reviews/sec):153.3 #Correct:6715 #Trained:10001 Training Accuracy:67.1%\n","Progress:52.0% Speed(reviews/sec):153.2 #Correct:8849 #Trained:12501 Training Accuracy:70.7%\n","Progress:62.4% Speed(reviews/sec):153.2 #Correct:10992 #Trained:15001 Training Accuracy:73.2%\n","Progress:72.9% Speed(reviews/sec):153.3 #Correct:13094 #Trained:17501 Training Accuracy:74.8%\n","Progress:83.3% Speed(reviews/sec):153.6 #Correct:15255 #Trained:20001 Training Accuracy:76.2%\n","Progress:93.7% Speed(reviews/sec):154.1 #Correct:17440 #Trained:22501 Training Accuracy:77.5%\n","Progress:99.9% Speed(reviews/sec):154.5 #Correct:18760 #Trained:24001 Training Accuracy:78.1%"]}],"metadata":{"id":"AHumlbZKNFlw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337816300,"user_tz":300,"elapsed":156716,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"0cd95cd9-3304-4649-8e25-89518526c45d"}},{"cell_type":"markdown","source":["That should have trained much better than the earlier attempts. It's still not wonderful, but it should have improved dramatically. Run the following cell to test your model with 1000 predictions."],"metadata":{"id":"CbvRfc5pNFlw"}},{"cell_type":"code","execution_count":null,"source":["mlp.test(reviews[-1000:],labels[-1000:])"],"outputs":[{"output_type":"stream","name":"stdout","text":["Progress:99.9% Speed(reviews/sec):598.2 #Correct:846 #Tested:1000 Testing Accuracy:84.6%"]}],"metadata":{"id":"5Ln-b2yaNFlw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337818234,"user_tz":300,"elapsed":1963,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"04c49e22-a8a5-4018-ec2f-1cbc87071b64"}},{"cell_type":"markdown","source":["# End of Project 4. \n","\n","# Analyzing Inefficiencies in our Network<a id='lesson_5'></a>"],"metadata":{"id":"wZtkHB8FNFlw"}},{"cell_type":"markdown","source":["<img src=\"https://raw.githubusercontent.com/llealgt/moview_review_sentiment_prediction_neural_network/master/sentiment_network_sparse.png\">"],"metadata":{"id":"eVfdHjhdp-PK"}},{"cell_type":"code","execution_count":null,"source":["layer_0 = np.zeros(10)"],"outputs":[],"metadata":{"collapsed":true,"id":"_dRnwYUMNFlx"}},{"cell_type":"code","execution_count":null,"source":["layer_0"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"]},"metadata":{},"execution_count":53}],"metadata":{"id":"8fGk3xEcNFlx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337818237,"user_tz":300,"elapsed":59,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"313f94a0-b6d2-4850-cdb0-0f43001c9da0"}},{"cell_type":"code","execution_count":null,"source":["layer_0[4] = 1\n","layer_0[9] = 1"],"outputs":[],"metadata":{"collapsed":true,"id":"nr1e89BONFlx"}},{"cell_type":"code","execution_count":null,"source":["layer_0"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1.])"]},"metadata":{},"execution_count":55}],"metadata":{"id":"NOw34BJiNFlx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337818238,"user_tz":300,"elapsed":38,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"3bed1141-885f-425e-835f-9630ee8b816b"}},{"cell_type":"code","execution_count":null,"source":["weights_0_1 = np.random.randn(10,5)"],"outputs":[],"metadata":{"collapsed":true,"id":"V5rVvVvyNFlx"}},{"cell_type":"code","execution_count":null,"source":["layer_0.dot(weights_0_1)"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 2.40385671, -2.03143821, -1.01001659, -0.20106613,  2.10673993])"]},"metadata":{},"execution_count":57}],"metadata":{"id":"uljK_odlNFlx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337818239,"user_tz":300,"elapsed":31,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"41e4e675-22a8-4fbc-b988-53ee5fd87bac"}},{"cell_type":"code","execution_count":null,"source":["indices = [4,9]"],"outputs":[],"metadata":{"collapsed":true,"id":"C-LSt2H3NFly"}},{"cell_type":"code","execution_count":null,"source":["layer_1 = np.zeros(5)"],"outputs":[],"metadata":{"collapsed":true,"id":"9J8qhMjCNFly"}},{"cell_type":"code","execution_count":null,"source":["for index in indices:\n","    layer_1 += (1 * weights_0_1[index])"],"outputs":[],"metadata":{"collapsed":true,"id":"ltLElVopNFly"}},{"cell_type":"code","execution_count":null,"source":["layer_1"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 2.40385671, -2.03143821, -1.01001659, -0.20106613,  2.10673993])"]},"metadata":{},"execution_count":61}],"metadata":{"id":"yIUr7VZnNFly","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337818456,"user_tz":300,"elapsed":43,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"c2edaf21-8d31-4f1a-8967-8cdbe14579ad"}},{"cell_type":"markdown","source":["<img src=\"https://raw.githubusercontent.com/llealgt/moview_review_sentiment_prediction_neural_network/master/sentiment_network_sparse_2.png\">"],"metadata":{"id":"eR1V9F4wqKS7"}},{"cell_type":"code","execution_count":null,"source":["layer_1 = np.zeros(5)"],"outputs":[],"metadata":{"collapsed":true,"id":"Evd5T317NFly"}},{"cell_type":"code","execution_count":null,"source":["for index in indices:\n","    layer_1 += (weights_0_1[index])"],"outputs":[],"metadata":{"collapsed":true,"id":"Wdp_wZiENFly"}},{"cell_type":"code","execution_count":null,"source":["layer_1"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 2.40385671, -2.03143821, -1.01001659, -0.20106613,  2.10673993])"]},"metadata":{},"execution_count":64}],"metadata":{"id":"YgLhiqmwNFlz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337818459,"user_tz":300,"elapsed":32,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"eec75a08-5d18-452f-a740-9827ac4d519b"}},{"cell_type":"markdown","source":["# Project 5: Making our Network More Efficient<a id='project_5'></a>\n","**TODO:** Make the `SentimentNetwork` class more efficient by eliminating unnecessary multiplications and additions that occur during forward and backward propagation. To do that, you can do the following:\n","* Copy the `SentimentNetwork` class from the previous project into the following cell.\n","* Remove the `update_input_layer` function - you will not need it in this version.\n","* Modify `init_network`:\n",">* You no longer need a separate input layer, so remove any mention of `self.layer_0`\n",">* You will be dealing with the old hidden layer more directly, so create `self.layer_1`, a two-dimensional matrix with shape 1 x hidden_nodes, with all values initialized to zero\n","* Modify `train`:\n",">* Change the name of the input parameter `training_reviews` to `training_reviews_raw`. This will help with the next step.\n",">* At the beginning of the function, you'll want to preprocess your reviews to convert them to a list of indices (from `word2index`) that are actually used in the review. This is equivalent to what you saw in the video when Andrew set specific indices to 1. Your code should create a local `list` variable named `training_reviews` that should contain a `list` for each review in `training_reviews_raw`. Those lists should contain the indices for words found in the review.\n",">* Remove call to `update_input_layer`\n",">* Use `self`'s  `layer_1` instead of a local `layer_1` object.\n",">* In the forward pass, replace the code that updates `layer_1` with new logic that only adds the weights for the indices used in the review.\n",">* When updating `weights_0_1`, only update the individual weights that were used in the forward pass.\n","* Modify `run`:\n",">* Remove call to `update_input_layer` \n",">* Use `self`'s  `layer_1` instead of a local `layer_1` object.\n",">* Much like you did in `train`, you will need to pre-process the `review` so you can work with word indices, then update `layer_1` by adding weights for the indices used in the review."],"metadata":{"id":"4cwxE6whNFlz"}},{"cell_type":"code","execution_count":null,"source":["# TODO: -Copy the SentimentNetwork class from Project 4 lesson\n","#       -Modify it according to the above instructions \n","#       -Modify it to reduce noise, like in the video \n","import time\n","import sys\n","import numpy as np\n","\n","# Encapsulate our neural network in a class\n","class SentimentNetwork:\n","    def __init__(self, reviews, labels, hidden_nodes = 10, learning_rate = 0.1):\n","        \"\"\"Create a SentimenNetwork with the given settings\n","        Args:\n","            reviews(list) - List of reviews used for training\n","            labels(list) - List of POSITIVE/NEGATIVE labels associated with the given reviews\n","            hidden_nodes(int) - Number of nodes to create in the hidden layer\n","            learning_rate(float) - Learning rate to use while training\n","        \n","        \"\"\"\n","        # Assign a seed to our random number generator to ensure we get\n","        # reproducable results during development \n","        np.random.seed(1)\n","\n","        # process the reviews and their associated labels so that everything\n","        # is ready for training\n","        self.pre_process_data(reviews, labels)\n","        \n","        # Build the network to have the number of hidden nodes and the learning rate that\n","        # were passed into this initializer. Make the same number of input nodes as\n","        # there are vocabulary words and create a single output node.\n","        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n","\n","    def pre_process_data(self, reviews, labels):\n","        \n","        review_vocab = set()\n","        # TODO: populate review_vocab with all of the words in the given reviews\n","        #       Remember to split reviews into individual words \n","        #       using \"split(' ')\" instead of \"split()\".\n","        \n","        for review in reviews:\n","            words = review.split(' ')\n","            for word in words:\n","                review_vocab.add(word)\n","        # Convert the vocabulary set to a list so we can access words via indices\n","        self.review_vocab = list(review_vocab)\n","        \n","        label_vocab = set()\n","        # TODO: populate label_vocab with all of the words in the given labels.\n","        #       There is no need to split the labels because each one is a single word.\n","        \n","        for label in labels:\n","            label_vocab.add(label)\n","        # Convert the label vocabulary set to a list so we can access labels via indices\n","        self.label_vocab = list(label_vocab)\n","        \n","        # Store the sizes of the review and label vocabularies.\n","        self.review_vocab_size = len(self.review_vocab)\n","        self.label_vocab_size = len(self.label_vocab)\n","        \n","        # Create a dictionary of words in the vocabulary mapped to index positions\n","        self.word2index = {}\n","        # TODO: populate self.word2index with indices for all the words in self.review_vocab\n","        #       like you saw earlier in the notebook\n","        for index,word in enumerate(self.review_vocab):\n","            self.word2index[word] = index\n","        # Create a dictionary of labels mapped to index positions\n","        self.label2index = {}\n","        # TODO: do the same thing you did for self.word2index and self.review_vocab, \n","        #       but for self.label2index and self.label_vocab instead\n","        for index,label in enumerate(self.label_vocab):\n","            self.label2index[label] = index\n","            \n","        \n","    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n","        # Store the number of nodes in input, hidden, and output layers.\n","        self.input_nodes = input_nodes\n","        self.hidden_nodes = hidden_nodes\n","        self.output_nodes = output_nodes\n","\n","        # Store the learning rate\n","        self.learning_rate = learning_rate\n","\n","        # Initialize weights\n","        \n","        # TODO: initialize self.weights_0_1 as a matrix of zeros. These are the weights between\n","        #       the input layer and the hidden layer.\n","        self.weights_0_1 = np.zeros((input_nodes,hidden_nodes))\n","        \n","        # TODO: initialize self.weights_1_2 as a matrix of random values. \n","        #       These are the weights between the hidden layer and the output layer.\n","        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, \n","                                                (self.hidden_nodes, self.output_nodes))\n","        \n","        # TODO: Create the input layer, a two-dimensional matrix with shape \n","        #       1 x input_nodes, with all values initialized to zero\n","        self.layer_1 = np.zeros((1,hidden_nodes))\n","    \n","                \n","    def get_target_for_label(self,label):\n","        # TODO: Copy the code you wrote for get_target_for_label \n","        #       earlier in this notebook. \n","        return 0 if label == 'NEGATIVE' else 1\n","        \n","    def sigmoid(self,x):\n","        # TODO: Return the result of calculating the sigmoid activation function\n","        #       shown in the lectures\n","        return 1 / ( 1 + np.exp(-x))\n","    \n","    def sigmoid_output_2_derivative(self,output):\n","        # TODO: Return the derivative of the sigmoid activation function, \n","        #       where \"output\" is the original output from the sigmoid fucntion \n","        return output * (1 - output)\n","\n","    def train(self, training_reviews_raw, training_labels):\n","        \n","        # make sure out we have a matching number of reviews and labels\n","        assert(len(training_reviews_raw) == len(training_labels))\n","        #create a list of lists, each inner list contains the word2index index for a review\n","        training_reviews = list()\n","        \n","\n","        for review in training_reviews_raw:\n","            review_indices = set()\n","            words = review.split(' ')\n","            for word in words:\n","                if word in self.word2index:\n","                    review_indices.add(self.word2index[word])\n","            training_reviews.append(list(review_indices))\n","        # Keep track of correct predictions to display accuracy during training \n","        correct_so_far = 0\n","        \n","        # Remember when we started for printing time statistics\n","        start = time.time()\n","\n","        # loop through all the given reviews and run a forward and backward pass,\n","        # updating weights for every item\n","        for i in range(len(training_reviews)):\n","            \n","            # TODO: Get the next review and its correct label\n","            review = training_reviews[i]\n","            label = training_labels[i]\n","            # TODO: Implement the forward pass through the network. \n","            #       That means use the given review to update the input layer, \n","            #       then calculate values for the hidden layer,\n","            #       and finally calculate the output layer.\n","            # \n","            #       Do not use an activation function for the hidden layer,\n","            #       but use the sigmoid activation function for the output layer.\n","            \n","            #TODO:update hidden layer so self.layer_1 is used and its calculated optimally\n","            self.layer_1 *= 0\n","            self.layer_1 = sum(self.weights_0_1[review])\n","            \n","            output_layer_logits = np.dot(self.layer_1,self.weights_1_2)\n","            output_layer_predictions = self.sigmoid(output_layer_logits)\n","            #print(\"output layer\",output_layer_predictions.shape)\n","            # TODO: Implement the back propagation pass here. (only update used weights)\n","            #       That means calculate the error for the forward pass's prediction\n","            #       and update the weights in the network according to their\n","            #       contributions toward the error, as calculated via the\n","            #       gradient descent and back propagation algorithms you \n","            #       learned in class.\n","            error = output_layer_predictions - self.get_target_for_label(label)\n","            output_error_term = error*self.sigmoid_output_2_derivative(output_layer_predictions)\n","            hidden_error_term = self.weights_1_2*output_error_term\n","            \n","            delta_weights_h_o =  output_error_term * self.layer_1\n","            #TODO:Only update weights with input  = 1\n","            delta_weights_i_h = hidden_error_term#*layer0 #\n","            self.weights_1_2-= (self.learning_rate*delta_weights_h_o).reshape(self.weights_1_2.shape)\n","            self.weights_0_1[review]-= (self.learning_rate*delta_weights_i_h).T\n","            # Keep track of correct predictions.\n","            if(output_layer_predictions >= 0.5 and label == 'POSITIVE'):\n","                correct_so_far += 1\n","            elif(output_layer_predictions < 0.5 and label == 'NEGATIVE'):\n","                correct_so_far += 1\n","            \n","            # For debug purposes, print out our prediction accuracy and speed \n","            # throughout the training process. \n","\n","            elapsed_time = float(time.time() - start)\n","            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n","            \n","            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] \\\n","                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n","                             + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) \\\n","                             + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n","            if(i % 2500 == 0):\n","                print(\"\")\n","    \n","    def test(self, testing_reviews, testing_labels):\n","        \"\"\"\n","        Attempts to predict the labels for the given testing_reviews,\n","        and uses the test_labels to calculate the accuracy of those predictions.\n","        \"\"\"\n","        \n","        # keep track of how many correct predictions we make\n","        correct = 0\n","\n","        # we'll time how many predictions per second we make\n","        start = time.time()\n","\n","        # Loop through each of the given reviews and call run to predict\n","        # its label. \n","        for i in range(len(testing_reviews)):\n","            pred = self.run(testing_reviews[i])\n","            if(pred == testing_labels[i]):\n","                correct += 1\n","            \n","            # For debug purposes, print out our prediction accuracy and speed \n","            # throughout the prediction process. \n","\n","            elapsed_time = float(time.time() - start)\n","            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n","            \n","            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n","                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n","                             + \" #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) \\\n","                             + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n","    \n","    def run(self, review):\n","        \"\"\"\n","        Returns a POSITIVE or NEGATIVE prediction for the given review.\n","        \"\"\"\n","        # TODO: Run a forward pass through the network, like you did in the\n","        #       \"train\" function. That means use the given review to \n","        #       update the input layer, then calculate values for the hidden layer,\n","        #       and finally calculate the output layer.\n","        #\n","        #       Note: The review passed into this function for prediction \n","        #             might come from anywhere, so you should convert it \n","        #             to lower case prior to using it.\n","        review = review.lower()\n","        review_indices = set()\n","        \n","        words = review.split(' ')\n","        for word in words:\n","            if word in self.word2index:\n","                review_indices.add(self.word2index[word])\n","            \n","            \n","        hidden_output = sum(self.weights_0_1[list(review_indices)])\n","        output_logits = np.dot(hidden_output,self.weights_1_2)\n","        output = self.sigmoid(output_logits)\n","        # TODO: The output layer should now contain a prediction. \n","        #       Return `POSITIVE` for predictions greater-than-or-equal-to `0.5`, \n","        #       and `NEGATIVE` otherwise.\n","        return \"POSITIVE\" if output >= 0.5 else \"NEGATIVE\""],"outputs":[],"metadata":{"collapsed":true,"id":"RIF7Jni6NFlz"}},{"cell_type":"markdown","source":["Run the following cell to recreate the network and train it once again."],"metadata":{"id":"j6SBgreHNFlz"}},{"cell_type":"code","execution_count":null,"source":["mlp = SentimentNetwork(reviews[:-1000],labels[:-1000], learning_rate=0.1)\n","mlp.train(reviews[:-1000],labels[:-1000])"],"outputs":[{"output_type":"stream","name":"stdout","text":["Progress:0.0% Speed(reviews/sec):0.0 #Correct:1 #Trained:1 Training Accuracy:100.%\n","Progress:10.4% Speed(reviews/sec):1662. #Correct:1823 #Trained:2501 Training Accuracy:72.8%\n","Progress:20.8% Speed(reviews/sec):1627. #Correct:3812 #Trained:5001 Training Accuracy:76.2%\n","Progress:31.2% Speed(reviews/sec):1634. #Correct:5892 #Trained:7501 Training Accuracy:78.5%\n","Progress:41.6% Speed(reviews/sec):1638. #Correct:8010 #Trained:10001 Training Accuracy:80.0%\n","Progress:52.0% Speed(reviews/sec):1631. #Correct:10140 #Trained:12501 Training Accuracy:81.1%\n","Progress:62.4% Speed(reviews/sec):1634. #Correct:12270 #Trained:15001 Training Accuracy:81.7%\n","Progress:72.9% Speed(reviews/sec):1636. #Correct:14397 #Trained:17501 Training Accuracy:82.2%\n","Progress:83.3% Speed(reviews/sec):1635. #Correct:16567 #Trained:20001 Training Accuracy:82.8%\n","Progress:93.7% Speed(reviews/sec):1632. #Correct:18744 #Trained:22501 Training Accuracy:83.3%\n","Progress:99.9% Speed(reviews/sec):1631. #Correct:20074 #Trained:24001 Training Accuracy:83.6%"]}],"metadata":{"id":"TTvR2XVbNFl0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337838013,"user_tz":300,"elapsed":19394,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"abfcaf49-c8f3-4658-be8a-46c5fe670446"}},{"cell_type":"markdown","source":["That should have trained much better than the earlier attempts. Run the following cell to test your model with 1000 predictions."],"metadata":{"id":"YLw2XOb9NFl0"}},{"cell_type":"code","execution_count":null,"source":["mlp.test(reviews[-1000:],labels[-1000:])"],"outputs":[{"output_type":"stream","name":"stdout","text":["Progress:99.9% Speed(reviews/sec):1426. #Correct:842 #Tested:1000 Testing Accuracy:84.2%"]}],"metadata":{"id":"mqD--MgNNFl1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337838659,"user_tz":300,"elapsed":682,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"c2355441-7c24-4835-95c0-4418ef0ea400"}},{"cell_type":"markdown","source":["# End of Project 5. \n","# Further Noise Reduction<a id='lesson_6'></a>"],"metadata":{"id":"VVhAl3kpNFl1"}},{"cell_type":"markdown","source":["<img src=\"https://raw.githubusercontent.com/llealgt/moview_review_sentiment_prediction_neural_network/master/sentiment_network_sparse_2.png\">"],"metadata":{"id":"3UzsOw2crCtT"}},{"cell_type":"code","execution_count":null,"source":["# words most frequently seen in a review with a \"POSITIVE\" label\n","pos_neg_ratios.most_common()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('edie', 4.6913478822291435),\n"," ('paulie', 4.07753744390572),\n"," ('felix', 3.152736022363656),\n"," ('polanski', 2.8233610476132043),\n"," ('matthau', 2.80672172860924),\n"," ('victoria', 2.681021528714291),\n"," ('mildred', 2.6026896854443837),\n"," ('gandhi', 2.538973871058276),\n"," ('flawless', 2.451005098112319),\n"," ('superbly', 2.26002547857525),\n"," ('perfection', 2.159484249353372),\n"," ('astaire', 2.1400661634962708),\n"," ('captures', 2.038619547159581),\n"," ('voight', 2.030170492673053),\n"," ('wonderfully', 2.0218960560332353),\n"," ('powell', 1.978345424808467),\n"," ('brosnan', 1.9547990964725592),\n"," ('lily', 1.9203768470501485),\n"," ('bakshi', 1.9029851043382795),\n"," ('lincoln', 1.9014583864844796),\n"," ('refreshing', 1.8551812956655511),\n"," ('breathtaking', 1.8481124057791867),\n"," ('bourne', 1.8478489358790986),\n"," ('lemmon', 1.8458266904983307),\n"," ('delightful', 1.8002701588959635),\n"," ('flynn', 1.7996646487351682),\n"," ('andrews', 1.7764919970972666),\n"," ('homer', 1.7692866133759964),\n"," ('beautifully', 1.7626953362841438),\n"," ('soccer', 1.7578579175523736),\n"," ('lumet', 1.7462970951512977),\n"," ('elvira', 1.739703107272002),\n"," ('underrated', 1.7197859696029656),\n"," ('gripping', 1.7165360479904674),\n"," ('superb', 1.7091514458966952),\n"," ('delight', 1.6714733033535532),\n"," ('welles', 1.667706820558076),\n"," ('sadness', 1.663505133704376),\n"," ('sinatra', 1.6389967146756448),\n"," ('touching', 1.637217476541176),\n"," ('timeless', 1.62924053973028),\n"," ('macy', 1.6211339521972916),\n"," ('unforgettable', 1.6177367152487956),\n"," ('favorites', 1.6158688027643908),\n"," ('stewart', 1.611998733295774),\n"," ('sullivan', 1.6094379124341003),\n"," ('extraordinary', 1.6094379124341003),\n"," ('hartley', 1.6094379124341003),\n"," ('brilliantly', 1.5950491749820008),\n"," ('friendship', 1.5677652160335325),\n"," ('wonderful', 1.5645425925262093),\n"," ('palma', 1.5553706911638245),\n"," ('magnificent', 1.54663701119507),\n"," ('finest', 1.546259010812569),\n"," ('jackie', 1.5439233053234738),\n"," ('ritter', 1.540445040947149),\n"," ('tremendous', 1.5184661342283736),\n"," ('freedom', 1.5091151908062312),\n"," ('fantastic', 1.5048433868558566),\n"," ('terrific', 1.5026699370083942),\n"," ('noir', 1.493925025312256),\n"," ('sidney', 1.493925025312256),\n"," ('outstanding', 1.4910053152089213),\n"," ('pleasantly', 1.4894785973551214),\n"," ('mann', 1.4894785973551214),\n"," ('nancy', 1.488077055429833),\n"," ('marie', 1.4825711915553104),\n"," ('marvelous', 1.4739999415389962),\n"," ('excellent', 1.4647538505723599),\n"," ('ruth', 1.4596256342054401),\n"," ('stanwyck', 1.4412101187160054),\n"," ('widmark', 1.4350845252893227),\n"," ('splendid', 1.4271163556401458),\n"," ('chan', 1.423108334242607),\n"," ('exceptional', 1.4201959127955721),\n"," ('tender', 1.410986973710262),\n"," ('gentle', 1.4078005663408544),\n"," ('poignant', 1.4022947024663317),\n"," ('gem', 1.3932148039644643),\n"," ('amazing', 1.3919815802404802),\n"," ('chilling', 1.3862943611198906),\n"," ('fisher', 1.3862943611198906),\n"," ('davies', 1.3862943611198906),\n"," ('captivating', 1.3862943611198906),\n"," ('darker', 1.3652409519220583),\n"," ('april', 1.349926716949016),\n"," ('kelly', 1.3461743673304654),\n"," ('blake', 1.3418425985490567),\n"," ('overlooked', 1.329135947279942),\n"," ('ralph', 1.32818673031261),\n"," ('bette', 1.3156767939059373),\n"," ('hoffman', 1.315066851831523),\n"," ('cole', 1.3121863889661687),\n"," ('shines', 1.3049487216659381),\n"," ('powerful', 1.2999662776313934),\n"," ('notch', 1.2950456896547455),\n"," ('remarkable', 1.2883688239495823),\n"," ('pitt', 1.286210902562908),\n"," ('winters', 1.2833463918674481),\n"," ('vivid', 1.2762934659055623),\n"," ('gritty', 1.2757524867200667),\n"," ('giallo', 1.274502955131774),\n"," ('portrait', 1.270462545594769),\n"," ('innocence', 1.2694300209805796),\n"," ('psychiatrist', 1.2685113254635072),\n"," ('favorite', 1.2668956297860055),\n"," ('ensemble', 1.2656663733312759),\n"," ('stunning', 1.2622417124499117),\n"," ('burns', 1.259880436264232),\n"," ('garbo', 1.258954938743289),\n"," ('barbara', 1.2580400255962119),\n"," ('philip', 1.252762968495368),\n"," ('panic', 1.252762968495368),\n"," ('holly', 1.252762968495368),\n"," ('carol', 1.2481440226390734),\n"," ('perfect', 1.246742480713785),\n"," ('appreciated', 1.2462482874741743),\n"," ('favourite', 1.2411123512753928),\n"," ('journey', 1.236762627148927),\n"," ('rural', 1.235471471385307),\n"," ('bond', 1.2321436812926323),\n"," ('builds', 1.2305398317106577),\n"," ('brilliant', 1.2287554137664785),\n"," ('brooklyn', 1.2286654169163074),\n"," ('von', 1.225175011976539),\n"," ('recommended', 1.2163953243244932),\n"," ('unfolds', 1.2163953243244932),\n"," ('daniel', 1.20215296760895),\n"," ('perfectly', 1.1971931173405572),\n"," ('crafted', 1.1962507582320256),\n"," ('prince', 1.1939224684724346),\n"," ('troubled', 1.192138346678933),\n"," ('consequences', 1.1865810616140668),\n"," ('haunting', 1.1814999484738773),\n"," ('cinderella', 1.180052620608284),\n"," ('alexander', 1.17599895228353),\n"," ('emotions', 1.1753049094563641),\n"," ('boxing', 1.1735135968412274),\n"," ('subtle', 1.173413501750808),\n"," ('solo', 1.1657515915057384),\n"," ('curtis', 1.1649873576129823),\n"," ('rare', 1.1566438362402944),\n"," ('loved', 1.1563661500586044),\n"," ('daughters', 1.1526795099383853),\n"," ('courage', 1.1438688802562305),\n"," ('dentist', 1.1426722784621401),\n"," ('highly', 1.1420208631618658),\n"," ('nominated', 1.1409146683587992),\n"," ('tony', 1.139749194228599),\n"," ('draws', 1.132513840343791),\n"," ('everyday', 1.1306150197542835),\n"," ('contrast', 1.128465251817791),\n"," ('cried', 1.121340539745666),\n"," ('fabulous', 1.1210851445201684),\n"," ('ned', 1.120591195386885),\n"," ('fay', 1.120591195386885),\n"," ('emma', 1.1184149159642893),\n"," ('sensitive', 1.113318436057805),\n"," ('corruption', 1.1118575154181303),\n"," ('smooth', 1.1089750757036563),\n"," ('dramas', 1.1080910326226534),\n"," ('today', 1.1050431789984),\n"," ('helps', 1.1023091505494358),\n"," ('inspiring', 1.0986122886681098),\n"," ('jimmy', 1.0937696641923216),\n"," ('awesome', 1.0931328229034842),\n"," ('unique', 1.0881409888008142),\n"," ('tragic', 1.0871835928444868),\n"," ('intense', 1.0870514662670339),\n"," ('stellar', 1.0857088838322018),\n"," ('rival', 1.0822184788924332),\n"," ('provides', 1.079708134028957),\n"," ('depression', 1.0782034170369026),\n"," ('shy', 1.0775588794702773),\n"," ('carrie', 1.076139432816051),\n"," ('blend', 1.0753554265038423),\n"," ('hank', 1.0736109864626924),\n"," ('diana', 1.072636802264849),\n"," ('adorable', 1.072636802264849),\n"," ('unexpected', 1.0722255334949147),\n"," ('achievement', 1.0668635903535293),\n"," ('bettie', 1.0663514264498881),\n"," ('happiness', 1.0632729222228008),\n"," ('glorious', 1.0608719606852626),\n"," ('davis', 1.0541605260972757),\n"," ('terrifying', 1.0525211814678428),\n"," ('beauty', 1.050410186850232),\n"," ('ideal', 1.0479685558493548),\n"," ('fears', 1.0467872208035236),\n"," ('hong', 1.0438040521731147),\n"," ('seasons', 1.0433496099930604),\n"," ('fascinating', 1.0414538748281612),\n"," ('carries', 1.0345904299031787),\n"," ('satisfying', 1.0321225473992768),\n"," ('definite', 1.0319209141694374),\n"," ('touched', 1.0296194171811581),\n"," ('greatest', 1.0248947127715422),\n"," ('creates', 1.0241097613701886),\n"," ('aunt', 1.023388867430522),\n"," ('walter', 1.022328983918479),\n"," ('spectacular', 1.0198314108149955),\n"," ('portrayal', 1.0189810189761024),\n"," ('ann', 1.0127808528183286),\n"," ('enterprise', 1.0116009116784799),\n"," ('musicals', 1.0096648026516135),\n"," ('deeply', 1.0094845087721023),\n"," ('incredible', 1.0061677561461084),\n"," ('mature', 1.0060195018402847),\n"," ('triumph', 0.9968295943581673),\n"," ('margaret', 0.9968295943581673),\n"," ('navy', 0.9949338591932683),\n"," ('harry', 0.9917691930500606),\n"," ('lucas', 0.990398704027877),\n"," ('sweet', 0.9896611048795548),\n"," ('joey', 0.9879467207805901),\n"," ('oscar', 0.9872190511104971),\n"," ('balance', 0.9864949905474035),\n"," ('warm', 0.9848534033114517),\n"," ('ages', 0.9844989819006886),\n"," ('guilt', 0.9808292530117262),\n"," ('glover', 0.9808292530117262),\n"," ('carrey', 0.9808292530117262),\n"," ('learns', 0.978811088855489),\n"," ('unusual', 0.9778837427819693),\n"," ('sons', 0.977775815524836),\n"," ('complex', 0.977618977381478),\n"," ('essence', 0.9775343571148737),\n"," ('brazil', 0.9769153536905899),\n"," ('widow', 0.9765095918672099),\n"," ('solid', 0.9753796482441615),\n"," ('beautiful', 0.9732630126284105),\n"," ('holmes', 0.9724610033412096),\n"," ('awe', 0.9718605830289658),\n"," ('vhs', 0.9711673420999893),\n"," ('eerie', 0.9711673420999893),\n"," ('lonely', 0.9687372072466975),\n"," ('grim', 0.9687372072466975),\n"," ('sport', 0.9682504708048661),\n"," ('debut', 0.965080896043587),\n"," ('destiny', 0.963437510299857),\n"," ('thrillers', 0.9628107475090479),\n"," ('tears', 0.9597758438138939),\n"," ('rose', 0.9566420273977225),\n"," ('feelings', 0.9555114450274363),\n"," ('ginger', 0.9555114450274363),\n"," ('winning', 0.9547181090080405),\n"," ('stanley', 0.953873443023198),\n"," ('cox', 0.9534302788236119),\n"," ('paris', 0.9527847903047266),\n"," ('heart', 0.9523880692451681),\n"," ('hooked', 0.951558870711613),\n"," ('comfortable', 0.9480394301887354),\n"," ('mgm', 0.9444616088408515),\n"," ('masterpiece', 0.941550398633393),\n"," ('themes', 0.9411882834958823),\n"," ('danny', 0.9396711805182187),\n"," ('anime', 0.9337838893216722),\n"," ('perry', 0.9332883082427261),\n"," ('joy', 0.9330175256794686),\n"," ('lovable', 0.9308188324370649),\n"," ('mysteries', 0.9295359586241757),\n"," ('hal', 0.9295359586241757),\n"," ('louis', 0.9287132518727123),\n"," ('charming', 0.9252060955321074),\n"," ('urban', 0.9236708391717776),\n"," ('allows', 0.9218309122497704),\n"," ('impact', 0.9181581460489504),\n"," ('italy', 0.9162907318741551),\n"," ('gradually', 0.9162907318741551),\n"," ('lifestyle', 0.9162907318741551),\n"," ('spy', 0.9128951428730169),\n"," ('treat', 0.9119334265051994),\n"," ('subsequent', 0.9105600571651701),\n"," ('kennedy', 0.9098182173685376),\n"," ('loving', 0.9096754927554359),\n"," ('surprising', 0.9093702890295813),\n"," ('quiet', 0.9064867317775342),\n"," ('winter', 0.9062403960206536),\n"," ('reveals', 0.9049054096490298),\n"," ('raw', 0.9044562742271522),\n"," ('funniest', 0.9007865453381899),\n"," ('pleased', 0.8999415938726256),\n"," ('norman', 0.8999415938726256),\n"," ('thief', 0.8987464222232455),\n"," ('season', 0.8982722263714767),\n"," ('secrets', 0.8979415932059586),\n"," ('colorful', 0.8970593699462676),\n"," ('highest', 0.8967461358011849),\n"," ('compelling', 0.8946292350929758),\n"," ('danes', 0.8924800831804366),\n"," ('castle', 0.889677083356065),\n"," ('kudos', 0.8888917576860407),\n"," ('great', 0.8881047090146459),\n"," ('baseball', 0.8873031950009027),\n"," ('subtitles', 0.8873031950009027),\n"," ('bleak', 0.8873031950009027),\n"," ('winner', 0.8864377687244739),\n"," ('tragedy', 0.8856369907831526),\n"," ('todd', 0.8855190732074014),\n"," ('nicely', 0.879249460193806),\n"," ('arthur', 0.8754687373538999),\n"," ('essential', 0.8737311174553593),\n"," ('gorgeous', 0.8731725250935497),\n"," ('fonda', 0.8729402910005413),\n"," ('eastwood', 0.871395411966264),\n"," ('focuses', 0.8708283577973978),\n"," ('enjoyed', 0.8707019595162461),\n"," ('natural', 0.8699792450691284),\n"," ('intensity', 0.868351269585036),\n"," ('witty', 0.8682410342324468),\n"," ('rob', 0.8642954367557748),\n"," ('worlds', 0.8637726975907087),\n"," ('health', 0.861138911799075),\n"," ('magical', 0.8595379152817056),\n"," ('deeper', 0.8580218237501793),\n"," ('lucy', 0.8561868078044496),\n"," ('moving', 0.8556661100577203),\n"," ('lovely', 0.8529064000468131),\n"," ('purple', 0.8513711857748395),\n"," ('memorable', 0.8480118911208606),\n"," ('sings', 0.8472978603872037),\n"," ('craig', 0.8434293836092832),\n"," ('modesty', 0.8434293836092832),\n"," ('relate', 0.8432655968592652),\n"," ('episodes', 0.8422371208413729),\n"," ('strong', 0.8416713577706093),\n"," ('smith', 0.8395981110859005),\n"," ('tear', 0.8370413602200144),\n"," ('apartment', 0.8333311529054953),\n"," ('princess', 0.8329091229351039),\n"," ('disagree', 0.8329091229351039),\n"," ('kung', 0.831733343846092),\n"," ('adventure', 0.8315056139327839),\n"," ('columbo', 0.8266785731844679),\n"," ('jake', 0.8266785731844679),\n"," ('adds', 0.8248565259145232),\n"," ('hart', 0.8247235383486646),\n"," ('strength', 0.8241754429663494),\n"," ('realizes', 0.8236000689573806),\n"," ('dave', 0.8232003088081431),\n"," ('childhood', 0.8220808639358386),\n"," ('forbidden', 0.8198988861990891),\n"," ('tight', 0.818835395723442),\n"," ('surreal', 0.8178506590609026),\n"," ('manager', 0.8177099032017076),\n"," ('dancer', 0.8157495026522776),\n"," ('studios', 0.8109302162163288),\n"," ('con', 0.8109302162163288),\n"," ('miike', 0.8082165103447326),\n"," ('realistic', 0.8080771472339223),\n"," ('explicit', 0.8079226951523736),\n"," ('kurt', 0.8060875917405409),\n"," ('traditional', 0.8053591711668733),\n"," ('deals', 0.8053591711668733),\n"," ('holds', 0.8049385865480619),\n"," ('carl', 0.8043728156701697),\n"," ('touches', 0.8039615469002355),\n"," ('gene', 0.8031480757742738),\n"," ('albert', 0.8027669055771679),\n"," ('abc', 0.8023464725249373),\n"," ('cry', 0.8001193001121131),\n"," ('sides', 0.7995275841185171),\n"," ('develops', 0.7985076962177716),\n"," ('eyre', 0.7985076962177716),\n"," ('dances', 0.7969439742415889),\n"," ('oscars', 0.7963314167951762),\n"," ('legendary', 0.7960045659996531),\n"," ('hearted', 0.7949298748698876),\n"," ('importance', 0.7949298748698876),\n"," ('portraying', 0.7935659283069927),\n"," ('impressed', 0.7925810775481322),\n"," ('waters', 0.7911275889201491),\n"," ('empire', 0.7907856501238614),\n"," ('edge', 0.789774016249017),\n"," ('jean', 0.7884573603642703),\n"," ('environment', 0.7884573603642703),\n"," ('sentimental', 0.7864791203521645),\n"," ('captured', 0.7862376036259573),\n"," ('styles', 0.7859289140109116),\n"," ('daring', 0.7859289140109116),\n"," ('frank', 0.7827593392496325),\n"," ('tense', 0.7827593392496325),\n"," ('backgrounds', 0.7827593392496325),\n"," ('matches', 0.7827593392496325),\n"," ('gothic', 0.7820946665764414),\n"," ('sharp', 0.7814397877056235),\n"," ('achieved', 0.780158557549575),\n"," ('court', 0.7794752640484425),\n"," ('steals', 0.7789140023173704),\n"," ('rules', 0.7784447610718404),\n"," ('colors', 0.7768461994365922),\n"," ('reunion', 0.7731898882334817),\n"," ('covers', 0.7713993774596934),\n"," ('tale', 0.7701082216960737),\n"," ('rain', 0.7683706017975328),\n"," ('forms', 0.7683706017975328),\n"," ('denzel', 0.768048488733063),\n"," ('stays', 0.7678707267558819),\n"," ('blob', 0.7672551527136672),\n"," ('maria', 0.7621400520468967),\n"," ('conventional', 0.7621400520468967),\n"," ('fresh', 0.7615843421131738),\n"," ('midnight', 0.7609697768987064),\n"," ('landscape', 0.758529939822797),\n"," ('animated', 0.7576857016975165),\n"," ('titanic', 0.7566605862822713),\n"," ('sunday', 0.7566605862822713),\n"," ('spring', 0.7537718023763802),\n"," ('cagney', 0.7537718023763802),\n"," ('enjoyable', 0.7524637577163648),\n"," ('immensely', 0.7519876805828787),\n"," ('sir', 0.7507762933965817),\n"," ('nevertheless', 0.7506710246981319),\n"," ('driven', 0.7499447789530785),\n"," ('performances', 0.7488325251606314),\n"," ('memories', 0.7472144018302211),\n"," ('nowadays', 0.7472144018302211),\n"," ('simple', 0.7464142097414326),\n"," ('golden', 0.7453329337305156),\n"," ('leslie', 0.7453329337305156),\n"," ('lovers', 0.7449722484245312),\n"," ('relationship', 0.7448423234560179),\n"," ('supporting', 0.7435780341868372),\n"," ('che', 0.742627237823315),\n"," ('packed', 0.7410032017375805),\n"," ('trek', 0.7402146914179311),\n"," ('provoking', 0.7384037721480662),\n"," ('strikes', 0.7375989431307791),\n"," ('depiction', 0.736822244062607),\n"," ('emotional', 0.7367821164568152),\n"," ('secretary', 0.7366322924996842),\n"," ('influenced', 0.7351113796589775),\n"," ('florida', 0.7351113796589775),\n"," ('germany', 0.7328875092094594),\n"," ('brings', 0.7314293671309623),\n"," ('lewis', 0.7312989465243216),\n"," ('elderly', 0.7308875085427924),\n"," ('owner', 0.7274362540385775),\n"," ('streets', 0.726669872598589),\n"," ('henry', 0.7264219694448174),\n"," ('portrays', 0.7259370033829363),\n"," ('bears', 0.7252354951114458),\n"," ('china', 0.7248958788745256),\n"," ('anger', 0.7243997240640498),\n"," ('society', 0.7243301079966333),\n"," ('available', 0.7241574173025055),\n"," ('best', 0.7234703406044631),\n"," ('blues', 0.7230001437096264),\n"," ('bugs', 0.7227059828014898),\n"," ('magic', 0.718789611173283),\n"," ('delivers', 0.7184649885442351),\n"," ('verhoeven', 0.7184649885442351),\n"," ('jim', 0.7178397931503168),\n"," ('donald', 0.7166776779701394),\n"," ('endearing', 0.714653385780909),\n"," ('relationships', 0.713937950229019),\n"," ('greatly', 0.7125652664170469),\n"," ('charlie', 0.7102416139192453),\n"," ('brad', 0.7102416139192453),\n"," ('simon', 0.7096764825111558),\n"," ('effectively', 0.7091475219063864),\n"," ('march', 0.7077459799810979),\n"," ('atmosphere', 0.7074477307021416),\n"," ('influence', 0.7073318155519017),\n"," ('genius', 0.706392407309966),\n"," ('emotionally', 0.7055697005585024),\n"," ('ken', 0.7052685410922901),\n"," ('identity', 0.7048432203231365),\n"," ('sophisticated', 0.7047080029610213),\n"," ('dan', 0.7045758763835681),\n"," ('andrew', 0.7032995520239632),\n"," ('india', 0.7014459833746404),\n"," ('roy', 0.6997045811061043),\n"," ('surprisingly', 0.6995780708902356),\n"," ('sky', 0.6978091936657567),\n"," ('romantic', 0.6966498111111474),\n"," ('match', 0.6956692499926552),\n"," ('meets', 0.6931471805599453),\n"," ('cowboy', 0.6931471805599453),\n"," ('wave', 0.6931471805599453),\n"," ('bitter', 0.6931471805599453),\n"," ('patient', 0.6931471805599453),\n"," ('stylish', 0.6931471805599453),\n"," ('britain', 0.6931471805599453),\n"," ('affected', 0.6931471805599453),\n"," ('beatty', 0.6931471805599453),\n"," ('love', 0.6919853354193732),\n"," ('paul', 0.6898082792944307),\n"," ('andy', 0.688463331247519),\n"," ('performance', 0.6879738632797247),\n"," ('patrick', 0.6864581924091486),\n"," ('unlike', 0.6854646843879291),\n"," ('brooks', 0.6843365508777904),\n"," ('refuses', 0.6834852696482084),\n"," ('award', 0.6824518914431974),\n"," ('complaint', 0.6824518914431974),\n"," ('ride', 0.6822971645358795),\n"," ('dawson', 0.6817184847363226),\n"," ('luke', 0.6815863581588694),\n"," ('wells', 0.680877087968131),\n"," ('france', 0.6804081547825156),\n"," ('sports', 0.6800750989925926),\n"," ('handsome', 0.6800750989925926),\n"," ('directs', 0.6787584431078457),\n"," ('rebel', 0.6787584431078457),\n"," ('greater', 0.6760527472006452),\n"," ('dreams', 0.6759941013336959),\n"," ('effective', 0.6756540231124281),\n"," ('interpretation', 0.6747980418917487),\n"," ('works', 0.6744550475477928),\n"," ('brando', 0.6744550475477928),\n"," ('noble', 0.6737290947028437),\n"," ('paced', 0.6731465138532757),\n"," ('le', 0.6706743247078867),\n"," ('master', 0.6701576623352465),\n"," ('h', 0.6696166831497512),\n"," ('rings', 0.6690496289808848),\n"," ('easy', 0.6689599549459415),\n"," ('city', 0.6682082322126932),\n"," ('sunshine', 0.6678293725756554),\n"," ('succeeds', 0.666478933477784),\n"," ('relations', 0.664159643686693),\n"," ('england', 0.663876798259832),\n"," ('glimpse', 0.6632942174102642),\n"," ('aired', 0.6626879730752367),\n"," ('sees', 0.6626316366339948),\n"," ('both', 0.66248336767383),\n"," ('definitely', 0.6619978948389881),\n"," ('imaginative', 0.661398482245365),\n"," ('appreciate', 0.6608389373272875),\n"," ('tricks', 0.6607119048067914),\n"," ('striking', 0.6607119048067914),\n"," ('carefully', 0.6599949732430448),\n"," ('complicated', 0.6598107602923535),\n"," ('perspective', 0.6596244885213017),\n"," ('trilogy', 0.6587795370557376),\n"," ('future', 0.6583466514105283),\n"," ('lion', 0.6574290979578661),\n"," ('douglas', 0.6554068525770982),\n"," ('victor', 0.6554068525770982),\n"," ('inspired', 0.6545985104427103),\n"," ('marriage', 0.653926467406664),\n"," ('demands', 0.653926467406664),\n"," ('father', 0.6517232167219466),\n"," ('page', 0.6512362849443085),\n"," ('instant', 0.6505875661411494),\n"," ('era', 0.6495567444850836),\n"," ('ruthless', 0.6493445579015524),\n"," ('saga', 0.6493445579015524),\n"," ('joan', 0.6489139255831198),\n"," ('joseph', 0.6484112867185539),\n"," ('workers', 0.6482966143945935),\n"," ('fantasy', 0.6472675748092517),\n"," ('distant', 0.6455191315706907),\n"," ('accomplished', 0.6455191315706907),\n"," ('manhattan', 0.6443570163905132),\n"," ('personal', 0.6435502394205732),\n"," ('meeting', 0.6431367599852839),\n"," ('individual', 0.6431367599852839),\n"," ('pushing', 0.6431367599852839),\n"," ('pleasant', 0.6425034477411904),\n"," ('brave', 0.6418538861723947),\n"," ('william', 0.6408313911957847),\n"," ('hudson', 0.6407791950426294),\n"," ('friendly', 0.6394944670676251),\n"," ('eccentric', 0.6390799592896695),\n"," ('awards', 0.6387531084941465),\n"," ('jack', 0.6383830951499704),\n"," ('seeking', 0.6380874033769178),\n"," ('divorce', 0.6375773294051346),\n"," ('colonel', 0.6375773294051346),\n"," ('jane', 0.6344395797331673),\n"," ('shaw', 0.6343066805370119),\n"," ('keeping', 0.6341488397979895),\n"," ('gives', 0.6338356815949788),\n"," ('ted', 0.633427945858323),\n"," ('animation', 0.632086923798699),\n"," ('progress', 0.6317782341836532),\n"," ('larger', 0.6312717768418578),\n"," ('concert', 0.6312717768418578),\n"," ('nation', 0.6296337748376194),\n"," ('albeit', 0.6273958029971649),\n"," ('adapted', 0.6261364702769852),\n"," ('discovers', 0.6254290065049944),\n"," ('classic', 0.6250495642805052),\n"," ('segment', 0.6233514186244034),\n"," ('morgan', 0.6230376143729187),\n"," ('mouse', 0.6229429218866968),\n"," ('impressive', 0.6221114074431935),\n"," ('artist', 0.6216882165778004),\n"," ('ultimate', 0.6216882165778004),\n"," ('griffith', 0.621173680934856),\n"," ('drew', 0.6208265189803192),\n"," ('emily', 0.6208265189803192),\n"," ('moved', 0.6197197120051281),\n"," ('families', 0.6190392084062235),\n"," ('profound', 0.6190392084062235),\n"," ('innocent', 0.6185121991713645),\n"," ('versions', 0.6173091041684409),\n"," ('eddie', 0.6169198151720611),\n"," ('criticism', 0.6165139545390294),\n"," ('nature', 0.6159451465319409),\n"," ('recognized', 0.6151856390902335),\n"," ('sexuality', 0.6146755651184501),\n"," ('contract', 0.6140098600012215),\n"," ('brian', 0.6134404379492028),\n"," ('remembered', 0.6131044728864089),\n"," ('determined', 0.6123858239154869),\n"," ('offers', 0.6120793574711635),\n"," ('pleasure', 0.611957025829932),\n"," ('washington', 0.6118015411059929),\n"," ('images', 0.6115973135958376),\n"," ('games', 0.6106709587357068),\n"," ('academy', 0.6087298387473621),\n"," ('fashioned', 0.6079893722196384),\n"," ('melodrama', 0.6074917359814515),\n"," ('rough', 0.6061358035703155),\n"," ('charismatic', 0.6061358035703155),\n"," ('peoples', 0.6061358035703155),\n"," ('dealing', 0.6051784076139881),\n"," ('fine', 0.604969622680133),\n"," ('tap', 0.6039160468320027),\n"," ('trio', 0.6015799870344548),\n"," ('russell', 0.6012096852342597),\n"," ('figures', 0.6007738604289301),\n"," ('ward', 0.6000567574939334),\n"," ('shine', 0.5991182309116689),\n"," ('brady', 0.5991182309116689),\n"," ('job', 0.5984556212516866),\n"," ('satisfied', 0.5965203448708737),\n"," ('river', 0.5963796286249509),\n"," ('brown', 0.595773016534769),\n"," ('believable', 0.595660721333025),\n"," ('always', 0.5947071077466928),\n"," ('bound', 0.5947071077466928),\n"," ('hall', 0.5933967777928858),\n"," ('cook', 0.5916777203950857),\n"," ('claire', 0.5913644862500029),\n"," ('broadway', 0.5903376866937243),\n"," ('anna', 0.5877866649021191),\n"," ('peace', 0.5862840350175841),\n"," ('visually', 0.5853943192634992),\n"," ('morality', 0.5852582185487603),\n"," ('falk', 0.5852582185487603),\n"," ('growing', 0.5846665375658754),\n"," ('experiences', 0.5831462853456169),\n"," ('stood', 0.5831462853456169),\n"," ('touch', 0.58122926435596),\n"," ('lives', 0.5810976767513224),\n"," ('kubrick', 0.5806691971332549),\n"," ('timing', 0.5804740180558324),\n"," ('expressions', 0.5798184952529422),\n"," ('struggles', 0.5798184952529422),\n"," ('authentic', 0.5784842722398056),\n"," ('helen', 0.5776342934381009),\n"," ('pre', 0.5770075306472918),\n"," ('quirky', 0.5753641449035618),\n"," ('young', 0.5753167234453431),\n"," ('inner', 0.5745414381520985),\n"," ('mexico', 0.5744308737205633),\n"," ('clint', 0.5738004229273791),\n"," ('sisters', 0.5728610146854434),\n"," ('realism', 0.5722652889994956),\n"," ('french', 0.5720692490067093),\n"," ('personalities', 0.5720692490067093),\n"," ('surprises', 0.5711322299969818),\n"," ('adventures', 0.5711322299969818),\n"," ('overcome', 0.5697681593994407),\n"," ('timothy', 0.5695332245927687),\n"," ('tales', 0.5690945318899664),\n"," ('war', 0.5684331730278168),\n"," ('civil', 0.5679840376059393),\n"," ('countries', 0.5673777932709119),\n"," ('streep', 0.5671064596645803),\n"," ('tradition', 0.5668534552356532),\n"," ('oliver', 0.5667332557042867),\n"," ('australia', 0.5658077581833438),\n"," ('understanding', 0.5653138090500605),\n"," ('players', 0.5650952537000482),\n"," ('knowing', 0.5648928450362665),\n"," ('rogers', 0.5642134971840521),\n"," ('suspenseful', 0.5636891133230585),\n"," ('variety', 0.5636891133230585),\n"," ('true', 0.5628152518081007),\n"," ('jr', 0.5622098231124694),\n"," ('psychological', 0.5610874585468789),\n"," ('sent', 0.5596157879354227),\n"," ('grand', 0.5596157879354227),\n"," ('branagh', 0.5596157879354227),\n"," ('reminiscent', 0.5596157879354227),\n"," ('performing', 0.5596157879354227),\n"," ('wealth', 0.5596157879354227),\n"," ('overwhelming', 0.5596157879354227),\n"," ('odds', 0.5596157879354227),\n"," ('brothers', 0.5589118104336285),\n"," ('howard', 0.5581108967560025),\n"," ('david', 0.5569312225647537),\n"," ('generation', 0.556287997842748),\n"," ('grow', 0.5561253829956542),\n"," ('survival', 0.5559460590464603),\n"," ('mainstream', 0.5557473111575023),\n"," ('dick', 0.5543107357057295),\n"," ('charm', 0.5528817557540786),\n"," ('kirk', 0.5527898228650229),\n"," ('twists', 0.5524472984568102),\n"," ('gangster', 0.5520685823000399),\n"," ('jeff', 0.5517930622542137),\n"," ('family', 0.5511624451006553),\n"," ('tend', 0.5505330733611034),\n"," ('thanks', 0.5504908801584222),\n"," ('world', 0.5474423472343264),\n"," ('sutherland', 0.5474353693785516),\n"," ('life', 0.5469551443495992),\n"," ('disc', 0.5465437063680699),\n"," ('bug', 0.5465437063680699),\n"," ('tribute', 0.5455111817538808),\n"," ('europe', 0.5452270504833231),\n"," ('sacrifice', 0.5443015529623801),\n"," ('color', 0.5440512713943111),\n"," ('superior', 0.5433349023312852),\n"," ('york', 0.5431823586653651),\n"," ('pulls', 0.5426662296216495),\n"," ('jackson', 0.5423242908253617),\n"," ('hearts', 0.5423242908253617),\n"," ('enjoy', 0.5412428513590611),\n"," ('redemption', 0.5405675929647282),\n"," ('madness', 0.540384426007535),\n"," ('stands', 0.5389965007326869),\n"," ('trial', 0.5389965007326869),\n"," ('greek', 0.5389965007326869),\n"," ('hamilton', 0.5389965007326869),\n"," ('each', 0.5388212312554177),\n"," ('faithful', 0.5377330766859151),\n"," ('received', 0.5372768098531604),\n"," ('documentaries', 0.537142932083364),\n"," ('jealous', 0.537142932083364),\n"," ('different', 0.5370986068246082),\n"," ('describes', 0.5368011101692514),\n"," ('shorts', 0.5359615970375329),\n"," ('brilliance', 0.5355182363563621),\n"," ('mountains', 0.5349231753450512),\n"," ('share', 0.5340824859302579),\n"," ('dealt', 0.5340824859302579),\n"," ('providing', 0.5332984796180493),\n"," ('explore', 0.5332984796180493),\n"," ('series', 0.5325809226575603),\n"," ('fellow', 0.5323318289869543),\n"," ('loves', 0.5306282510621704),\n"," ('revolution', 0.5306282510621704),\n"," ('olivier', 0.5306282510621704),\n"," ('roman', 0.5306282510621704),\n"," ('century', 0.5300278307499267),\n"," ('musical', 0.5296687115674706),\n"," ('heroic', 0.5292593254548287),\n"," ('approach', 0.5280674302004967),\n"," ('ironically', 0.5280674302004967),\n"," ('temple', 0.5280674302004967),\n"," ('moves', 0.5279372642387119),\n"," ('gift', 0.5270203096859714),\n"," ('julie', 0.5260930958967791),\n"," ('tells', 0.52415107836314),\n"," ('radio', 0.5239467117286878),\n"," ('uncle', 0.5235443961737654),\n"," ('union', 0.5232481437645479),\n"," ('deep', 0.523095716357805),\n"," ('reminds', 0.5215784155422524),\n"," ('famous', 0.5211884108015372),\n"," ('jazz', 0.5205344378929515),\n"," ('dennis', 0.5198754592859086),\n"," ('epic', 0.5191938734365074),\n"," ('adult', 0.519167695083386),\n"," ('shows', 0.519153222203753),\n"," ('performed', 0.5191244265806858),\n"," ('demons', 0.5191244265806858),\n"," ('discovered', 0.5187937934151675),\n"," ('eric', 0.5187937934151675),\n"," ('youth', 0.5185626062681431),\n"," ('human', 0.5185141122498709),\n"," ('tarzan', 0.5181382706122772),\n"," ('ourselves', 0.5179430915348546),\n"," ('wwii', 0.5175824062288704),\n"," ('passion', 0.5162164724008671),\n"," ('desire', 0.5160749796521344),\n"," ('pays', 0.5158131652770298),\n"," ('dirty', 0.5155762265245886),\n"," ('fox', 0.5155762265245886),\n"," ('sympathetic', 0.5154660033224929),\n"," ('symbolism', 0.5154660033224929),\n"," ('attitude', 0.5153099362133193),\n"," ('appearances', 0.5146644000731564),\n"," ('jeremy', 0.5146644000731564),\n"," ('fun', 0.5143906899304869),\n"," ('south', 0.5142097217502312),\n"," ('arrives', 0.5140989491109599),\n"," ('present', 0.5134196589430373),\n"," ('com', 0.5132616785638717),\n"," ('smile', 0.5126588048476517),\n"," ('alan', 0.5108256237659907),\n"," ('ring', 0.5108256237659907),\n"," ('visit', 0.5108256237659907),\n"," ('fits', 0.5108256237659907),\n"," ('provided', 0.5108256237659907),\n"," ('carter', 0.5108256237659907),\n"," ('aging', 0.5108256237659907),\n"," ('countryside', 0.5108256237659907),\n"," ('begins', 0.5101565036339665),\n"," ('success', 0.5090057870490047),\n"," ('japan', 0.5090057870490047),\n"," ('accurate', 0.5089547158301789),\n"," ('proud', 0.5080047474243493),\n"," ('daily', 0.5075946031845443),\n"," ('karloff', 0.5072478024181067),\n"," ('atmospheric', 0.5072478024181067),\n"," ('recently', 0.5071491490366821),\n"," ('fu', 0.5070449009260847),\n"," ('horrors', 0.5065612249795332),\n"," ('finding', 0.5063712734166104),\n"," ('lust', 0.5059356384717989),\n"," ('hitchcock', 0.50574947073413),\n"," ('loyal', 0.5055485666651469),\n"," ('among', 0.5033400495133273),\n"," ('viewing', 0.5030213982744091),\n"," ('investigation', 0.5026288565618122),\n"," ('shining', 0.5026288565618122),\n"," ('duo', 0.5020919437972361),\n"," ('cameron', 0.5020919437972361),\n"," ('finds', 0.501283031005398),\n"," ('contemporary', 0.5007752879124892),\n"," ('genuine', 0.500462836730444),\n"," ('frightening', 0.49995595152908684),\n"," ('plays', 0.49975983848890226),\n"," ('age', 0.49941323171424595),\n"," ('position', 0.4989911661189878),\n"," ('continues', 0.4986303506721724),\n"," ('roles', 0.4983971655075218),\n"," ('james', 0.498372162694704),\n"," ('individuals', 0.4982468415591305),\n"," ('brought', 0.49783842823917956),\n"," ('hilarious', 0.4971455198619106),\n"," ('brutal', 0.49681488669639234),\n"," ('appropriate', 0.49643688631389105),\n"," ('dance', 0.4958199831481205),\n"," ('league', 0.49578774640145024),\n"," ('helping', 0.49578774640145024),\n"," ('answers', 0.49578774640145024),\n"," ('stunts', 0.49561620510246196),\n"," ('traveling', 0.4953214372300254),\n"," ('thoroughly', 0.49414593456733524),\n"," ('depicted', 0.4931706885272699),\n"," ('combination', 0.49247648509779424),\n"," ('honor', 0.49247648509779424),\n"," ('differences', 0.49247648509779424),\n"," ('fully', 0.4921334907538381),\n"," ('tracy', 0.49159426183810306),\n"," ('battles', 0.4914075379088891),\n"," ('possibility', 0.4911205526866582),\n"," ('romance', 0.4901589869574316),\n"," ('initially', 0.49002249613622745),\n"," ('happy', 0.4898997500608791),\n"," ('crime', 0.48977221456815834),\n"," ('singing', 0.4893852925281213),\n"," ('especially', 0.48901267837860624),\n"," ('shakespeare', 0.4875479388966451),\n"," ('hugh', 0.4872951263557966),\n"," ('detail', 0.4860948425082735),\n"," ('julia', 0.4855078157817008),\n"," ('san', 0.4855078157817008),\n"," ('guide', 0.4855078157817008),\n"," ('desperation', 0.4855078157817008),\n"," ('companion', 0.4855078157817008),\n"," ('strongly', 0.48460242866688824),\n"," ('necessary', 0.48302334245403883),\n"," ('humanity', 0.48265474679929443),\n"," ('drama', 0.48221998493060503),\n"," ('nonetheless', 0.4818380868927384),\n"," ('intrigue', 0.4818380868927384),\n"," ('warming', 0.4818380868927384),\n"," ('cuba', 0.4818380868927384),\n"," ('planned', 0.4795730802618863),\n"," ('pictures', 0.4792993701192168),\n"," ('broadcast', 0.4784902431230542),\n"," ('nine', 0.47803580094299974),\n"," ('settings', 0.47743860773325364),\n"," ('history', 0.4773296693378085),\n"," ('ordinary', 0.4772588001269074),\n"," ('trade', 0.47692407209030935),\n"," ('official', 0.4760826753221178),\n"," ('primary', 0.4760826753221178),\n"," ('episode', 0.4752962026115043),\n"," ('role', 0.47520268270188676),\n"," ('spirit', 0.4747769079983932),\n"," ('grey', 0.4740936144972607),\n"," ('ways', 0.47323464982718205),\n"," ('cup', 0.472604410945793),\n"," ('piano', 0.472604410945793),\n"," ('familiar', 0.4724161756511195),\n"," ('sinister', 0.4719857904497268),\n"," ('reveal', 0.47171449364936496),\n"," ('max', 0.4715085204251558),\n"," ('dated', 0.4712164856709448),\n"," ('losing', 0.47000362924573563),\n"," ('discovery', 0.47000362924573563),\n"," ('vicious', 0.47000362924573563),\n"," ('genuinely', 0.46871413841586385),\n"," ('hatred', 0.46734051182625186),\n"," ('mistaken', 0.4670230011075978),\n"," ('dream', 0.46608972992459924),\n"," ('challenge', 0.46608972992459924),\n"," ('crisis', 0.46575733836428446),\n"," ('photographed', 0.4648885285789651),\n"," ('critics', 0.4643056081310978),\n"," ('bird', 0.4643056081310978),\n"," ('machines', 0.4643056081310978),\n"," ('born', 0.4641138351896721),\n"," ('detective', 0.4636633473511525),\n"," ('higher', 0.46328467899699055),\n"," ('remains', 0.46262352194811296),\n"," ('inevitable', 0.46262352194811296),\n"," ('soviet', 0.4618180446592961),\n"," ('ryan', 0.461345566502621),\n"," ('african', 0.46112595521371813),\n"," ('smaller', 0.46081520319132935),\n"," ('techniques', 0.46052488529119184),\n"," ('information', 0.4603417183339986),\n"," ('deserved', 0.45999798712841444),\n"," ('lynch', 0.45953232937844013),\n"," ('spielberg', 0.45953232937844013),\n"," ('cynical', 0.45953232937844013),\n"," ('tour', 0.45953232937844013),\n"," ('francisco', 0.45953232937844013),\n"," ('struggle', 0.45911782160048453),\n"," ('language', 0.4590212125771265),\n"," ('visual', 0.4582351440882285),\n"," ('warner', 0.45724137763188427),\n"," ('social', 0.45720078250735313),\n"," ('reality', 0.45719346885019546),\n"," ('hidden', 0.4567584024957149),\n"," ('breaking', 0.4560173872709956),\n"," ('sometimes', 0.45563021171182794),\n"," ('modern', 0.45500247579345005),\n"," ('surfing', 0.4542552722775964),\n"," ('popular', 0.45410691533051023),\n"," ('surprised', 0.4534409399850382),\n"," ('follows', 0.4524536175440835),\n"," ('keeps', 0.45234869400701483),\n"," ('john', 0.4520909494482197),\n"," ('mixed', 0.4519851237430572),\n"," ('defeat', 0.4519851237430572),\n"," ('justice', 0.4514272436728002),\n"," ('treasure', 0.45083371313801535),\n"," ('presents', 0.44973793178615257),\n"," ('years', 0.4491919703210497),\n"," ('chief', 0.4489502200479032),\n"," ('shadows', 0.44802472252696035),\n"," ('closely', 0.4470141110210369),\n"," ('segments', 0.4470141110210369),\n"," ('lose', 0.446583355037637),\n"," ('caine', 0.44628710262841953),\n"," ('caught', 0.4461027538399907),\n"," ('hamlet', 0.44558510189758965),\n"," ('chinese', 0.4450742462032102),\n"," ('welcome', 0.4443805243578379),\n"," ('birth', 0.4436863209283622),\n"," ('represents', 0.44320543609101143),\n"," ('puts', 0.4427910657208508),\n"," ('visuals', 0.44183275227903923),\n"," ('fame', 0.44183275227903923),\n"," ('closer', 0.44183275227903923),\n"," ('web', 0.44183275227903923),\n"," ('criminal', 0.4412745608048752),\n"," ('minor', 0.4409224199448939),\n"," ('jon', 0.44086703515908027),\n"," ('liked', 0.4407499151402072),\n"," ('restaurant', 0.44031183943833246),\n"," ('de', 0.4398327516123722),\n"," ('flaws', 0.4398327516123722),\n"," ('searching', 0.4393666597838457),\n"," ('rap', 0.4389130421757044),\n"," ('light', 0.4388443301819989),\n"," ('elizabeth', 0.4387223298646468),\n"," ('marry', 0.4386173154250649),\n"," ('learned', 0.4382549309311553),\n"," ('controversial', 0.4382549309311553),\n"," ('oz', 0.4382549309311553),\n"," ('slowly', 0.4378566038993998),\n"," ('comedic', 0.43721380642274466),\n"," ('wayne', 0.43721380642274466),\n"," ('thrilling', 0.43721380642274466),\n"," ('bridge', 0.43721380642274466),\n"," ('married', 0.4365850168219689),\n"," ('nazi', 0.4361020775700542),\n"," ('murder', 0.4353180712578455),\n"," ('physical', 0.4353180712578455),\n"," ('johnny', 0.43483971678806865),\n"," ('michelle', 0.4344526449814167),\n"," ('wallace', 0.4340384805522204),\n"," ('comedies', 0.43395706390247063),\n"," ('silent', 0.43395706390247063),\n"," ('played', 0.43387244114515305),\n"," ('international', 0.43363598507486073),\n"," ...]"]},"metadata":{},"execution_count":68}],"metadata":{"id":"BlE_fieUNFl1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337838660,"user_tz":300,"elapsed":40,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"3dfee85f-9b73-41a7-8629-daaeebc30c4a"}},{"cell_type":"code","execution_count":null,"source":["# words most frequently seen in a review with a \"NEGATIVE\" label\n","list(reversed(pos_neg_ratios.most_common()))[0:30]"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('boll', -4.835282406618394),\n"," ('uwe', -4.527846102553548),\n"," ('seagal', -3.606606956743819),\n"," ('unwatchable', -3.232428791272904),\n"," ('stinker', -3.1843768086123894),\n"," ('mst', -2.931339111817795),\n"," ('incoherent', -2.918210222585477),\n"," ('unfunny', -2.677582826320177),\n"," ('waste', -2.6057506568316997),\n"," ('blah', -2.5574420885289504),\n"," ('horrid', -2.4729780789227265),\n"," ('pointless', -2.443723518768643),\n"," ('atrocious', -2.4146593168481547),\n"," ('redeeming', -2.3576171050548607),\n"," ('prom', -2.35030978724235),\n"," ('drivel', -2.33663658094709),\n"," ('lousy', -2.2975727999267512),\n"," ('worst', -2.2771908066767406),\n"," ('laughable', -2.2547849053935245),\n"," ('awful', -2.2179631752505466),\n"," ('poorly', -2.2115829815780015),\n"," ('wasting', -2.1955788734265296),\n"," ('remotely', -2.1882648359647474),\n"," ('existent', -2.0714733720306593),\n"," ('boredom', -1.987774353154012),\n"," ('miserably', -1.9851235895077681),\n"," ('sucks', -1.9798005773223373),\n"," ('uninspired', -1.9760572894714397),\n"," ('lame', -1.9745380983043672),\n"," ('insult', -1.9711406722511042)]"]},"metadata":{},"execution_count":69}],"metadata":{"id":"nziziZi7NFl1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337838660,"user_tz":300,"elapsed":25,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"d8627b6e-f7ec-4a02-8cc0-fc689aae63ba"}},{"cell_type":"code","execution_count":null,"source":["from bokeh.models import ColumnDataSource, LabelSet\n","from bokeh.plotting import figure, show, output_file\n","from bokeh.io import output_notebook\n","output_notebook()"],"outputs":[],"metadata":{"id":"V2qSTrpSNFl2"}},{"cell_type":"code","execution_count":null,"source":["hist, edges = np.histogram(list(map(lambda x:x[1],pos_neg_ratios.most_common())), density=True, bins=100, normed=True)\n","\n","p = figure(tools=\"pan,wheel_zoom,reset,save\",\n","           toolbar_location=\"above\",\n","           title=\"Word Positive/Negative Affinity Distribution\")\n","p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:], line_color=\"#555555\")\n","show(p)"],"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: The normed argument is ignored when density is provided. In future passing both will result in an error.\n","  \"\"\"Entry point for launching an IPython kernel.\n"]},{"output_type":"display_data","data":{"application/vnd.bokehjs_load.v0+json":"","application/javascript":"\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  var JS_MIME_TYPE = 'application/javascript';\n  var HTML_MIME_TYPE = 'text/html';\n  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  var CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    var script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    var cell = handle.cell;\n\n    var id = cell.output_area._bokeh_element_id;\n    var server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd, {\n        iopub: {\n          output: function(msg) {\n            var id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    var output_area = handle.output_area;\n    var output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      var bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      var script_attrs = bk_div.children[0].attributes;\n      for (var i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      var toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\": \"dM3QQsP+wXdHg42wTqW85BjZQdLNNIXqlPw/BgKoExPmTG7ZLML4EGqLMfqHT6ON\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\": \"8x57I4YuIfu8XyZfFo0XVr2WAT8EK4rh/uDe3wF7YuW2FNUSNEpJbsPaB1nJ2fz2\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\": \"3QTqdz9LyAm2i0sG5XTePsHec3UHWwVsrOL68SYRoAXsafvfAyqtQ+h440+qIBhS\"};\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"},"metadata":{}},{"output_type":"display_data","data":{"text/html":["\n","\n","\n","\n","\n","\n","  <div class=\"bk-root\" id=\"1ce0aa3b-0a09-40db-b429-aa84d4226474\" data-root-id=\"1002\"></div>\n"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":"(function(root) {\n  function embed_document(root) {\n    \n  var docs_json = {\"428716be-7f32-4a80-9b63-a9f04f301975\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1013\"}],\"center\":[{\"id\":\"1016\"},{\"id\":\"1020\"}],\"left\":[{\"id\":\"1017\"}],\"renderers\":[{\"id\":\"1033\"}],\"title\":{\"id\":\"1003\"},\"toolbar\":{\"id\":\"1025\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"1005\"},\"x_scale\":{\"id\":\"1009\"},\"y_range\":{\"id\":\"1007\"},\"y_scale\":{\"id\":\"1011\"}},\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"axis\":{\"id\":\"1013\"},\"ticker\":null},\"id\":\"1016\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1041\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"data\":{\"left\":{\"__ndarray__\":\"lWZtRVRXE8AlIhDIxvUSwLbdsko5lBLARplVzasyEsDWVPhPHtERwGcQm9KQbxHA98s9VQMOEcCIh+DXdawQwBhDg1roShDAUP1LurXSD8BxdJG/mg8PwJLr1sR/TA7AsmIcymSJDcDU2WHPScYMwPRQp9QuAwzAFcjs2RNAC8A2PzLf+HwKwFa2d+TduQnAdy296cL2CMCYpALvpzMIwLgbSPSMcAfA2ZKN+XGtBsD6CdP+VuoFwBuBGAQ8JwXAO/hdCSFkBMBcb6MOBqEDwH3m6BPr3QLAnV0uGdAaAsC+1HMetVcBwN9LuSOalADAAIb9Uf6i/79AdIhcyBz+v4JiE2eSlvy/xFCecVwQ+78EPyl8Jor5v0YttIbwA/i/iBs/kbp99r/KCcqbhPf0vwr4VKZOcfO/TObfsBjr8b+O1Gq74mTwv5yF64tZve2/IGIBoe2w6r+gPhe2gaTnvygbLcsVmOS/qPdC4KmL4b9gqLHqe/7cv2Bh3RSk5da/YBoJP8zM0L/gpmnS6GfFv8Axgk1ybLK/AKk7J7Tblz8ABiBhTFq+PwCRONzVXss/gI/ww0LI0z9w1sSZGuHZP3AdmW/y+d8/OLK2ImUJ4z+w1aAN0RXmPzD5ivg8Iuk/qBx146gu7D8oQF/OFDvvP9SxpFzAI/E/kMMZUvap8j9Q1Y5HLDD0PxDnAz1itvU/zPh4Mpg89z+MCu4nzsL4P0wcYx0ESfo/CC7YEjrP+z/IP00IcFX9P4RRwv2l2/4/orGb+e0wAECCOlb0CPQAQGDDEO8jtwFAQEzL6T56AkAg1YXkWT0DQP5dQN90AARA3ub62Y/DBEC+b7XUqoYFQJz4b8/FSQZAfIEqyuAMB0BcCuXE+88HQDqTn78WkwhAGhxaujFWCUD6pBS1TBkKQNotz69n3ApAtraJqoKfC0CWP0SlnWIMQHbI/p+4JQ1AVlG5mtPoDUA22nOV7qsOQBJjLpAJbw9A+XV0RRIZEEBputHCn3oQQNn+LkAt3BBASUOMvbo9EUC5h+k6SJ8RQCfMRrjVABJAlxCkNWNiEkA=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[100]},\"right\":{\"__ndarray__\":\"JSIQyMb1EsC23bJKOZQSwEaZVc2rMhLA1lT4Tx7REcBnEJvSkG8RwPfLPVUDDhHAiIfg13WsEMAYQ4Na6EoQwFD9S7q10g/AcXSRv5oPD8CS69bEf0wOwLJiHMpkiQ3A1Nlhz0nGDMD0UKfULgMMwBXI7NkTQAvANj8y3/h8CsBWtnfk3bkJwHctvenC9gjAmKQC76czCMC4G0j0jHAHwNmSjflxrQbA+gnT/lbqBcAbgRgEPCcFwDv4XQkhZATAXG+jDgahA8B95ugT690CwJ1dLhnQGgLAvtRzHrVXAcDfS7kjmpQAwACG/VH+ov+/QHSIXMgc/r+CYhNnkpb8v8RQnnFcEPu/BD8pfCaK+b9GLbSG8AP4v4gbP5G6ffa/ygnKm4T39L8K+FSmTnHzv0zm37AY6/G/jtRqu+Jk8L+cheuLWb3tvyBiAaHtsOq/oD4XtoGk578oGy3LFZjkv6j3QuCpi+G/YKix6nv+3L9gYd0UpOXWv2AaCT/MzNC/4KZp0uhnxb/AMYJNcmyyvwCpOye025c/AAYgYUxavj8AkTjc1V7LP4CP8MNCyNM/cNbEmRrh2T9wHZlv8vnfPziytiJlCeM/sNWgDdEV5j8w+Yr4PCLpP6gcdeOoLuw/KEBfzhQ77z/UsaRcwCPxP5DDGVL2qfI/UNWORyww9D8Q5wM9Yrb1P8z4eDKYPPc/jAruJ87C+D9MHGMdBEn6Pwgu2BI6z/s/yD9NCHBV/T+EUcL9pdv+P6Kxm/ntMABAgjpW9Aj0AEBgwxDvI7cBQEBMy+k+egJAINWF5Fk9A0D+XUDfdAAEQN7m+tmPwwRAvm+11KqGBUCc+G/PxUkGQHyBKsrgDAdAXArlxPvPB0A6k5+/FpMIQBocWroxVglA+qQUtUwZCkDaLc+vZ9wKQLa2iaqCnwtAlj9EpZ1iDEB2yP6fuCUNQFZRuZrT6A1ANtpzle6rDkASYy6QCW8PQPl1dEUSGRBAabrRwp96EEDZ/i5ALdwQQElDjL26PRFAuYfpOkifEUAnzEa41QASQJcQpDVjYhJABlUBs/DDEkA=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[100]},\"top\":{\"__ndarray__\":\"0InalSscZD8AAAAAAAAAAAAAAAAAAAAA0InalSscZD8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABIralSscZD8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADQidqVKxxkP+mJ2pUrHGQ/AAAAAAAAAADQidqVKxxkP+mJ2pUrHGQ/AAAAAAAAAADpidqVKxxkP9CJ2pUrHHQ/6YnalSscZD/pidqVKxx0P0MsUXs2I4k/ZCxRezYjiT8AAAAAAAAAAOmJ2pUrHIQ/+I/BaeNWoD/fzsdgQSqOP6w4HyOmmJE/lTgfI6aYkT8NkMFp41agPwPVrjT5ZKo/iTI4T+5dpT/g1K40+WSqP/wMzn+HObI/ZCxRezYjqT/g1K40+WS6PwPVrjT5ZLo/vKJ20RbpwT+dE7U/S1bLP5BkcLLQ2c0/tLUrOUp70z9Xr0RlkkDXP/iPwWnjVuA/oAAA4hFT4z8wXontj/XnP8xRu0qdR+w/KQfnodVv7D+4g/O89hnrPxypXZZXzec/uwAA3ZSL5j8x+hgT19/jPywNzmuTG98/bUXttiHw1j8zr0RvjM/QP62WqCmnc8k/ugbnq8/+xT8Go3a9Isu+P9UAANgXxLk/gbUrOUp7sz8aJmqnfuisP2PhfNxo2qI/CduVCLGfpj+VOB8jppihPwbPx2BBKo4/0InalSsclD/DOB8jppiRP7bOx2BBKn4/0InalSscdD8EitqVKxx0P9CJ2pUrHGQ/AAAAAAAAAAAEitqVKxxkP9CJ2pUrHGQ/0InalSscdD8AAAAAAAAAANCJ2pUrHHQ/AAAAAAAAAAAAAAAAAAAAANCJ2pUrHGQ/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA0InalSscZD8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABIralSscZD8=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[100]}},\"selected\":{\"id\":\"1043\"},\"selection_policy\":{\"id\":\"1042\"}},\"id\":\"1030\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"left\":{\"field\":\"left\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#555555\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"1032\",\"type\":\"Quad\"},{\"attributes\":{\"formatter\":{\"id\":\"1038\"},\"major_label_policy\":{\"id\":\"1037\"},\"ticker\":{\"id\":\"1018\"}},\"id\":\"1017\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1014\",\"type\":\"BasicTicker\"},{\"attributes\":{\"text\":\"Word Positive/Negative Affinity Distribution\"},\"id\":\"1003\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1007\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1011\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1037\",\"type\":\"AllLabels\"},{\"attributes\":{\"axis\":{\"id\":\"1017\"},\"dimension\":1,\"ticker\":null},\"id\":\"1020\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1018\",\"type\":\"BasicTicker\"},{\"attributes\":{\"active_multi\":null,\"tools\":[{\"id\":\"1021\"},{\"id\":\"1022\"},{\"id\":\"1023\"},{\"id\":\"1024\"}]},\"id\":\"1025\",\"type\":\"Toolbar\"},{\"attributes\":{\"source\":{\"id\":\"1030\"}},\"id\":\"1034\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1009\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1038\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"formatter\":{\"id\":\"1041\"},\"major_label_policy\":{\"id\":\"1040\"},\"ticker\":{\"id\":\"1014\"}},\"id\":\"1013\",\"type\":\"LinearAxis\"},{\"attributes\":{\"data_source\":{\"id\":\"1030\"},\"glyph\":{\"id\":\"1031\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1032\"},\"view\":{\"id\":\"1034\"}},\"id\":\"1033\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1021\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1040\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"1005\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1022\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1043\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1023\",\"type\":\"ResetTool\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_color\":{\"value\":\"#1f77b4\"},\"left\":{\"field\":\"left\"},\"line_color\":{\"value\":\"#555555\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"1031\",\"type\":\"Quad\"},{\"attributes\":{},\"id\":\"1042\",\"type\":\"UnionRenderers\"}],\"root_ids\":[\"1002\"]},\"title\":\"Bokeh Application\",\"version\":\"2.3.3\"}};\n  var render_items = [{\"docid\":\"428716be-7f32-4a80-9b63-a9f04f301975\",\"root_ids\":[\"1002\"],\"roots\":{\"1002\":\"1ce0aa3b-0a09-40db-b429-aa84d4226474\"}}];\n  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n\n  }\n  if (root.Bokeh !== undefined) {\n    embed_document(root);\n  } else {\n    var attempts = 0;\n    var timer = setInterval(function(root) {\n      if (root.Bokeh !== undefined) {\n        clearInterval(timer);\n        embed_document(root);\n      } else {\n        attempts++;\n        if (attempts > 100) {\n          clearInterval(timer);\n          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n        }\n      }\n    }, 10, root)\n  }\n})(window);","application/vnd.bokehjs_exec.v0+json":""},"metadata":{"application/vnd.bokehjs_exec.v0+json":{"id":"1002"}}}],"metadata":{"id":"3oI8sBXLNFl2","colab":{"base_uri":"https://localhost:8080/","height":671},"executionInfo":{"status":"ok","timestamp":1629337839274,"user_tz":300,"elapsed":277,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"a2f12956-84c3-468c-9cc9-be11ddd17684"}},{"cell_type":"code","execution_count":null,"source":["frequency_frequency = Counter()\n","\n","for word, cnt in total_counts.most_common():\n","    frequency_frequency[cnt] += 1"],"outputs":[],"metadata":{"collapsed":true,"id":"0-27K6cFNFl2"}},{"cell_type":"code","execution_count":null,"source":["hist, edges = np.histogram(list(map(lambda x:x[1],frequency_frequency.most_common())), density=True, bins=100, normed=True)\n","\n","p = figure(tools=\"pan,wheel_zoom,reset,save\",\n","           toolbar_location=\"above\",\n","           title=\"The frequency distribution of the words in our corpus\")\n","p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:], line_color=\"#555555\")\n","show(p)"],"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: The normed argument is ignored when density is provided. In future passing both will result in an error.\n","  \"\"\"Entry point for launching an IPython kernel.\n"]},{"output_type":"display_data","data":{"application/vnd.bokehjs_load.v0+json":"","application/javascript":"\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  var JS_MIME_TYPE = 'application/javascript';\n  var HTML_MIME_TYPE = 'text/html';\n  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  var CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    var script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    var cell = handle.cell;\n\n    var id = cell.output_area._bokeh_element_id;\n    var server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd, {\n        iopub: {\n          output: function(msg) {\n            var id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    var output_area = handle.output_area;\n    var output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      var bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      var script_attrs = bk_div.children[0].attributes;\n      for (var i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      var toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\": \"dM3QQsP+wXdHg42wTqW85BjZQdLNNIXqlPw/BgKoExPmTG7ZLML4EGqLMfqHT6ON\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\": \"8x57I4YuIfu8XyZfFo0XVr2WAT8EK4rh/uDe3wF7YuW2FNUSNEpJbsPaB1nJ2fz2\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\": \"3QTqdz9LyAm2i0sG5XTePsHec3UHWwVsrOL68SYRoAXsafvfAyqtQ+h440+qIBhS\"};\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"},"metadata":{}},{"output_type":"display_data","data":{"text/html":["\n","\n","\n","\n","\n","\n","  <div class=\"bk-root\" id=\"119dc53a-5f95-4ac6-939a-05cf378af27f\" data-root-id=\"1089\"></div>\n"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":"(function(root) {\n  function embed_document(root) {\n    \n  var docs_json = {\"e53260a5-935c-4dd4-a28d-31b41e21e7a8\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1100\"}],\"center\":[{\"id\":\"1103\"},{\"id\":\"1107\"}],\"left\":[{\"id\":\"1104\"}],\"renderers\":[{\"id\":\"1120\"}],\"title\":{\"id\":\"1090\"},\"toolbar\":{\"id\":\"1112\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"1092\"},\"x_scale\":{\"id\":\"1096\"},\"y_range\":{\"id\":\"1094\"},\"y_scale\":{\"id\":\"1098\"}},\"id\":\"1089\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1111\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1092\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1110\",\"type\":\"ResetTool\"},{\"attributes\":{\"text\":\"The frequency distribution of the words in our corpus\"},\"id\":\"1090\",\"type\":\"Title\"},{\"attributes\":{\"formatter\":{\"id\":\"1134\"},\"major_label_policy\":{\"id\":\"1133\"},\"ticker\":{\"id\":\"1105\"}},\"id\":\"1104\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1094\",\"type\":\"DataRange1d\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"left\":{\"field\":\"left\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#555555\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"1119\",\"type\":\"Quad\"},{\"attributes\":{},\"id\":\"1096\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1098\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1134\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"formatter\":{\"id\":\"1137\"},\"major_label_policy\":{\"id\":\"1136\"},\"ticker\":{\"id\":\"1101\"}},\"id\":\"1100\",\"type\":\"LinearAxis\"},{\"attributes\":{\"data_source\":{\"id\":\"1117\"},\"glyph\":{\"id\":\"1118\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1119\"},\"view\":{\"id\":\"1121\"}},\"id\":\"1120\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1105\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1101\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1109\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1108\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1137\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1138\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"axis\":{\"id\":\"1100\"},\"ticker\":null},\"id\":\"1103\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1136\",\"type\":\"AllLabels\"},{\"attributes\":{\"active_multi\":null,\"tools\":[{\"id\":\"1108\"},{\"id\":\"1109\"},{\"id\":\"1110\"},{\"id\":\"1111\"}]},\"id\":\"1112\",\"type\":\"Toolbar\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_color\":{\"value\":\"#1f77b4\"},\"left\":{\"field\":\"left\"},\"line_color\":{\"value\":\"#555555\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"1118\",\"type\":\"Quad\"},{\"attributes\":{},\"id\":\"1139\",\"type\":\"Selection\"},{\"attributes\":{\"data\":{\"left\":{\"__ndarray__\":\"AAAAAAAA8D/NzMzMzFhxQM3MzMzMUIFANDMzMzP1iUDNzMzMzEyRQAAAAAAAn5VANDMzMzPxmUBnZmZmZkOeQM3MzMzMSqFAZ2ZmZuZzo0AAAAAAAJ2lQJqZmZkZxqdANDMzMzPvqUDNzMzMTBisQGdmZmZmQa5AAAAAAEA1sEDNzMzMzEmxQJqZmZlZXrJAZ2ZmZuZys0AzMzMzc4e0QAAAAAAAnLVAzczMzIywtkCamZmZGcW3QGdmZmam2bhANDMzMzPuuUAAAAAAwAK7QM3MzMxMF7xAmpmZmdkrvUBnZmZmZkC+QDQzMzPzVL9AAAAAAMA0wEBnZmZmBr/AQM3MzMxMScFAMzMzM5PTwUCamZmZ2V3CQAAAAAAg6MJAZ2ZmZmZyw0DNzMzMrPzDQDMzMzPzhsRAmpmZmTkRxUAAAAAAgJvFQGdmZmbGJcZAzczMzAywxkAzMzMzUzrHQJqZmZmZxMdAAAAAAOBOyEBnZmZmJtnIQM3MzMxsY8lANDMzM7PtyUCamZmZ+XfKQAAAAABAAstAZ2ZmZoaMy0DNzMzMzBbMQDQzMzMTocxAmpmZmVkrzUAAAAAAoLXNQGdmZmbmP85AzczMzCzKzkA0MzMzc1TPQJqZmZm53s9AAAAAAIA00EAzMzMzo3nQQGdmZmbGvtBAmpmZmekD0UDNzMzMDEnRQAAAAAAwjtFAMzMzM1PT0UBnZmZmdhjSQJqZmZmZXdJAzczMzLyi0kAAAAAA4OfSQDMzMzMDLdNAZ2ZmZiZy00CamZmZSbfTQM3MzMxs/NNAAAAAAJBB1EAzMzMzs4bUQGdmZmbWy9RAmpmZmfkQ1UDNzMzMHFbVQAAAAABAm9VAMzMzM2Pg1UBnZmZmhiXWQJqZmZmpatZAzczMzMyv1kAAAAAA8PTWQDMzMzMTOtdAZ2ZmZjZ/10CamZmZWcTXQM3MzMx8CdhAAAAAAKBO2EAzMzMzw5PYQGdmZmbm2NhAmpmZmQke2UDNzMzMLGPZQAAAAABQqNlANDMzM3Pt2UBnZmZmljLaQJqZmZm5d9pAzczMzNy82kA=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[100]},\"right\":{\"__ndarray__\":\"zczMzMxYcUDNzMzMzFCBQDQzMzMz9YlAzczMzMxMkUAAAAAAAJ+VQDQzMzMz8ZlAZ2ZmZmZDnkDNzMzMzEqhQGdmZmbmc6NAAAAAAACdpUCamZmZGcanQDQzMzMz76lAzczMzEwYrEBnZmZmZkGuQAAAAABANbBAzczMzMxJsUCamZmZWV6yQGdmZmbmcrNAMzMzM3OHtEAAAAAAAJy1QM3MzMyMsLZAmpmZmRnFt0BnZmZmptm4QDQzMzMz7rlAAAAAAMACu0DNzMzMTBe8QJqZmZnZK71AZ2ZmZmZAvkA0MzMz81S/QAAAAADANMBAZ2ZmZga/wEDNzMzMTEnBQDMzMzOT08FAmpmZmdldwkAAAAAAIOjCQGdmZmZmcsNAzczMzKz8w0AzMzMz84bEQJqZmZk5EcVAAAAAAICbxUBnZmZmxiXGQM3MzMwMsMZAMzMzM1M6x0CamZmZmcTHQAAAAADgTshAZ2ZmZibZyEDNzMzMbGPJQDQzMzOz7clAmpmZmfl3ykAAAAAAQALLQGdmZmaGjMtAzczMzMwWzEA0MzMzE6HMQJqZmZlZK81AAAAAAKC1zUBnZmZm5j/OQM3MzMwsys5ANDMzM3NUz0CamZmZud7PQAAAAACANNBAMzMzM6N50EBnZmZmxr7QQJqZmZnpA9FAzczMzAxJ0UAAAAAAMI7RQDMzMzNT09FAZ2ZmZnYY0kCamZmZmV3SQM3MzMy8otJAAAAAAODn0kAzMzMzAy3TQGdmZmYmctNAmpmZmUm300DNzMzMbPzTQAAAAACQQdRAMzMzM7OG1EBnZmZm1svUQJqZmZn5ENVAzczMzBxW1UAAAAAAQJvVQDMzMzNj4NVAZ2ZmZoYl1kCamZmZqWrWQM3MzMzMr9ZAAAAAAPD01kAzMzMzEzrXQGdmZmY2f9dAmpmZmVnE10DNzMzMfAnYQAAAAACgTthAMzMzM8OT2EBnZmZm5tjYQJqZmZkJHtlAzczMzCxj2UAAAAAAUKjZQDQzMzNz7dlAZ2ZmZpYy2kCamZmZuXfaQM3MzMzcvNpAAAAAAAAC20A=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[100]},\"top\":{\"__ndarray__\":\"TDhFg5YVbT+JTZDME4n7PtMKDQpDB+Y+1QoNCkMH1j7VCg0KQwfWPgAAAAAAAAAA1QoNCkMHxj7VCg0KQwfGPgAAAAAAAAAA2goNCkMHxj4AAAAAAAAAAAAAAAAAAAAA2goNCkMHxj4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA5QoNCkMHxj4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOUKDQpDB8Y+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA5QoNCkMHxj4=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[100]}},\"selected\":{\"id\":\"1139\"},\"selection_policy\":{\"id\":\"1138\"}},\"id\":\"1117\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"axis\":{\"id\":\"1104\"},\"dimension\":1,\"ticker\":null},\"id\":\"1107\",\"type\":\"Grid\"},{\"attributes\":{\"source\":{\"id\":\"1117\"}},\"id\":\"1121\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1133\",\"type\":\"AllLabels\"}],\"root_ids\":[\"1089\"]},\"title\":\"Bokeh Application\",\"version\":\"2.3.3\"}};\n  var render_items = [{\"docid\":\"e53260a5-935c-4dd4-a28d-31b41e21e7a8\",\"root_ids\":[\"1089\"],\"roots\":{\"1089\":\"119dc53a-5f95-4ac6-939a-05cf378af27f\"}}];\n  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n\n  }\n  if (root.Bokeh !== undefined) {\n    embed_document(root);\n  } else {\n    var attempts = 0;\n    var timer = setInterval(function(root) {\n      if (root.Bokeh !== undefined) {\n        clearInterval(timer);\n        embed_document(root);\n      } else {\n        attempts++;\n        if (attempts > 100) {\n          clearInterval(timer);\n          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n        }\n      }\n    }, 10, root)\n  }\n})(window);","application/vnd.bokehjs_exec.v0+json":""},"metadata":{"application/vnd.bokehjs_exec.v0+json":{"id":"1089"}}}],"metadata":{"id":"sWbtHr93NFl2","colab":{"base_uri":"https://localhost:8080/","height":671},"executionInfo":{"status":"ok","timestamp":1629337839279,"user_tz":300,"elapsed":19,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"eaac29e0-847b-4dde-bb20-2c0f06e479e5"}},{"cell_type":"markdown","source":["# Project 6: Reducing Noise by Strategically Reducing the Vocabulary<a id='project_6'></a>\n","\n","**TODO:** Improve `SentimentNetwork`'s performance by reducing more noise in the vocabulary. Specifically, do the following:\n","* Copy the `SentimentNetwork` class from the previous project into the following cell.\n","* Modify `pre_process_data`:\n",">* Add two additional parameters: `min_count` and `polarity_cutoff`\n",">* Calculate the positive-to-negative ratios of words used in the reviews. (You can use code you've written elsewhere in the notebook, but we are moving it into the class like we did with other helper code earlier.)\n",">* Andrew's solution only calculates a postive-to-negative ratio for words that occur at least 50 times. This keeps the network from attributing too much sentiment to rarer words. You can choose to add this to your solution if you would like.  \n",">* Change so words are only added to the vocabulary if they occur in the vocabulary more than `min_count` times.\n",">* Change so words are only added to the vocabulary if the absolute value of their postive-to-negative ratio is at least `polarity_cutoff`\n","* Modify `__init__`:\n",">* Add the same two parameters (`min_count` and `polarity_cutoff`) and use them when you call `pre_process_data`"],"metadata":{"id":"NHuo5bKaNFl2"}},{"cell_type":"code","execution_count":null,"source":["# TODO: -Copy the SentimentNetwork class from Project 5 lesson\n","#       -Modify it according to the above instructions \n","# TODO: -Copy the SentimentNetwork class from Project 4 lesson\n","#       -Modify it according to the above instructions \n","#       -Modify it to reduce noise, like in the video \n","import time\n","import sys\n","import numpy as np\n","\n","# Encapsulate our neural network in a class\n","class SentimentNetwork:\n","    def __init__(self, reviews, labels, hidden_nodes = 10, learning_rate = 0.1,min_count=50,polarity_cutoff=1):\n","        \"\"\"Create a SentimenNetwork with the given settings\n","        Args:\n","            reviews(list) - List of reviews used for training\n","            labels(list) - List of POSITIVE/NEGATIVE labels associated with the given reviews\n","            hidden_nodes(int) - Number of nodes to create in the hidden layer\n","            learning_rate(float) - Learning rate to use while training\n","        \n","        \"\"\"\n","        # Assign a seed to our random number generator to ensure we get\n","        # reproducable results during development \n","        np.random.seed(1)\n","\n","        # process the reviews and their associated labels so that everything\n","        # is ready for training\n","        self.pre_process_data(reviews, labels ,min_count,polarity_cutoff)\n","        \n","        # Build the network to have the number of hidden nodes and the learning rate that\n","        # were passed into this initializer. Make the same number of input nodes as\n","        # there are vocabulary words and create a single output node.\n","        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n","\n","    def pre_process_data(self, reviews, labels,min_count,polarity_cutoff):\n","        positive_counts = Counter()\n","        negative_counts = Counter()\n","        total_counts = Counter()\n","        pos_neg_ratios = Counter()\n","        review_vocab = set()\n","        # TODO: populate review_vocab with all of the words in the given reviews\n","        #       Remember to split reviews into individual words \n","        #       using \"split(' ')\" instead of \"split()\".\n","        \n","        for index,label in enumerate(labels):\n","            words = reviews[index].split(' ')\n","            if label == 'POSITIVE':\n","                for word in words:\n","                    positive_counts[word]+=1\n","                    total_counts[word]+=1\n","                    #review_vocab.add(word)\n","            else:\n","                for word in words:\n","                    negative_counts[word]+=1\n","                    total_counts[word]+=1\n","                    \n","        for word in total_counts:\n","            count = total_counts[word]\n","            positive_count = positive_counts[word]\n","            negative_count = negative_counts[word] + 1\n","            word_positive_ratio  =  positive_count/negative_count\n","            word_positive_ratio = np.log(word_positive_ratio) if word_positive_ratio > 1 else  -np.log(1/(word_positive_ratio + 0.01))\n","            \n","            if (count > min_count and abs(word_positive_ratio)>= polarity_cutoff) or count > min_count:\n","                review_vocab.add(word)\n","        # Convert the vocabulary set to a list so we can access words via indices\n","        self.review_vocab = list(review_vocab)\n","        \n","        label_vocab = set()\n","        # TODO: populate label_vocab with all of the words in the given labels.\n","        #       There is no need to split the labels because each one is a single word.\n","        \n","        for label in labels:\n","            label_vocab.add(label)\n","        # Convert the label vocabulary set to a list so we can access labels via indices\n","        self.label_vocab = list(label_vocab)\n","        \n","        # Store the sizes of the review and label vocabularies.\n","        self.review_vocab_size = len(self.review_vocab)\n","        self.label_vocab_size = len(self.label_vocab)\n","        \n","        # Create a dictionary of words in the vocabulary mapped to index positions\n","        self.word2index = {}\n","        # TODO: populate self.word2index with indices for all the words in self.review_vocab\n","        #       like you saw earlier in the notebook\n","        for index,word in enumerate(self.review_vocab):\n","            self.word2index[word] = index\n","        # Create a dictionary of labels mapped to index positions\n","        self.label2index = {}\n","        # TODO: do the same thing you did for self.word2index and self.review_vocab, \n","        #       but for self.label2index and self.label_vocab instead\n","        for index,label in enumerate(self.label_vocab):\n","            self.label2index[label] = index\n","            \n","        \n","    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n","        # Store the number of nodes in input, hidden, and output layers.\n","        self.input_nodes = input_nodes\n","        self.hidden_nodes = hidden_nodes\n","        self.output_nodes = output_nodes\n","\n","        # Store the learning rate\n","        self.learning_rate = learning_rate\n","\n","        # Initialize weights\n","        \n","        # TODO: initialize self.weights_0_1 as a matrix of zeros. These are the weights between\n","        #       the input layer and the hidden layer.\n","        self.weights_0_1 = np.zeros((input_nodes,hidden_nodes))\n","        \n","        # TODO: initialize self.weights_1_2 as a matrix of random values. \n","        #       These are the weights between the hidden layer and the output layer.\n","        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, \n","                                                (self.hidden_nodes, self.output_nodes))\n","        \n","        # TODO: Create the input layer, a two-dimensional matrix with shape \n","        #       1 x input_nodes, with all values initialized to zero\n","        self.layer_1 = np.zeros((1,hidden_nodes))\n","    \n","                \n","    def get_target_for_label(self,label):\n","        # TODO: Copy the code you wrote for get_target_for_label \n","        #       earlier in this notebook. \n","        return 0 if label == 'NEGATIVE' else 1\n","        \n","    def sigmoid(self,x):\n","        # TODO: Return the result of calculating the sigmoid activation function\n","        #       shown in the lectures\n","        return 1 / ( 1 + np.exp(-x))\n","    \n","    def sigmoid_output_2_derivative(self,output):\n","        # TODO: Return the derivative of the sigmoid activation function, \n","        #       where \"output\" is the original output from the sigmoid fucntion \n","        return output * (1 - output)\n","\n","    def train(self, training_reviews_raw, training_labels):\n","        \n","        # make sure out we have a matching number of reviews and labels\n","        assert(len(training_reviews_raw) == len(training_labels))\n","        #create a list of lists, each inner list contains the word2index index for a review\n","        training_reviews = list()\n","        \n","\n","        for review in training_reviews_raw:\n","            review_indices = set()\n","            words = review.split(' ')\n","            for word in words:\n","                if word in self.word2index:\n","                    review_indices.add(self.word2index[word])\n","            training_reviews.append(list(review_indices))\n","        # Keep track of correct predictions to display accuracy during training \n","        correct_so_far = 0\n","        \n","        # Remember when we started for printing time statistics\n","        start = time.time()\n","\n","        # loop through all the given reviews and run a forward and backward pass,\n","        # updating weights for every item\n","        for i in range(len(training_reviews)):\n","            \n","            # TODO: Get the next review and its correct label\n","            review = training_reviews[i]\n","            label = training_labels[i]\n","            # TODO: Implement the forward pass through the network. \n","            #       That means use the given review to update the input layer, \n","            #       then calculate values for the hidden layer,\n","            #       and finally calculate the output layer.\n","            # \n","            #       Do not use an activation function for the hidden layer,\n","            #       but use the sigmoid activation function for the output layer.\n","            \n","            #TODO:update hidden layer so self.layer_1 is used and its calculated optimally\n","            #print(\"words:\",review)\n","            self.layer_1 *= 0\n","            self.layer_1 = sum(self.weights_0_1[review])\n","            \n","            output_layer_logits = np.dot(self.layer_1,self.weights_1_2)\n","            output_layer_predictions = self.sigmoid(output_layer_logits)\n","\n","            #print(\"output layer\",output_layer_predictions.shape)\n","            # TODO: Implement the back propagation pass here. (only update used weights)\n","            #       That means calculate the error for the forward pass's prediction\n","            #       and update the weights in the network according to their\n","            #       contributions toward the error, as calculated via the\n","            #       gradient descent and back propagation algorithms you \n","            #       learned in class.\n","            error = output_layer_predictions - self.get_target_for_label(label)\n","            output_error_term = error*self.sigmoid_output_2_derivative(output_layer_predictions)\n","            hidden_error_term = self.weights_1_2*output_error_term\n","            \n","            delta_weights_h_o =  output_error_term * self.layer_1\n","            #TODO:Only update weights with input  = 1\n","            delta_weights_i_h = hidden_error_term#*layer0 #\n","            self.weights_1_2-= (self.learning_rate*delta_weights_h_o).reshape(self.weights_1_2.shape)\n","            self.weights_0_1[review]-= (self.learning_rate*delta_weights_i_h).T\n","            # Keep track of correct predictions.\n","            if(output_layer_predictions >= 0.5 and label == 'POSITIVE'):\n","                correct_so_far += 1\n","            elif(output_layer_predictions < 0.5 and label == 'NEGATIVE'):\n","                correct_so_far += 1\n","            \n","            # For debug purposes, print out our prediction accuracy and speed \n","            # throughout the training process. \n","\n","            elapsed_time = float(time.time() - start)\n","            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n","            \n","            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] \\\n","                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n","                             + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) \\\n","                             + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n","            if(i % 2500 == 0):\n","                print(\"\")\n","    \n","    def test(self, testing_reviews, testing_labels):\n","        \"\"\"\n","        Attempts to predict the labels for the given testing_reviews,\n","        and uses the test_labels to calculate the accuracy of those predictions.\n","        \"\"\"\n","        \n","        # keep track of how many correct predictions we make\n","        correct = 0\n","\n","        # we'll time how many predictions per second we make\n","        start = time.time()\n","\n","        # Loop through each of the given reviews and call run to predict\n","        # its label. \n","        for i in range(len(testing_reviews)):\n","            pred = self.run(testing_reviews[i])\n","            if(pred == testing_labels[i]):\n","                correct += 1\n","            \n","            # For debug purposes, print out our prediction accuracy and speed \n","            # throughout the prediction process. \n","\n","            elapsed_time = float(time.time() - start)\n","            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n","            \n","            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n","                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n","                             + \" #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) \\\n","                             + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n","    \n","    def run(self, review):\n","        \"\"\"\n","        Returns a POSITIVE or NEGATIVE prediction for the given review.\n","        \"\"\"\n","        # TODO: Run a forward pass through the network, like you did in the\n","        #       \"train\" function. That means use the given review to \n","        #       update the input layer, then calculate values for the hidden layer,\n","        #       and finally calculate the output layer.\n","        #\n","        #       Note: The review passed into this function for prediction \n","        #             might come from anywhere, so you should convert it \n","        #             to lower case prior to using it.\n","        review = review.lower()\n","        review_indices = set()\n","        \n","        words = review.split(' ')\n","        for word in words:\n","            if word in self.word2index:\n","                review_indices.add(self.word2index[word])\n","            \n","            \n","        hidden_output = sum(self.weights_0_1[list(review_indices)])\n","        output_logits = np.dot(hidden_output,self.weights_1_2)\n","        output = self.sigmoid(output_logits)\n","        # TODO: The output layer should now contain a prediction. \n","        #       Return `POSITIVE` for predictions greater-than-or-equal-to `0.5`, \n","        #       and `NEGATIVE` otherwise.\n","        return \"POSITIVE\" if output >= 0.5 else \"NEGATIVE\""],"outputs":[],"metadata":{"collapsed":true,"id":"qlXY9BXRNFl2"}},{"cell_type":"markdown","source":["Run the following cell to train your network with a small polarity cutoff."],"metadata":{"id":"VX4W_TBRNFl3"}},{"cell_type":"code","execution_count":null,"source":["mlp = SentimentNetwork(reviews[:-1000],labels[:-1000],min_count=20,polarity_cutoff=0.05,learning_rate=0.01)\n","mlp.train(reviews[:-1000],labels[:-1000])"],"outputs":[{"output_type":"stream","name":"stdout","text":["Progress:0.0% Speed(reviews/sec):0.0 #Correct:1 #Trained:1 Training Accuracy:100.%\n","Progress:10.4% Speed(reviews/sec):1683. #Correct:1955 #Trained:2501 Training Accuracy:78.1%\n","Progress:20.8% Speed(reviews/sec):1644. #Correct:3997 #Trained:5001 Training Accuracy:79.9%\n","Progress:31.2% Speed(reviews/sec):1652. #Correct:6115 #Trained:7501 Training Accuracy:81.5%\n","Progress:41.6% Speed(reviews/sec):1659. #Correct:8267 #Trained:10001 Training Accuracy:82.6%\n","Progress:52.0% Speed(reviews/sec):1659. #Correct:10425 #Trained:12501 Training Accuracy:83.3%\n","Progress:62.4% Speed(reviews/sec):1661. #Correct:12562 #Trained:15001 Training Accuracy:83.7%\n","Progress:72.9% Speed(reviews/sec):1660. #Correct:14662 #Trained:17501 Training Accuracy:83.7%\n","Progress:83.3% Speed(reviews/sec):1662. #Correct:16827 #Trained:20001 Training Accuracy:84.1%\n","Progress:93.7% Speed(reviews/sec):1663. #Correct:19006 #Trained:22501 Training Accuracy:84.4%\n","Progress:99.9% Speed(reviews/sec):1663. #Correct:20328 #Trained:24001 Training Accuracy:84.6%"]}],"metadata":{"id":"gEwcIndLNFl3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337862438,"user_tz":300,"elapsed":22546,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"29b53761-70c7-4b18-ec5b-4af023fd549f"}},{"cell_type":"markdown","source":["And run the following cell to test it's performance. It should be "],"metadata":{"id":"b-HWLXzLNFl4"}},{"cell_type":"code","execution_count":null,"source":["mlp.test(reviews[-1000:],labels[-1000:])"],"outputs":[{"output_type":"stream","name":"stdout","text":["Progress:99.9% Speed(reviews/sec):1444. #Correct:859 #Tested:1000 Testing Accuracy:85.9%"]}],"metadata":{"id":"yntmsPOqNFl4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337863110,"user_tz":300,"elapsed":707,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"5b24efb4-9060-43c9-ecb6-14082b813110"}},{"cell_type":"markdown","source":["Run the following cell to train your network with a much larger polarity cutoff."],"metadata":{"id":"iGvm4XItNFl4"}},{"cell_type":"code","execution_count":null,"source":["mlp = SentimentNetwork(reviews[:-1000],labels[:-1000],min_count=20,polarity_cutoff=0.8,learning_rate=0.01)\n","mlp.train(reviews[:-1000],labels[:-1000])"],"outputs":[{"output_type":"stream","name":"stdout","text":["Progress:0.0% Speed(reviews/sec):0.0 #Correct:1 #Trained:1 Training Accuracy:100.%\n","Progress:10.4% Speed(reviews/sec):1645. #Correct:1955 #Trained:2501 Training Accuracy:78.1%\n","Progress:20.8% Speed(reviews/sec):1645. #Correct:3997 #Trained:5001 Training Accuracy:79.9%\n","Progress:31.2% Speed(reviews/sec):1640. #Correct:6115 #Trained:7501 Training Accuracy:81.5%\n","Progress:41.6% Speed(reviews/sec):1641. #Correct:8267 #Trained:10001 Training Accuracy:82.6%\n","Progress:52.0% Speed(reviews/sec):1646. #Correct:10425 #Trained:12501 Training Accuracy:83.3%\n","Progress:62.4% Speed(reviews/sec):1650. #Correct:12562 #Trained:15001 Training Accuracy:83.7%\n","Progress:72.9% Speed(reviews/sec):1660. #Correct:14662 #Trained:17501 Training Accuracy:83.7%\n","Progress:83.3% Speed(reviews/sec):1660. #Correct:16827 #Trained:20001 Training Accuracy:84.1%\n","Progress:93.7% Speed(reviews/sec):1651. #Correct:19006 #Trained:22501 Training Accuracy:84.4%\n","Progress:99.9% Speed(reviews/sec):1651. #Correct:20328 #Trained:24001 Training Accuracy:84.6%"]}],"metadata":{"id":"hWJ4MUn4NFl5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337885859,"user_tz":300,"elapsed":22760,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"e0cdfa63-6cc9-4c94-ecda-7e3854a99e56"}},{"cell_type":"markdown","source":["And run the following cell to test it's performance."],"metadata":{"id":"Bkm4F7huNFl6"}},{"cell_type":"code","execution_count":null,"source":["mlp.test(reviews[-1000:],labels[-1000:])"],"outputs":[{"output_type":"stream","name":"stdout","text":["Progress:99.9% Speed(reviews/sec):1404. #Correct:859 #Tested:1000 Testing Accuracy:85.9%"]}],"metadata":{"id":"U6Zcyl1ZNFl6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337886622,"user_tz":300,"elapsed":792,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"aa791bef-cf0a-44a6-a764-5dc4f574538d"}},{"cell_type":"code","execution_count":null,"source":["mlp = SentimentNetwork(reviews[:-1000],labels[:-1000],min_count=200,polarity_cutoff=2.2,learning_rate=0.01)\n","mlp.train(reviews[:-1000],labels[:-1000])"],"outputs":[{"output_type":"stream","name":"stdout","text":["Progress:0.0% Speed(reviews/sec):0.0 #Correct:1 #Trained:1 Training Accuracy:100.%\n","Progress:10.4% Speed(reviews/sec):1769. #Correct:1912 #Trained:2501 Training Accuracy:76.4%\n","Progress:20.8% Speed(reviews/sec):1734. #Correct:3935 #Trained:5001 Training Accuracy:78.6%\n","Progress:31.2% Speed(reviews/sec):1746. #Correct:6018 #Trained:7501 Training Accuracy:80.2%\n","Progress:41.6% Speed(reviews/sec):1755. #Correct:8138 #Trained:10001 Training Accuracy:81.3%\n","Progress:52.0% Speed(reviews/sec):1751. #Correct:10271 #Trained:12501 Training Accuracy:82.1%\n","Progress:62.4% Speed(reviews/sec):1753. #Correct:12385 #Trained:15001 Training Accuracy:82.5%\n","Progress:72.9% Speed(reviews/sec):1746. #Correct:14471 #Trained:17501 Training Accuracy:82.6%\n","Progress:83.3% Speed(reviews/sec):1742. #Correct:16618 #Trained:20001 Training Accuracy:83.0%\n","Progress:93.7% Speed(reviews/sec):1742. #Correct:18777 #Trained:22501 Training Accuracy:83.4%\n","Progress:99.9% Speed(reviews/sec):1740. #Correct:20081 #Trained:24001 Training Accuracy:83.6%"]}],"metadata":{"id":"Wm4qNKzyNFl6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337908450,"user_tz":300,"elapsed":21831,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"e9d67689-1cf2-402a-e8e3-1e0150157f22"}},{"cell_type":"code","execution_count":null,"source":["mlp.test(reviews[-1000:],labels[-1000:])"],"outputs":[{"output_type":"stream","name":"stdout","text":["Progress:99.9% Speed(reviews/sec):1577. #Correct:847 #Tested:1000 Testing Accuracy:84.7%"]}],"metadata":{"id":"-jiYO-2ENFl8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337908978,"user_tz":300,"elapsed":557,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"9c49bc20-adbd-4116-b092-baa7fec1a5bf"}},{"cell_type":"markdown","source":["# End of Project 6. \n"],"metadata":{"id":"CMqtFnRRNFl8"}},{"cell_type":"markdown","source":["# Analysis: What's Going on in the Weights?<a id='lesson_7'></a>"],"metadata":{"collapsed":true,"id":"nD1TOgmvNFl9"}},{"cell_type":"code","execution_count":null,"source":["mlp_full = SentimentNetwork(reviews[:-1000],labels[:-1000],min_count=0,polarity_cutoff=0,learning_rate=0.01)"],"outputs":[],"metadata":{"collapsed":true,"id":"tNywVFR2NFl9"}},{"cell_type":"code","execution_count":null,"source":["mlp_full.train(reviews[:-1000],labels[:-1000])"],"outputs":[{"output_type":"stream","name":"stdout","text":["Progress:0.0% Speed(reviews/sec):0.0 #Correct:1 #Trained:1 Training Accuracy:100.%\n","Progress:10.4% Speed(reviews/sec):1643. #Correct:1962 #Trained:2501 Training Accuracy:78.4%\n","Progress:20.8% Speed(reviews/sec):1630. #Correct:4002 #Trained:5001 Training Accuracy:80.0%\n","Progress:31.2% Speed(reviews/sec):1615. #Correct:6120 #Trained:7501 Training Accuracy:81.5%\n","Progress:41.6% Speed(reviews/sec):1608. #Correct:8271 #Trained:10001 Training Accuracy:82.7%\n","Progress:52.0% Speed(reviews/sec):1598. #Correct:10431 #Trained:12501 Training Accuracy:83.4%\n","Progress:62.4% Speed(reviews/sec):1599. #Correct:12565 #Trained:15001 Training Accuracy:83.7%\n","Progress:72.9% Speed(reviews/sec):1602. #Correct:14670 #Trained:17501 Training Accuracy:83.8%\n","Progress:83.3% Speed(reviews/sec):1601. #Correct:16833 #Trained:20001 Training Accuracy:84.1%\n","Progress:93.7% Speed(reviews/sec):1604. #Correct:19015 #Trained:22501 Training Accuracy:84.5%\n","Progress:99.9% Speed(reviews/sec):1607. #Correct:20336 #Trained:24001 Training Accuracy:84.7%"]}],"metadata":{"id":"qBHmsLuBNFl9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337932725,"user_tz":300,"elapsed":17988,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"e290cbaf-9242-4034-e4c1-e4ef1e3d7f4f"}},{"cell_type":"markdown","source":["<img src=\"https://raw.githubusercontent.com/llealgt/moview_review_sentiment_prediction_neural_network/master/sentiment_network_sparse.png\">"],"metadata":{"id":"RrFgJ3T3sClN"}},{"cell_type":"code","execution_count":null,"source":["def get_most_similar_words(focus = \"horrible\"):\n","    most_similar = Counter()\n","\n","    for word in mlp_full.word2index.keys():\n","        most_similar[word] = np.dot(mlp_full.weights_0_1[mlp_full.word2index[word]],mlp_full.weights_0_1[mlp_full.word2index[focus]])\n","    \n","    return most_similar.most_common()"],"outputs":[],"metadata":{"collapsed":true,"id":"TDBjvi3aNFmA"}},{"cell_type":"code","execution_count":null,"source":["get_most_similar_words(\"excellent\")"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('excellent', 0.13672950757352473),\n"," ('perfect', 0.12548286087225946),\n"," ('amazing', 0.09182763392599971),\n"," ('today', 0.09022366269441422),\n"," ('wonderful', 0.0893559769622146),\n"," ('fun', 0.0875044666742069),\n"," ('great', 0.08714175888229206),\n"," ('best', 0.08581088561788061),\n"," ('liked', 0.07769762912384341),\n"," ('definitely', 0.07667096405563839),\n"," ('brilliant', 0.07346604141795139),\n"," ('loved', 0.07328542892812215),\n"," ('favorite', 0.07278113603616077),\n"," ('superb', 0.07173620717850507),\n"," ('fantastic', 0.07092219191626623),\n"," ('job', 0.0692027998563064),\n"," ('incredible', 0.0664240779526144),\n"," ('enjoyable', 0.0656325605028888),\n"," ('rare', 0.06481921266261509),\n"," ('highly', 0.06388945335097052),\n"," ('enjoyed', 0.06212754610181297),\n"," ('wonderfully', 0.06205517860409017),\n"," ('perfectly', 0.061093208811887394),\n"," ('fascinating', 0.06066354793749387),\n"," ('bit', 0.05969760969432539),\n"," ('gem', 0.05951085929615679),\n"," ('outstanding', 0.05886080814708301),\n"," ('beautiful', 0.058613934703162056),\n"," ('surprised', 0.05831549713123532),\n"," ('worth', 0.05765748423647122),\n"," ('especially', 0.057422020781760806),\n"," ('refreshing', 0.057310532092265776),\n"," ('entertaining', 0.05661203383562924),\n"," ('hilarious', 0.05616854103228666),\n"," ('masterpiece', 0.05499398864943156),\n"," ('simple', 0.05448408313492409),\n"," ('subtle', 0.05436888303350863),\n"," ('funniest', 0.05345716487130268),\n"," ('solid', 0.052903564743620665),\n"," ('awesome', 0.05248919420277041),\n"," ('always', 0.05226032852534526),\n"," ('noir', 0.0515301947264069),\n"," ('guys', 0.051109413645642685),\n"," ('sweet', 0.050818930317526004),\n"," ('unique', 0.05067016226358919),\n"," ('very', 0.05017517759720084),\n"," ('heart', 0.04994805849824361),\n"," ('moving', 0.04942460116437913),\n"," ('atmosphere', 0.0488846835445852),\n"," ('strong', 0.04857088063175921),\n"," ('remember', 0.048479036942291276),\n"," ('believable', 0.04841538439160377),\n"," ('shows', 0.048336045608039606),\n"," ('love', 0.047310648160924645),\n"," ('beautifully', 0.04711871744081491),\n"," ('both', 0.04695727890148035),\n"," ('terrific', 0.04668659797575663),\n"," ('touching', 0.046589962377280976),\n"," ('fine', 0.04625643132885577),\n"," ('caught', 0.04616332622478236),\n"," ('recommended', 0.0458763411608853),\n"," ('jack', 0.04535290997518832),\n"," ('everyone', 0.04514527396459937),\n"," ('episodes', 0.04506445706262128),\n"," ('classic', 0.04498581663793276),\n"," ('will', 0.04496667255793047),\n"," ('appreciate', 0.04476413958457087),\n"," ('powerful', 0.04417644262185278),\n"," ('realistic', 0.043597482283464814),\n"," ('performances', 0.043020249087841744),\n"," ('human', 0.042657925475092555),\n"," ('expecting', 0.04258844299521223),\n"," ('each', 0.042163774519666956),\n"," ('delightful', 0.04181500717023552),\n"," ('cry', 0.04175096839593481),\n"," ('enjoy', 0.04166009179781807),\n"," ('you', 0.041465994778271106),\n"," ('surprisingly', 0.041393139256517365),\n"," ('think', 0.04110372057105706),\n"," ('performance', 0.04084425942089682),\n"," ('nice', 0.04001650666693177),\n"," ('paced', 0.039944488647599634),\n"," ('true', 0.03975059264337067),\n"," ('tight', 0.03942543882555264),\n"," ('similar', 0.03922238017068349),\n"," ('friendship', 0.0391101127642043),\n"," ('somewhat', 0.03906961573101024),\n"," ('beauty', 0.03813092255473877),\n"," ('short', 0.037981700131409196),\n"," ('life', 0.03771663926531024),\n"," ('stunning', 0.03750736483254377),\n"," ('still', 0.037479827910101494),\n"," ('normal', 0.03742214466943512),\n"," ('works', 0.03725583018634418),\n"," ('appreciated', 0.03715616513806625),\n"," ('mind', 0.037080739403157786),\n"," ('twists', 0.03693255247307412),\n"," ('knowing', 0.036786021801572075),\n"," ('captures', 0.0364675068844947),\n"," ('certain', 0.036348359494082834),\n"," ('later', 0.03621004278676522),\n"," ('finest', 0.03613210182786267),\n"," ('compelling', 0.03609846491893577),\n"," ('others', 0.03609012020219611),\n"," ('tragic', 0.03600500358047278),\n"," ('viewing', 0.035933572455523),\n"," ('above', 0.03588671784974258),\n"," ('them', 0.03571751328155576),\n"," ('matter', 0.03560271061968564),\n"," ('future', 0.035323777987573406),\n"," ('good', 0.03529231348818509),\n"," ('hooked', 0.035154077227308),\n"," ('world', 0.03509877780645501),\n"," ('unexpected', 0.03507844250295778),\n"," ('innocent', 0.03476536069672922),\n"," ('tears', 0.03433830992700885),\n"," ('certainly', 0.034301037742714126),\n"," ('available', 0.03426810110948802),\n"," ('unlike', 0.03425398884344659),\n"," ('season', 0.03403892242701162),\n"," ('vhs', 0.03401151928101813),\n"," ('superior', 0.03391762273249577),\n"," ('genre', 0.0338082980569596),\n"," ('unusual', 0.03379779968823937),\n"," ('criminal', 0.033744472720326844),\n"," ('makes', 0.033587001877476645),\n"," ('greatest', 0.033431852271975364),\n"," ('small', 0.03342652987053841),\n"," ('episode', 0.033336443796849906),\n"," ('deal', 0.0333361076652819),\n"," ('now', 0.033283339034235505),\n"," ('quiet', 0.03314793597752928),\n"," ('played', 0.03310878220153682),\n"," ('day', 0.03307494973128655),\n"," ('moved', 0.032873980754099905),\n"," ('underrated', 0.03273881819272633),\n"," ('society', 0.03261358041861624),\n"," ('focuses', 0.03260733385838283),\n"," ('intense', 0.03256431861385499),\n"," ('sharp', 0.032309211040923345),\n"," ('adds', 0.032236076588351786),\n"," ('check', 0.03203054114966881),\n"," ('take', 0.03175932284193097),\n"," ('deeply', 0.03169309945845458),\n"," ('games', 0.03166349528572018),\n"," ('pre', 0.031251131973427125),\n"," ('change', 0.031183353959862586),\n"," ('thanks', 0.031172398048464705),\n"," ('own', 0.031121337943347076),\n"," ('easy', 0.03108847934052966),\n"," ('pace', 0.030934361491678233),\n"," ('parts', 0.03085018602862831),\n"," ('truly', 0.030836637734471664),\n"," ('thought', 0.030749620026669772),\n"," ('tony', 0.03073943481174503),\n"," ('inspired', 0.030725453849735025),\n"," ('complex', 0.03046462267670203),\n"," ('worlds', 0.030391255174782052),\n"," ('language', 0.03026497620030958),\n"," ('soundtrack', 0.030210032139046033),\n"," ('steals', 0.030207167115964797),\n"," ('glad', 0.029812003262142273),\n"," ('ride', 0.0298017948097517),\n"," ('came', 0.02976062831303152),\n"," ('impact', 0.029695785634015856),\n"," ('personally', 0.02967747701225488),\n"," ('gritty', 0.029540021762615),\n"," ('effective', 0.029512382123355347),\n"," ('wise', 0.02951040870183034),\n"," ('ultimate', 0.029442440672320932),\n"," ('ways', 0.029439341792844204),\n"," ('well', 0.029280568856373652),\n"," ('sent', 0.029147924396380104),\n"," ('after', 0.02903766891553129),\n"," ('tells', 0.029004383695691503),\n"," ('along', 0.028932972901634907),\n"," ('modern', 0.02891064215934934),\n"," ('family', 0.02889738066286555),\n"," ('pleasantly', 0.028754280601052392),\n"," ('edge', 0.028744687476241263),\n"," ('american', 0.028706398764554435),\n"," ('england', 0.028640930969798126),\n"," ('grand', 0.028581102406371937),\n"," ('slowly', 0.028470328912922987),\n"," ('treat', 0.028418097520915966),\n"," ('pleasure', 0.028370704112004187),\n"," ('living', 0.028335845213660425),\n"," ('impressed', 0.028311856507726562),\n"," ('fans', 0.028234674336798965),\n"," ('suspenseful', 0.02815665872554116),\n"," ('smile', 0.02806565183459762),\n"," ('jim', 0.02791084267227756),\n"," ('saw', 0.027900239466183016),\n"," ('length', 0.02789643130127453),\n"," ('impressive', 0.02789477824336281),\n"," ('times', 0.027869981332762583),\n"," ('witty', 0.027809121334036412),\n"," ('flawless', 0.02767640930293912),\n"," ('magic', 0.027671001404746005),\n"," ('though', 0.027476270489743878),\n"," ('subtitles', 0.027431981179380473),\n"," ('stands', 0.027348518548416446),\n"," ('freedom', 0.027271908118037397),\n"," ('relationship', 0.02723114637576913),\n"," ('tape', 0.027213179198573842),\n"," ('apartment', 0.02719885916091001),\n"," ('shown', 0.02706216905870985),\n"," ('films', 0.027035590529373488),\n"," ('lot', 0.02693452737047636),\n"," ('barbara', 0.0268371410361936),\n"," ('office', 0.02677523044965629),\n"," ('damn', 0.026751196837598835),\n"," ('murder', 0.026709073212876626),\n"," ('brilliantly', 0.026701889741880664),\n"," ('learns', 0.026699872569574595),\n"," ('tends', 0.02668377436133576),\n"," ('complaint', 0.026587011626106872),\n"," ('themselves', 0.02652465893849897),\n"," ('war', 0.026518675436425342),\n"," ('violence', 0.02645062815807616),\n"," ('judge', 0.02644326777494736),\n"," ('thriller', 0.026431555027632118),\n"," ('his', 0.026370773394088616),\n"," ('finding', 0.02636227989288501),\n"," ('cast', 0.026360860883736625),\n"," ('police', 0.026352129453305277),\n"," ('once', 0.026255817642908214),\n"," ('spectacular', 0.02624546699709238),\n"," ('deserves', 0.026214508159961687),\n"," ('driven', 0.026194930792511652),\n"," ('spot', 0.02617168678056367),\n"," ('carrey', 0.026162838804053033),\n"," ('negative', 0.026161677045062226),\n"," ('suspense', 0.02611001657582281),\n"," ('flaws', 0.026085421601700295),\n"," ('brave', 0.026080835779725284),\n"," ('surprising', 0.026070851171974718),\n"," ('gives', 0.02606997804496077),\n"," ('takes', 0.026047493401813344),\n"," ('light', 0.025921067904644535),\n"," ('timing', 0.025900303450693652),\n"," ('crime', 0.02588601157263865),\n"," ('thank', 0.025873161609513366),\n"," ('century', 0.025871056310112644),\n"," ('until', 0.025870245942132535),\n"," ('nature', 0.025817942935875457),\n"," ('stellar', 0.025803971141651165),\n"," ('emotions', 0.02578380972867193),\n"," ('tremendous', 0.025772614605786566),\n"," ('overall', 0.025697835133774126),\n"," ('missed', 0.02565750102895259),\n"," ('haven', 0.0256506921771408),\n"," ('portrayal', 0.025594273657909644),\n"," ('taylor', 0.02551699271089818),\n"," ('appropriate', 0.02549590884990164),\n"," ('joan', 0.02548982985914064),\n"," ('realize', 0.025452457061382175),\n"," ('different', 0.025434073970060447),\n"," ('return', 0.025384569542597595),\n"," ('bound', 0.025380084410398837),\n"," ('noticed', 0.02530649499844078),\n"," ('constantly', 0.02528218674576247),\n"," ('first', 0.0252461008889198),\n"," ('lovable', 0.02521350049227307),\n"," ('comic', 0.025074597800944065),\n"," ('scared', 0.024995376513809515),\n"," ('fight', 0.024943209945836417),\n"," ('extraordinary', 0.024940366453083614),\n"," ('buy', 0.024803940824255574),\n"," ('know', 0.024749519416087072),\n"," ('brothers', 0.024675058346350753),\n"," ('action', 0.02466090782463527),\n"," ('needs', 0.024634851651549355),\n"," ('jerry', 0.024621484385343853),\n"," ('while', 0.02462023331368385),\n"," ('also', 0.024519480987472413),\n"," ('definite', 0.024509585305468835),\n"," ('genius', 0.024500478757646955),\n"," ('tragedy', 0.024481339186882285),\n"," ('heard', 0.024446567944460495),\n"," ('haunting', 0.024431007352898916),\n"," ('legendary', 0.024412777264908984),\n"," ('uses', 0.024358972452013995),\n"," ('years', 0.02431609489573528),\n"," ('notch', 0.024310571597216276),\n"," ('fabulous', 0.024258810824927632),\n"," ('herself', 0.02424139095749106),\n"," ('battle', 0.02420582794017813),\n"," ('ralph', 0.024205046194653322),\n"," ('provoking', 0.024106106062481814),\n"," ('ago', 0.0240245419041565),\n"," ('game', 0.02400454190151239),\n"," ('deals', 0.023947020249031),\n"," ('themes', 0.023936597120221125),\n"," ('my', 0.023928374753346037),\n"," ('which', 0.023908264765228712),\n"," ('together', 0.02388768394280823),\n"," ('record', 0.023879473557965516),\n"," ('chilling', 0.02387741367731744),\n"," ('absorbing', 0.023848541510400122),\n"," ('studios', 0.02384061097032533),\n"," ('helps', 0.023800338082370937),\n"," ('paul', 0.023782537407117967),\n"," ('drama', 0.02376668886201472),\n"," ('spots', 0.023727534480488425),\n"," ('japanese', 0.02370847543051148),\n"," ('com', 0.02366353731039337),\n"," ('meets', 0.023649415936523144),\n"," ('may', 0.023619695363961225),\n"," ('goal', 0.023571992449256608),\n"," ('out', 0.02355875377346512),\n"," ('page', 0.023530160671184873),\n"," ('con', 0.02352320081454053),\n"," ('thankfully', 0.0234050049707117),\n"," ('number', 0.023389568775323562),\n"," ('captured', 0.023351056068531183),\n"," ('joy', 0.02333885463857542),\n"," ('brought', 0.023336907813285956),\n"," ('max', 0.02325090944797587),\n"," ('superbly', 0.023239871167515608),\n"," ('those', 0.02317684500753064),\n"," ('course', 0.023170128305056534),\n"," ('inspiring', 0.023124940469820027),\n"," ('troubled', 0.0231045532881433),\n"," ('starring', 0.023098181939380305),\n"," ('famous', 0.023080990484234908),\n"," ('nowadays', 0.023041214534459814),\n"," ('gripping', 0.023039160339941953),\n"," ('identity', 0.02303835236926517),\n"," ('many', 0.02303005974896419),\n"," ('victor', 0.023028627724258652),\n"," ('michael', 0.022946522358330876),\n"," ('stop', 0.022927047859442093),\n"," ('eerie', 0.022877301562370833),\n"," ('seen', 0.02282092921742264),\n"," ('caused', 0.02279167067216753),\n"," ('moment', 0.02278906233818426),\n"," ('portraying', 0.022729334983088958),\n"," ('influence', 0.02269856902907706),\n"," ('when', 0.022541791159242774),\n"," ('touched', 0.02252563929227021),\n"," ('complicated', 0.022432126566344645),\n"," ('turns', 0.022415566693423816),\n"," ('young', 0.02241522806863201),\n"," ('award', 0.022414761392271595),\n"," ('put', 0.02232584900817718),\n"," ('trust', 0.022301497663936423),\n"," ('issues', 0.022257753376187506),\n"," ('innocence', 0.02223692899375283),\n"," ('anime', 0.022201683728338896),\n"," ('without', 0.022144543987858856),\n"," ('himself', 0.022068240705874407),\n"," ('charlie', 0.022052037301460187),\n"," ('parents', 0.02188813820237176),\n"," ('covered', 0.021887533337961756),\n"," ('final', 0.021877215769079535),\n"," ('killers', 0.02183066490039512),\n"," ('ages', 0.02177437667757559),\n"," ('usual', 0.02176098051271814),\n"," ('physical', 0.02174910319122181),\n"," ('like', 0.021730991541426752),\n"," ('crazy', 0.021727382570242995),\n"," ('puts', 0.021725737321791547),\n"," ('got', 0.021701574500289117),\n"," ('room', 0.02169096856946563),\n"," ('complaints', 0.02167042659391657),\n"," ('type', 0.02166362898294517),\n"," ('brings', 0.02160060097587544),\n"," ('remarkable', 0.02157679171939603),\n"," ('get', 0.021538325389801348),\n"," ('city', 0.02152338537831488),\n"," ('coming', 0.021492351614142778),\n"," ('traditional', 0.021430875828269802),\n"," ('romantic', 0.02142058753616854),\n"," ('cinema', 0.021411776829230962),\n"," ('regular', 0.02139588225557585),\n"," ('intelligent', 0.021391350897315444),\n"," ('music', 0.021381013806527436),\n"," ('humor', 0.021365697759571502),\n"," ('experience', 0.021314525649372917),\n"," ('favourite', 0.021253476483878247),\n"," ('social', 0.02125008525523737),\n"," ('feelings', 0.02124503089571435),\n"," ('cried', 0.02123327164107075),\n"," ('rock', 0.021213280029832356),\n"," ('against', 0.02115731411958726),\n"," ('including', 0.02115667412249141),\n"," ('honest', 0.02114345875879347),\n"," ('parallel', 0.021107353247706455),\n"," ('eddie', 0.021080182147252734),\n"," ('crafted', 0.02097919495374508),\n"," ('more', 0.02093379734319382),\n"," ('glued', 0.020931988721930157),\n"," ('insanity', 0.02091493559910115),\n"," ('thoroughly', 0.020905661542252776),\n"," ('eyes', 0.02086801329128111),\n"," ('jr', 0.020865268971014532),\n"," ('dramas', 0.020836398428109224),\n"," ('follows', 0.020814937146708422),\n"," ('situation', 0.02081482110566649),\n"," ('understood', 0.02074967709247017),\n"," ('face', 0.020701739464945062),\n"," ('albeit', 0.020680340389878416),\n"," ('memorable', 0.020608260124115523),\n"," ('accurate', 0.020585303033408754),\n"," ('under', 0.02057443069837424),\n"," ('arthur', 0.020562083939889488),\n"," ('elderly', 0.02054535047180812),\n"," ('opinion', 0.02053957092279777),\n"," ('whoopi', 0.020515675744150082),\n"," ('helped', 0.02047624233713054),\n"," ('detract', 0.020443807698341677),\n"," ('flawed', 0.020436371691432333),\n"," ('unusually', 0.020433523835905337),\n"," ('performing', 0.020396957567555735),\n"," ('smooth', 0.020347681451465382),\n"," ('magnificent', 0.020334637688102838),\n"," ('desperation', 0.020287768999057227),\n"," ('lose', 0.020277535683257873),\n"," ('satisfying', 0.02025152711027206),\n"," ('friend', 0.020227651020398925),\n"," ('kudos', 0.020201477326926624),\n"," ('breaking', 0.020117861519854306),\n"," ('elephant', 0.02011578344705705),\n"," ('colors', 0.020112155987764873),\n"," ('willing', 0.020087728040224344),\n"," ('fresh', 0.02005401912359375),\n"," ('offers', 0.020003415308141058),\n"," ('provides', 0.020002909565985043),\n"," ('guilt', 0.01998791797065958),\n"," ('shouldn', 0.01990787945802436),\n"," ('japan', 0.019906368589571694),\n"," ('secrets', 0.019876976104814398),\n"," ('obligatory', 0.01978966543184042),\n"," ('dvd', 0.019782796187823453),\n"," ('since', 0.019768441561362662),\n"," ('tale', 0.019752149872839884),\n"," ('roles', 0.019710495505208002),\n"," ('breathtaking', 0.019705824135660535),\n"," ('ground', 0.0196872365249619),\n"," ('higher', 0.01967052613953756),\n"," ('jean', 0.019665400087401586),\n"," ('rich', 0.01965309571666073),\n"," ('right', 0.019629293580435744),\n"," ('stone', 0.01961059590566911),\n"," ('lives', 0.019610348936710133),\n"," ('it', 0.019584184951949905),\n"," ('essential', 0.019533860093920413),\n"," ('tend', 0.019523404457496812),\n"," ('places', 0.019510216587218025),\n"," ('recommend', 0.01950621155981814),\n"," ('loy', 0.019481148560970926),\n"," ('tell', 0.01945028666926875),\n"," ('challenge', 0.019374490591710928),\n"," ('fiction', 0.01935060149873538),\n"," ('able', 0.019340445094151417),\n"," ('animated', 0.019333069625267093),\n"," ('complain', 0.01933202879655011),\n"," ('deeper', 0.019318681931941167),\n"," ('blew', 0.019304454395430135),\n"," ('seeing', 0.019302442445035522),\n"," ('release', 0.01920990400623913),\n"," ('unfolds', 0.019184703456013686),\n"," ('boys', 0.019177414753158407),\n"," ('favorites', 0.019160378141489527),\n"," ('throughout', 0.019136892845690676),\n"," ('marvelous', 0.019110015321943577),\n"," ('end', 0.019056602786965533),\n"," ('relax', 0.019044075162625462),\n"," ('desire', 0.019016117204605984),\n"," ('questions', 0.01897769996868485),\n"," ('man', 0.01895674449472024),\n"," ('rea', 0.018928733395777463),\n"," ('comments', 0.018923870708363082),\n"," ('vengeance', 0.018908638777923946),\n"," ('brian', 0.018906876323023594),\n"," ('learned', 0.018899947923704443),\n"," ('lovely', 0.018854980464698644),\n"," ('seasons', 0.018852496578683826),\n"," ('shines', 0.018827509959493265),\n"," ('justice', 0.018827310862034666),\n"," ('succeeds', 0.018776998522312776),\n"," ('discovered', 0.018766802216817074),\n"," ('touch', 0.0187628067388615),\n"," ('white', 0.018743225697414198),\n"," ('bitter', 0.018724701999912892),\n"," ('knows', 0.018719063288744297),\n"," ('gene', 0.01866006079655624),\n"," ('mainstream', 0.018654252436913914),\n"," ('raw', 0.018609728881254835),\n"," ('focus', 0.01860507830549493),\n"," ('won', 0.01859753787687164),\n"," ('ve', 0.018560162581379287),\n"," ('million', 0.018514133006256914),\n"," ('attention', 0.018406547682637126),\n"," ('river', 0.018403383531225694),\n"," ('although', 0.018392435622494256),\n"," ('classics', 0.018375185367387352),\n"," ('quirky', 0.018358100535754603),\n"," ('september', 0.018345012211358883),\n"," ('emotional', 0.01832716507095174),\n"," ('events', 0.01832455447591812),\n"," ('released', 0.018304767183625538),\n"," ('thus', 0.018302709016086095),\n"," ('rules', 0.018298967789718686),\n"," ('find', 0.01826218376891969),\n"," ('trilogy', 0.0182619859222885),\n"," ('jackie', 0.018261017705562578),\n"," ('country', 0.018248984107628794),\n"," ('sure', 0.01820528197054591),\n"," ('overlooked', 0.018173644592107394),\n"," ('sensitive', 0.018173518786609152),\n"," ('harsh', 0.018143998075916396),\n"," ('chair', 0.018127987063468087),\n"," ('neatly', 0.01812304461217944),\n"," ('round', 0.018082305853658363),\n"," ('adult', 0.01806071885938952),\n"," ('strength', 0.018042558269708926),\n"," ('aunt', 0.018028313353173665),\n"," ('description', 0.01799755734083396),\n"," ('perspective', 0.017974761193339697),\n"," ('closer', 0.017945066423908047),\n"," ('extra', 0.017934760731343112),\n"," ('hit', 0.017910740181690348),\n"," ('tough', 0.01790450947037624),\n"," ('work', 0.017882494289916093),\n"," ('captivating', 0.017875072308920954),\n"," ('swim', 0.01785335427201485),\n"," ('holmes', 0.017846058193393126),\n"," ('unlikely', 0.017843839699452125),\n"," ('fears', 0.01783806745175279),\n"," ('nominated', 0.01783743930452059),\n"," ('neat', 0.01782306847491318),\n"," ('discovers', 0.017801301834152468),\n"," ('paris', 0.017798057884200073),\n"," ('streets', 0.017746147480597597),\n"," ('realism', 0.017729724930388047),\n"," ('travel', 0.017694257020940293),\n"," ('keep', 0.017684400089090117),\n"," ('anyway', 0.017675995400919468),\n"," ('realizes', 0.017618932935696142),\n"," ('variety', 0.017618487604827666),\n"," ('chief', 0.01760396383436282),\n"," ('broke', 0.017601657476194958),\n"," ('craven', 0.01759761349993533),\n"," ('moves', 0.01755974422177169),\n"," ('see', 0.017554713803040207),\n"," ('intellectual', 0.017537349329235133),\n"," ('normally', 0.017511237908563515),\n"," ('technique', 0.017502265077830197),\n"," ('dancer', 0.017501395365645264),\n"," ('awe', 0.01746744664064139),\n"," ('technology', 0.017414969148737195),\n"," ('kelly', 0.01738079467163824),\n"," ('particular', 0.01738050333910924),\n"," ('awards', 0.017343067374305077),\n"," ('twisted', 0.017342731655512207),\n"," ('manager', 0.017337683585341684),\n"," ('fantasy', 0.017314736380004723),\n"," ('blake', 0.0172829639905522),\n"," ('criticism', 0.01727955867680368),\n"," ('identify', 0.01727747119984367),\n"," ('collection', 0.01725353305226094),\n"," ('sidney', 0.017239120845031552),\n"," ('ironic', 0.017225809884120882),\n"," ('score', 0.017223046869263493),\n"," ('charm', 0.017204164112517878),\n"," ('lonely', 0.017192972607511976),\n"," ('recall', 0.017189512282670277),\n"," ('dream', 0.017185607849471315),\n"," ('known', 0.01716934147304581),\n"," ('hoffman', 0.01712393702301425),\n"," ('answers', 0.01711237453169526),\n"," ('taking', 0.017102244694823316),\n"," ('color', 0.017086755659474467),\n"," ('existed', 0.01708449183478003),\n"," ('mel', 0.01708064412549848),\n"," ('treats', 0.017076365809061668),\n"," ('kennedy', 0.01706305411017942),\n"," ('millionaire', 0.017058120181534065),\n"," ('stewart', 0.017017863935395124),\n"," ('soon', 0.017016949690113508),\n"," ('style', 0.016978446616527434),\n"," ('urban', 0.01696177374188857),\n"," ('sides', 0.016958377563876276),\n"," ('nicely', 0.01695658404466507),\n"," ('survive', 0.016953201066203547),\n"," ('contrast', 0.016949017788907707),\n"," ('granted', 0.016948500759420813),\n"," ('wes', 0.016856895803564042),\n"," ('heroic', 0.016849533387674566),\n"," ('sadness', 0.016836182986070536),\n"," ('faults', 0.016833966998505423),\n"," ('ladies', 0.016818146836646262),\n"," ('walter', 0.016813645209614796),\n"," ('exceptional', 0.016810242985337294),\n"," ('dangerous', 0.016796058008032435),\n"," ('fan', 0.016737120507724367),\n"," ('witch', 0.01671708591491734),\n"," ('occasionally', 0.016711349636820475),\n"," ('its', 0.016681485589934642),\n"," ('movies', 0.016676687954063633),\n"," ('celebration', 0.016664197566723736),\n"," ('castle', 0.016661909651854555),\n"," ('catch', 0.016647995152024714),\n"," ('tribute', 0.016629617927918804),\n"," ('jimmy', 0.016625132101972973),\n"," ('bravo', 0.016616754156460054),\n"," ('enjoying', 0.016613140144305677),\n"," ('bus', 0.016593157501778106),\n"," ('documentary', 0.016564651461285357),\n"," ('frightening', 0.016559987706802778),\n"," ('is', 0.016553692092072095),\n"," ('guilty', 0.01653611025366425),\n"," ('slightly', 0.01652642172419933),\n"," ('chan', 0.016507204515006663),\n"," ('mixed', 0.0165068475673114),\n"," ('curious', 0.016506488394564575),\n"," ('spirit', 0.0165029770440991),\n"," ('pleased', 0.016487261129390265),\n"," ('most', 0.01647675933321412),\n"," ('chemistry', 0.01642535634398907),\n"," ('age', 0.01641066631492986),\n"," ('understanding', 0.016345696202945577),\n"," ('marie', 0.016341053241072705),\n"," ('dreams', 0.016332672013556315),\n"," ('again', 0.016287090973937754),\n"," ('union', 0.016282379359022565),\n"," ('spy', 0.01627815492378592),\n"," ('presented', 0.016273043238663482),\n"," ('steele', 0.016260993339006803),\n"," ('lay', 0.016259995458797857),\n"," ('plenty', 0.01624719418983283),\n"," ('horrors', 0.016246022980305596),\n"," ('black', 0.016223176851856824),\n"," ('comedy', 0.016220408022010583),\n"," ('winner', 0.016220318857398417),\n"," ('african', 0.016214456609794967),\n"," ('drummer', 0.016178152199513927),\n"," ('entertainment', 0.016173112007890973),\n"," ('delivers', 0.01616659946568308),\n"," ('stays', 0.01613947635279378),\n"," ('america', 0.016108896341111498),\n"," ('disappoint', 0.01606661593399644),\n"," ('gorgeous', 0.01606235016681506),\n"," ('sisters', 0.016060080355840688),\n"," ('subsequent', 0.01604357420387397),\n"," ('cerebral', 0.016039058904070033),\n"," ('french', 0.01603842531736319),\n"," ('perfection', 0.01603315486934693),\n"," ('likable', 0.016021713396124564),\n"," ('warm', 0.01601914409582735),\n"," ('studio', 0.016007232818464584),\n"," ('late', 0.015997923350457077),\n"," ('reality', 0.015978872249423737),\n"," ('showed', 0.01593875064432394),\n"," ('figures', 0.01592744660892325),\n"," ('ever', 0.015926454600790646),\n"," ('italy', 0.015909186780479364),\n"," ('accustomed', 0.015906246911558283),\n"," ('into', 0.015892173681617976),\n"," ('he', 0.01586623993209234),\n"," ('journey', 0.015817191390925515),\n"," ('waters', 0.015800906878826317),\n"," ('bill', 0.01578597614879133),\n"," ('cousin', 0.01578438271080167),\n"," ('explores', 0.0157687563455696),\n"," ('originally', 0.015766016465315412),\n"," ('astonishing', 0.015741175347778344),\n"," ('mouse', 0.01573947307055508),\n"," ('affect', 0.015719798460443277),\n"," ('authenticity', 0.015716491136675288),\n"," ('key', 0.015706372736941265),\n"," ('authorities', 0.015700111946298504),\n"," ('fortunately', 0.015676427069879845),\n"," ('notes', 0.015668388567765482),\n"," ('disagree', 0.01565982223146425),\n"," ('advanced', 0.015653464856497618),\n"," ('contribution', 0.015651919381489545),\n"," ('flaw', 0.015630623175485563),\n"," ('burning', 0.015593951152590378),\n"," ('scoop', 0.015580911014213501),\n"," ('levels', 0.015579506047588164),\n"," ('dead', 0.015575945832152282),\n"," ('reveals', 0.015552631094426438),\n"," ('explicit', 0.01553505254238325),\n"," ('fault', 0.015532818014787654),\n"," ('requires', 0.015440001642516228),\n"," ('way', 0.015434313286947611),\n"," ('waitress', 0.015433929845739235),\n"," ('i', 0.01540102885847682),\n"," ('vividly', 0.015399209375312225),\n"," ('truman', 0.015388667015530336),\n"," ('leslie', 0.015388355420398663),\n"," ('cool', 0.015362419182460993),\n"," ('dated', 0.015351894934707871),\n"," ('ruthless', 0.015347223840634992),\n"," ('anymore', 0.01532784098857371),\n"," ('batman', 0.015325445892906495),\n"," ('york', 0.015323650797282736),\n"," ('expressions', 0.0152909435993352),\n"," ('terms', 0.015285161966075801),\n"," ('sunday', 0.015279982329904828),\n"," ('chinese', 0.015240680418926657),\n"," ('done', 0.015230733309302687),\n"," ('behind', 0.015219079842199825),\n"," ('event', 0.015214794169662841),\n"," ('chamberlain', 0.015214082741427193),\n"," ('mysteries', 0.015204556759409916),\n"," ('manages', 0.01520348693463202),\n"," ('simpsons', 0.015191849812926223),\n"," ('mine', 0.015191085212402705),\n"," ('canadian', 0.015117611742208811),\n"," ('purple', 0.015100505661562475),\n"," ('website', 0.015095063701722871),\n"," ('master', 0.015091528696557655),\n"," ('charming', 0.015088362486196548),\n"," ('joe', 0.015081920177878152),\n"," ('reservations', 0.01507782134347409),\n"," ('fever', 0.015076873583983725),\n"," ('covers', 0.015047233453258799),\n"," ('madness', 0.01503036185965722),\n"," ('glimpse', 0.014991086926970954),\n"," ('pilot', 0.014978443271049661),\n"," ('johansson', 0.014975808461544405),\n"," ('explains', 0.014970512080227469),\n"," ('excellently', 0.014970388571598853),\n"," ('hawke', 0.01496975010993136),\n"," ('genuinely', 0.014947672770702573),\n"," ('often', 0.014942833143544464),\n"," ('cube', 0.01493992870936536),\n"," ('clean', 0.014937853229023516),\n"," ('ensemble', 0.014913656909087879),\n"," ('referred', 0.014910582069880149),\n"," ('replies', 0.014907131594945564),\n"," ('disease', 0.014895193110452171),\n"," ('wish', 0.01489224554930704),\n"," ('logical', 0.014888665766304071),\n"," ('nathan', 0.0148699288516704),\n"," ('aware', 0.014869867112894512),\n"," ('exciting', 0.014823139694980628),\n"," ('gone', 0.014821497224651524),\n"," ('critics', 0.014818559383907352),\n"," ('split', 0.014788117032985612),\n"," ('series', 0.014770708703162166),\n"," ('henry', 0.014757735101897458),\n"," ('prisoners', 0.01474771018400387),\n"," ('sentenced', 0.01474621990650384),\n"," ('laughing', 0.014722151818909788),\n"," ('president', 0.014671766779490546),\n"," ('list', 0.014666775185665172),\n"," ('ones', 0.014658997854109318),\n"," ('information', 0.014651687169784221),\n"," ('bonus', 0.014648059891508167),\n"," ('chicago', 0.014631769872667602),\n"," ('someday', 0.014629340475262567),\n"," ('splendid', 0.014609703424340661),\n"," ('surprises', 0.014608824054662458),\n"," ('sentimental', 0.014591361045287946),\n"," ('admit', 0.014588098910742791),\n"," ('previously', 0.014571223247118625),\n"," ('conveys', 0.014567143509152131),\n"," ('prominent', 0.014547363114083282),\n"," ('born', 0.014536990751946694),\n"," ('necessary', 0.014533225697989462),\n"," ('yes', 0.014531704633026995),\n"," ('marvel', 0.014527554209112411),\n"," ('initially', 0.01451018771455598),\n"," ('jake', 0.014502509408478864),\n"," ('matters', 0.014497730426084203),\n"," ('lucas', 0.014496736417950714),\n"," ('stories', 0.014475382661229965),\n"," ('happy', 0.014471040644253795),\n"," ('improvement', 0.014459225025278405),\n"," ('anger', 0.01444069696929931),\n"," ('hong', 0.014412020732763245),\n"," ('devotion', 0.014406165594180762),\n"," ('infamous', 0.01440248316113687),\n"," ('sir', 0.01439058584994257),\n"," ('fashioned', 0.01437649516309287),\n"," ('clear', 0.01434001455230736),\n"," ('whenever', 0.01431198484084473),\n"," ('facing', 0.014311813694297498),\n"," ('spin', 0.01430093789094724),\n"," ('verhoeven', 0.014290838087095132),\n"," ('onto', 0.014287704198288396),\n"," ('sheriff', 0.014266680346279283),\n"," ('boy', 0.014238393212172492),\n"," ('felix', 0.014236371593101722),\n"," ('what', 0.014231196728127862),\n"," ('site', 0.014212839329217037),\n"," ('hits', 0.014208508715996897),\n"," ('convincingly', 0.014165838532387455),\n"," ('adventures', 0.014158492204346286),\n"," ('multiple', 0.014150723728410525),\n"," ('wrapped', 0.014118759103459128),\n"," ('reveal', 0.014118693302495135),\n"," ('toby', 0.014075221493111766),\n"," ('months', 0.01406198600537469),\n"," ('comedies', 0.01405030180887608),\n"," ('shot', 0.014031987455271903),\n"," ('holds', 0.01402350490448421),\n"," ('weeks', 0.014002257803042342),\n"," ('window', 0.01398543454161485),\n"," ('received', 0.01398330170962994),\n"," ('him', 0.013968181093938327),\n"," ('court', 0.013964352058193526),\n"," ('double', 0.013960483190947283),\n"," ('refuses', 0.013957613385590656),\n"," ('stand', 0.013948813859221339),\n"," ('shocked', 0.01393515724326192),\n"," ('powell', 0.013934062441977028),\n"," ('brutal', 0.013924129605946696),\n"," ('among', 0.013913156765292931),\n"," ('prostitute', 0.013911765274631796),\n"," ('nine', 0.01388234334472091),\n"," ('timeless', 0.013858274395499411),\n"," ('likes', 0.013844971514262248),\n"," ('kurosawa', 0.013820064338774897),\n"," ('fact', 0.013814297186034386),\n"," ('ass', 0.013813899781949808),\n"," ('deanna', 0.013799520782801162),\n"," ('almost', 0.013791517357271342),\n"," ('technicolor', 0.013790541990858997),\n"," ('adventure', 0.01378299990704706),\n"," ('gerard', 0.0137761404341376),\n"," ('analysis', 0.013764039325045375),\n"," ('mid', 0.013747853289146201),\n"," ('stanwyck', 0.013738927891779263),\n"," ('mann', 0.013726915645691885),\n"," ('stuart', 0.01370022906923579),\n"," ('reluctantly', 0.013697113976504024),\n"," ('humanity', 0.013690830736911047),\n"," ('classical', 0.013688949911986582),\n"," ('health', 0.013684784640613444),\n"," ('edie', 0.013683859176013944),\n"," ('british', 0.01366646025087646),\n"," ('primary', 0.0136617947140339),\n"," ('coaster', 0.013660631014138405),\n"," ('explore', 0.013656042478726912),\n"," ('china', 0.013638756081011161),\n"," ('advantage', 0.013631698822745402),\n"," ('protagonists', 0.01362759364893279),\n"," ('partly', 0.013617059618125359),\n"," ('artist', 0.013597123465502832),\n"," ('terrifying', 0.013581203319898153),\n"," ('scarlett', 0.013567078625941566),\n"," ('mesmerizing', 0.01354781689947941),\n"," ('prince', 0.013541105943095605),\n"," ('weird', 0.013535346249579569),\n"," ('vance', 0.013518150392608121),\n"," ('collect', 0.013513303578887659),\n"," ('humour', 0.013508890166677974),\n"," ('doc', 0.01350728643140293),\n"," ('history', 0.01350612020078827),\n"," ('miss', 0.013498187990897411),\n"," ('angles', 0.01349750726566544),\n"," ('dealers', 0.013493607234383902),\n"," ('mass', 0.013472328625932874),\n"," ('paramount', 0.013467546662344527),\n"," ('musicians', 0.013464517138686277),\n"," ('jackman', 0.013441428735872103),\n"," ('cheer', 0.013440230376864147),\n"," ('aired', 0.01342795754736686),\n"," ('personal', 0.013422418887670078),\n"," ('become', 0.013415910991211795),\n"," ('wang', 0.013406655764270567),\n"," ('unforgettable', 0.013405651085753999),\n"," ('theme', 0.01339799585710551),\n"," ('satisfy', 0.01336101263463745),\n"," ('beginning', 0.013353575498360075),\n"," ('tongue', 0.013332587937334753),\n"," ('ran', 0.013322580056022448),\n"," ('vh', 0.013321694862247341),\n"," ('april', 0.01331795808268902),\n"," ('cracking', 0.013316482654851879),\n"," ('hilariously', 0.013312111975215823),\n"," ('addictive', 0.013304056341282523),\n"," ('factory', 0.013302408850101538),\n"," ('bloom', 0.013287106893282026),\n"," ('outcome', 0.013278893812795744),\n"," ('startling', 0.013276469703553522),\n"," ('portrait', 0.013273055100999274),\n"," ('adapted', 0.013258514308676838),\n"," ('raines', 0.013257908724754868),\n"," ('sky', 0.013252502620889907),\n"," ('earlier', 0.013233110743632577),\n"," ('atlantis', 0.013228188610144565),\n"," ('delirious', 0.013226874818125447),\n"," ('titanic', 0.013205633401144468),\n"," ('nevertheless', 0.013198200611184945),\n"," ('proved', 0.013189760358384489),\n"," ('denzel', 0.013188430841614768),\n"," ('pleasant', 0.013180077348723368),\n"," ('horses', 0.01317865156802947),\n"," ('about', 0.013166154528006844),\n"," ('astounding', 0.01316169833722681),\n"," ('savage', 0.01315410055375993),\n"," ('winning', 0.013153246708379663),\n"," ('rose', 0.013145586701309787),\n"," ('fitting', 0.01313357825433035),\n"," ('compared', 0.013131693803520042),\n"," ('took', 0.013119343481498983),\n"," ('masterson', 0.013112762074217894),\n"," ('owner', 0.01310869045481914),\n"," ('delight', 0.013107278788311012),\n"," ('conventions', 0.013106039770696055),\n"," ('natali', 0.013094964441143222),\n"," ('message', 0.013093664295113421),\n"," ('stood', 0.013090122718303428),\n"," ('sailor', 0.013058959170423455),\n"," ('ida', 0.013058842950256241),\n"," ('escaping', 0.013052723624706783),\n"," ('top', 0.013047466741024409),\n"," ('louis', 0.013046238442637009),\n"," ('peace', 0.013040907918892319),\n"," ('several', 0.013028244887060293),\n"," ('info', 0.013023754625550193),\n"," ('graphics', 0.013020850288881851),\n"," ('reflection', 0.01301924382394011),\n"," ('slimy', 0.013014377070231842),\n"," ('elvira', 0.013009811638957062),\n"," ('andre', 0.013000047313446745),\n"," ('kong', 0.01299908031330052),\n"," ('mayor', 0.01299475840972357),\n"," ('punishment', 0.012988264949614942),\n"," ('morris', 0.012983710119604974),\n"," ('hall', 0.012981593609354813),\n"," ('match', 0.012980233583057332),\n"," ('bleak', 0.012972505086304062),\n"," ('lindy', 0.012972248933121265),\n"," ('sequence', 0.012964435808713594),\n"," ('learn', 0.01293884897008334),\n"," ('happen', 0.01293283638787376),\n"," ('john', 0.01292952497900167),\n"," ('gothic', 0.012926957011734873),\n"," ('wider', 0.012920985981480962),\n"," ('popular', 0.012891690509844088),\n"," ('diverse', 0.012875263936567813),\n"," ('compare', 0.0128693952920652),\n"," ('brooklyn', 0.012852986243263935),\n"," ('broadcast', 0.012839574692097625),\n"," ('zane', 0.012834302957709143),\n"," ('andrew', 0.01282402094061526),\n"," ('finely', 0.012822716004015864),\n"," ('confronted', 0.01281752368660863),\n"," ('going', 0.012809762839304968),\n"," ('likewise', 0.012804639349082513),\n"," ('breath', 0.012790132659417907),\n"," ('building', 0.012789809704793879),\n"," ('suggesting', 0.012780624321169344),\n"," ('contemporary', 0.012772749462937515),\n"," ('midnight', 0.012766963563112075),\n"," ('victoria', 0.012756422131580528),\n"," ('lasting', 0.01275242441564259),\n"," ('kitty', 0.012751468371946009),\n"," ('continued', 0.012744325456485402),\n"," ('indian', 0.012712962842718683),\n"," ('subplots', 0.012709887814283912),\n"," ('douglas', 0.01269383067945591),\n"," ('explosions', 0.012692697593201848),\n"," ('bond', 0.012689802823687823),\n"," ('delightfully', 0.012669417460922624),\n"," ('understated', 0.012669374312789347),\n"," ('greater', 0.012664580396020156),\n"," ('sailing', 0.012662424581282425),\n"," ('images', 0.012661803048859869),\n"," ('copy', 0.012624649645734167),\n"," ('seat', 0.012610464273152518),\n"," ('eleven', 0.012602533659978892),\n"," ('riveting', 0.01259182946009452),\n"," ('boiled', 0.01258886352963876),\n"," ('academy', 0.012581996178142976),\n"," ('whilst', 0.012569841653295643),\n"," ('heaven', 0.012547361621330926),\n"," ('fruit', 0.012543513029693256),\n"," ('reviewer', 0.012534273375083902),\n"," ('cost', 0.012529643005796605),\n"," ('week', 0.012522845015008274),\n"," ('intriguing', 0.012508687653306351),\n"," ('streak', 0.012507752385208553),\n"," ('san', 0.012502130058217934),\n"," ('awareness', 0.012476446442012451),\n"," ('catching', 0.012467108595451533),\n"," ('kicks', 0.012457714930570575),\n"," ('complexities', 0.012454362663082467),\n"," ('draws', 0.01244775328512591),\n"," ('easily', 0.012444885855614894),\n"," ('ealing', 0.01244433925570893),\n"," ('psychopath', 0.012431259926282271),\n"," ('skin', 0.012424248540973577),\n"," ('creative', 0.012386713452491531),\n"," ('recognition', 0.012354025801439425),\n"," ('downey', 0.012348698765161129),\n"," ('symbolism', 0.012329925038271334),\n"," ('touches', 0.01232801347075147),\n"," ('everyday', 0.012324934809895901),\n"," ('achieves', 0.0123148987074835),\n"," ('outcast', 0.012313662230219674),\n"," ('overwhelmed', 0.01230663313886948),\n"," ...]"]},"metadata":{},"execution_count":84}],"metadata":{"id":"hr6O-Y3TNFmA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337933187,"user_tz":300,"elapsed":478,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"2ba101fa-36bb-46cd-d8c6-83bfabb009ee"}},{"cell_type":"code","execution_count":null,"source":["get_most_similar_words(\"terrible\")"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('worst', 0.16966107259049845),\n"," ('awful', 0.12026847019691246),\n"," ('waste', 0.11945367265311006),\n"," ('poor', 0.09275888757443551),\n"," ('terrible', 0.09142538719772796),\n"," ('dull', 0.08420927167822362),\n"," ('poorly', 0.08124154451604207),\n"," ('disappointment', 0.08006475962136872),\n"," ('fails', 0.07859977372333754),\n"," ('disappointing', 0.07733948548032338),\n"," ('boring', 0.07709336533844613),\n"," ('unfortunately', 0.07550244970585908),\n"," ('worse', 0.07060183536419468),\n"," ('mess', 0.07056429962359041),\n"," ('stupid', 0.06948482283254305),\n"," ('badly', 0.06688890366622859),\n"," ('annoying', 0.06568702190337415),\n"," ('bad', 0.06309381453757217),\n"," ('save', 0.06288059749586575),\n"," ('disappointed', 0.06269235381207287),\n"," ('wasted', 0.061387183028051295),\n"," ('supposed', 0.06098545295772518),\n"," ('horrible', 0.06012177233938014),\n"," ('laughable', 0.05869840628546763),\n"," ('crap', 0.05810452866788459),\n"," ('basically', 0.05721884036963617),\n"," ('nothing', 0.0571582200430342),\n"," ('ridiculous', 0.056905481068931445),\n"," ('lacks', 0.05576656588946544),\n"," ('lame', 0.055616009058110184),\n"," ('avoid', 0.0555187260731972),\n"," ('unless', 0.054208926212940746),\n"," ('script', 0.05394835946704851),\n"," ('failed', 0.05341393055000915),\n"," ('pointless', 0.05285553154689413),\n"," ('oh', 0.05276158093317685),\n"," ('effort', 0.05077374712729233),\n"," ('guess', 0.05037957642007654),\n"," ('minutes', 0.049784532804242186),\n"," ('wooden', 0.049453108380727195),\n"," ('redeeming', 0.04918286911472175),\n"," ('seems', 0.04907962515466976),\n"," ('instead', 0.04795764512353228),\n"," ('weak', 0.04649638737476566),\n"," ('pathetic', 0.04609974114971577),\n"," ('looks', 0.04579653673024488),\n"," ('hoping', 0.045082242887577055),\n"," ('wonder', 0.0446697917809346),\n"," ('forgettable', 0.04285434925187171),\n"," ('silly', 0.04223782968726999),\n"," ('attempt', 0.04170629994137352),\n"," ('predictable', 0.04151444243856811),\n"," ('someone', 0.0415061190273373),\n"," ('sorry', 0.04086887728153336),\n"," ('might', 0.04044568350068837),\n"," ('slow', 0.04034686910703497),\n"," ('painful', 0.040220039039613256),\n"," ('thin', 0.04006264225377786),\n"," ('mediocre', 0.03940716537757739),\n"," ('garbage', 0.03931097944098111),\n"," ('money', 0.038907973313640515),\n"," ('none', 0.03830080705223096),\n"," ('bland', 0.038062246057085046),\n"," ('couldn', 0.038016664218957934),\n"," ('either', 0.037738833070341954),\n"," ('unfunny', 0.03707662980504451),\n"," ('entire', 0.03664211939946318),\n"," ('cheap', 0.03651680080252559),\n"," ('honestly', 0.03621204154379785),\n"," ('mildly', 0.03574485060818565),\n"," ('total', 0.03556045447101307),\n"," ('neither', 0.03541594604354857),\n"," ('making', 0.035244315060985604),\n"," ('problem', 0.03508825103456245),\n"," ('flat', 0.034518947038747076),\n"," ('bizarre', 0.03450946069452116),\n"," ('group', 0.034335883528586776),\n"," ('dreadful', 0.03428761851133187),\n"," ('ludicrous', 0.03415964932381604),\n"," ('clich', 0.03375144463172057),\n"," ('decent', 0.0337370923783022),\n"," ('daughter', 0.03373272585838489),\n"," ('bored', 0.033622879572852545),\n"," ('horror', 0.033464120619956815),\n"," ('writing', 0.03343791391675679),\n"," ('skip', 0.03343063985049117),\n"," ('absurd', 0.03315417353016333),\n"," ('barely', 0.03265341682751772),\n"," ('idea', 0.032549519766096456),\n"," ('wasn', 0.032481207966272074),\n"," ('fake', 0.03213643509803153),\n"," ('believe', 0.031677858935800815),\n"," ('uninteresting', 0.03152681591586714),\n"," ('reason', 0.03139071526027054),\n"," ('scenes', 0.031181869525822394),\n"," ('alright', 0.031046883113956262),\n"," ('body', 0.030999982945986666),\n"," ('no', 0.030917695380560425),\n"," ('insult', 0.03080845014635594),\n"," ('mst', 0.030527916471397867),\n"," ('nowhere', 0.030352177599338306),\n"," ('lousy', 0.030160195468380797),\n"," ('didn', 0.030115903194061402),\n"," ('interest', 0.02988811846877114),\n"," ('half', 0.029813246115057247),\n"," ('lee', 0.029804235955718662),\n"," ('dimensional', 0.029562861996904027),\n"," ('unconvincing', 0.029322607679950236),\n"," ('left', 0.029322408787030532),\n"," ('sex', 0.029296748476082154),\n"," ('even', 0.02922520945092342),\n"," ('far', 0.029158124924727816),\n"," ('tries', 0.029004001132703534),\n"," ('anything', 0.02898809774350112),\n"," ('trying', 0.028919477228465117),\n"," ('accent', 0.028779542310252596),\n"," ('nudity', 0.028662654953266063),\n"," ('apparently', 0.02829162694151793),\n"," ('zombies', 0.028178583120430676),\n"," ('sense', 0.02816674053475878),\n"," ('incoherent', 0.02798892619086252),\n"," ('something', 0.027986519420278227),\n"," ('tedious', 0.027952212405329524),\n"," ('wrong', 0.027831947557365636),\n"," ('were', 0.0278256957999854),\n"," ('endless', 0.027824591794431468),\n"," ('turkey', 0.0276242662050585),\n"," ('zombie', 0.027543333835110862),\n"," ('appears', 0.027469840878483243),\n"," ('embarrassing', 0.027425437142424354),\n"," ('walked', 0.027411768647042718),\n"," ('premise', 0.027346072285964196),\n"," ('ok', 0.02733300835623201),\n"," ('result', 0.0273125586531919),\n"," ('complete', 0.027247564384243438),\n"," ('t', 0.02718673746561022),\n"," ('least', 0.026949072632017266),\n"," ('was', 0.02688341336249851),\n"," ('unwatchable', 0.026829458762459388),\n"," ('sat', 0.026806511532143463),\n"," ('to', 0.026801902698524088),\n"," ('sadly', 0.026753380035391502),\n"," ('christmas', 0.026735555962199228),\n"," ('gore', 0.026670161630608404),\n"," ('mother', 0.02661269698743775),\n"," ('aspects', 0.026583237615263818),\n"," ('amateurish', 0.026565159291175696),\n"," ('below', 0.026548271016778147),\n"," ('stupidity', 0.02646099022194693),\n"," ('appeal', 0.026396596713420966),\n"," ('trite', 0.026331168557051407),\n"," ('then', 0.02628462920393767),\n"," ('rubbish', 0.026216695246125507),\n"," ('okay', 0.025981446095883615),\n"," ('sucks', 0.02593022440196933),\n"," ('pretentious', 0.02590791237062829),\n"," ('positive', 0.025773976409798765),\n"," ('confusing', 0.025737618729473624),\n"," ('remotely', 0.025699566061653027),\n"," ('obnoxious', 0.02545482974585025),\n"," ('m', 0.025435495928249195),\n"," ('rent', 0.0253734419340385),\n"," ('laughs', 0.025346512576104416),\n"," ('re', 0.02534223990362786),\n"," ('context', 0.025274382593713573),\n"," ('disgusting', 0.025195418263468182),\n"," ('so', 0.025148024611438797),\n"," ('tiresome', 0.025031684199042108),\n"," ('miscast', 0.024970026716882372),\n"," ('aren', 0.0249687038893859),\n"," ('forced', 0.02493329977771371),\n"," ('paid', 0.024906929703330336),\n"," ('utter', 0.02480228223338552),\n"," ('uninspired', 0.02479957621201747),\n"," ('falls', 0.024749631706810712),\n"," ('throw', 0.02461495407304669),\n"," ('been', 0.024470487429445045),\n"," ('ugly', 0.02433482004483239),\n"," ('hopes', 0.02431563565205431),\n"," ('dire', 0.024191221840051087),\n"," ('hunter', 0.02417129112741848),\n"," ('producers', 0.02408923199713024),\n"," ('seem', 0.024065146985976858),\n"," ('straight', 0.02399666645155215),\n"," ('vampire', 0.023942797574072684),\n"," ('paper', 0.02390882808396102),\n"," ('crappy', 0.023807255546688066),\n"," ('excited', 0.023764516357875826),\n"," ('start', 0.023739057832096785),\n"," ('material', 0.023729757962158763),\n"," ('excuse', 0.02368157727032811),\n"," ('cop', 0.023480677028928136),\n"," ('f', 0.023312251619610837),\n"," ('ms', 0.023282327986278318),\n"," ('villain', 0.02315827348366075),\n"," ('fest', 0.02309142571177825),\n"," ('lack', 0.02303943789432519),\n"," ('such', 0.023031161078650962),\n"," ('saving', 0.023025745893238077),\n"," ('clichs', 0.022928209200342317),\n"," ('enough', 0.022921397253925318),\n"," ('mistake', 0.022868689470375),\n"," ('unbelievable', 0.022864325693347894),\n"," ('maybe', 0.022825002748295294),\n"," ('blame', 0.022808369279543175),\n"," ('bunch', 0.022769532876362845),\n"," ('version', 0.022753296945755484),\n"," ('candy', 0.022749363632616763),\n"," ('island', 0.022745800666080167),\n"," ('tripe', 0.02269518850983268),\n"," ('wasting', 0.02268137134335677),\n"," ('inept', 0.02267927642566577),\n"," ('actor', 0.022636975371771045),\n"," ('flop', 0.022613758633444538),\n"," ('any', 0.022560608437607196),\n"," ('k', 0.022554017579615056),\n"," ('appalling', 0.022500975853556062),\n"," ('propaganda', 0.02246502443075575),\n"," ('major', 0.022430482324246586),\n"," ('sequel', 0.022362296462477872),\n"," ('offensive', 0.02232608060482545),\n"," ('revenge', 0.022315150942472623),\n"," ('shoot', 0.02228810570921175),\n"," ('whatsoever', 0.02228649834694094),\n"," ('ruined', 0.022173811528211046),\n"," ('painfully', 0.022152008209040924),\n"," ('on', 0.022016020939730065),\n"," ('shame', 0.021981493467648265),\n"," ('effects', 0.021849482201960254),\n"," ('wouldn', 0.021848506706035165),\n"," ('development', 0.021738748580498977),\n"," ('co', 0.021728673026887652),\n"," ('church', 0.021719723717009982),\n"," ('plot', 0.021699400267083842),\n"," ('storyline', 0.021663404462350773),\n"," ('screenwriter', 0.021660177252485927),\n"," ('bother', 0.021571699909566977),\n"," ('miserably', 0.02151617387249981),\n"," ('christian', 0.021515873507543658),\n"," ('add', 0.021468134313277945),\n"," ('found', 0.021449077767987143),\n"," ('watching', 0.021344833140596584),\n"," ('pseudo', 0.021308384076023475),\n"," ('boredom', 0.02111999591793001),\n"," ('please', 0.021090765093296316),\n"," ('talent', 0.0210058474452748),\n"," ('continuity', 0.02100514585242192),\n"," ('talents', 0.020992716564348885),\n"," ('college', 0.020990718952374865),\n"," ('tried', 0.020978219626186817),\n"," ('editing', 0.020865814801443765),\n"," ('lines', 0.0208537554088458),\n"," ('drivel', 0.020726493692759695),\n"," ('generous', 0.020697017742242002),\n"," ('potential', 0.020672988272090832),\n"," ('creatures', 0.020601399429061328),\n"," ('disjointed', 0.020581338926655212),\n"," ('irritating', 0.020576764848872678),\n"," ('pile', 0.02056089896754154),\n"," ('acts', 0.020560043588043527),\n"," ('junk', 0.020558505639508215),\n"," ('raped', 0.02055062928513327),\n"," ('christ', 0.020481424289613522),\n"," ('brain', 0.020431161137662707),\n"," ('slasher', 0.020425652445140895),\n"," ('seconds', 0.02039092744342189),\n"," ('nobody', 0.020389268101762618),\n"," ('dialog', 0.0203383491976015),\n"," ('makers', 0.02033318443195113),\n"," ('excitement', 0.020290456024291817),\n"," ('flashbacks', 0.02026751051291025),\n"," ('sloppy', 0.020234078734398368),\n"," ('joke', 0.020212187048528518),\n"," ('sleep', 0.020108895811675784),\n"," ('bottom', 0.019986770547280187),\n"," ('however', 0.019981104962051174),\n"," ('fail', 0.019937405211620237),\n"," ('sucked', 0.01987492301731157),\n"," ('soap', 0.01985352539554302),\n"," ('looked', 0.019810211840927114),\n"," ('stinks', 0.01976936538178117),\n"," ('deserve', 0.01961403432109647),\n"," ('exact', 0.019555320028258997),\n"," ('substance', 0.01955264743249818),\n"," ('yeah', 0.019513150136671556),\n"," ('production', 0.019510696746296543),\n"," ('female', 0.019476914978121807),\n"," ('unintentional', 0.019387723280198926),\n"," ('army', 0.019364852889641623),\n"," ('minute', 0.01935186255456824),\n"," ('unrealistic', 0.01935065725049786),\n"," ('rescue', 0.019340920364464918),\n"," ('theater', 0.019333829276668508),\n"," ('monsters', 0.019332636015751022),\n"," ('frankly', 0.019326550823843887),\n"," ('children', 0.01931424060686888),\n"," ('convince', 0.019312073515560652),\n"," ('shallow', 0.01929844550493055),\n"," ('synopsis', 0.019259706392396585),\n"," ('scott', 0.019183474405570326),\n"," ('seriously', 0.01918202798715),\n"," ('ridiculously', 0.01916930028517898),\n"," ('looking', 0.01915098543996655),\n"," ('kareena', 0.019110212601710665),\n"," ('wrote', 0.019015323411486436),\n"," ('attempts', 0.019006343780653932),\n"," ('bothered', 0.01897071277757852),\n"," ('utterly', 0.018924824767803404),\n"," ('giant', 0.018891084650049694),\n"," ('writers', 0.018868906582101292),\n"," ('atrocious', 0.018848042351202354),\n"," ('plain', 0.018828766525513595),\n"," ('presumably', 0.018826629750947947),\n"," ('example', 0.01879645323783717),\n"," ('murray', 0.01875417343004693),\n"," ('seemed', 0.018749132295913074),\n"," ('stay', 0.01874415970643269),\n"," ('interview', 0.01867208596470954),\n"," ('disaster', 0.018553283301235166),\n"," ('value', 0.018544080955166378),\n"," ('paint', 0.01852960713242937),\n"," ('original', 0.018528190682362413),\n"," ('difficult', 0.018518455298178586),\n"," ('care', 0.01849480480117126),\n"," ('watchable', 0.018481870605389094),\n"," ('useless', 0.018470481000366856),\n"," ('desperately', 0.018421675047000256),\n"," ('except', 0.018391993551238554),\n"," ('doing', 0.018384737621350646),\n"," ('errors', 0.01838041497833026),\n"," ('solely', 0.018349321075079403),\n"," ('sitting', 0.018346519170301095),\n"," ('giving', 0.018335957397904844),\n"," ('ideas', 0.018327099221245206),\n"," ('unbearable', 0.018321159676201414),\n"," ('advice', 0.018273372527688833),\n"," ('nor', 0.0182544202595543),\n"," ('project', 0.018252633214771753),\n"," ('dozen', 0.018206363291515763),\n"," ('charles', 0.01816366057829346),\n"," ('plastic', 0.01816174102037866),\n"," ('book', 0.018139011699011297),\n"," ('shots', 0.018114876064363863),\n"," ('ill', 0.018103621818215745),\n"," ('grade', 0.01808830951124236),\n"," ('where', 0.018065882599695167),\n"," ('women', 0.018026883825059365),\n"," ('screenplay', 0.018014307024101325),\n"," ('through', 0.0179908630032414),\n"," ('actress', 0.01787600348785716),\n"," ('sign', 0.017865636144056934),\n"," ('walk', 0.017823522607756628),\n"," ('santa', 0.01772710273321919),\n"," ('happens', 0.017722408798843587),\n"," ('contrived', 0.017720303645882795),\n"," ('gun', 0.017685993176933847),\n"," ('ashamed', 0.01767962309872159),\n"," ('gratuitous', 0.017665737783803856),\n"," ('one', 0.01760825934404327),\n"," ('credibility', 0.017558852870687952),\n"," ('promising', 0.017544417082572285),\n"," ('risk', 0.017532600100721246),\n"," ('sub', 0.017531947750389472),\n"," ('not', 0.017527843031623098),\n"," ('lacking', 0.017513759836446534),\n"," ('fell', 0.017464857159331267),\n"," ('scenery', 0.017451365955319948),\n"," ('flesh', 0.017402514298262686),\n"," ('animal', 0.017386681692205433),\n"," ('tired', 0.017383214541566674),\n"," ('writer', 0.017380887757560835),\n"," ('lady', 0.01737065721256548),\n"," ('dialogue', 0.017319373946647603),\n"," ('terribly', 0.0172911352572769),\n"," ('downright', 0.01727767556320545),\n"," ('rented', 0.017247977656900722),\n"," ('blah', 0.017217377177396766),\n"," ('clumsy', 0.017206797395615314),\n"," ('random', 0.017199913549248),\n"," ('members', 0.01719894711734477),\n"," ('three', 0.017189383912215916),\n"," ('celluloid', 0.017174000803758884),\n"," ('your', 0.01714017388643006),\n"," ('lost', 0.01712776332206181),\n"," ('suddenly', 0.017124566068806125),\n"," ('cover', 0.01706668083587431),\n"," ('existent', 0.017028540662919332),\n"," ('mostly', 0.017009366180205397),\n"," ('dig', 0.016990887715494302),\n"," ('spending', 0.016944400877991022),\n"," ('elsewhere', 0.01693787716791653),\n"," ('suck', 0.016897737192407582),\n"," ('apparent', 0.01678387422580727),\n"," ('fill', 0.016766110935370605),\n"," ('running', 0.01672862109999636),\n"," ('jokes', 0.01671892031222803),\n"," ('cheese', 0.016699473014889835),\n"," ('outer', 0.01661259139198147),\n"," ('anil', 0.016581200840654876),\n"," ('awfully', 0.016492200414985305),\n"," ('director', 0.016478401040744654),\n"," ('mix', 0.016468214294032505),\n"," ('naturally', 0.01640487983526945),\n"," ('scientist', 0.016395078905109235),\n"," ('imdb', 0.016343168034107174),\n"," ('dumb', 0.01628969354969246),\n"," ('curiosity', 0.016277433551029973),\n"," ('made', 0.01624531650087467),\n"," ('somewhere', 0.01623611744674799),\n"," ('stereotyped', 0.016235814767295294),\n"," ('officer', 0.01623540103988457),\n"," ('shelf', 0.016151304702362455),\n"," ('spends', 0.016089566181633208),\n"," ('explanation', 0.016040330428242225),\n"," ('proof', 0.01602138123515429),\n"," ('killed', 0.016004979798664876),\n"," ('songs', 0.0160022801891881),\n"," ('why', 0.015994497048455188),\n"," ('adequate', 0.015978003410591603),\n"," ('assume', 0.015953574865902428),\n"," ('mean', 0.015907137878947295),\n"," ('year', 0.015900265748875857),\n"," ('named', 0.01589737729649342),\n"," ('actors', 0.015880849255718716),\n"," ('dreck', 0.015844184837849273),\n"," ('ripped', 0.015809352391222227),\n"," ('exception', 0.01580103765354694),\n"," ('let', 0.01574755499580686),\n"," ('said', 0.01573920675680914),\n"," ('handed', 0.015729421480492778),\n"," ('five', 0.015692627471399444),\n"," ('manage', 0.015647108880417124),\n"," ('thousands', 0.015643430975892963),\n"," ('faith', 0.01561697695555187),\n"," ('hideous', 0.0155891581718908),\n"," ('alas', 0.015538213296394253),\n"," ('interesting', 0.015537431607034413),\n"," ('camera', 0.015534217771859272),\n"," ('affair', 0.01549937182032941),\n"," ('basketball', 0.01549802590481383),\n"," ('saved', 0.015479619606949038),\n"," ('allow', 0.015471290657970012),\n"," ('embarrassed', 0.015465690911012358),\n"," ('historically', 0.015405093934372963),\n"," ('guy', 0.015377641254470047),\n"," ('smoking', 0.01534650885437834),\n"," ('implausible', 0.015340453986022747),\n"," ('entirely', 0.01533469278818365),\n"," ('insulting', 0.015328508644691503),\n"," ('unable', 0.015321433538157141),\n"," ('supposedly', 0.015316107621242393),\n"," ('replaced', 0.015263381265213496),\n"," ('write', 0.015247349730647845),\n"," ('devoid', 0.015196181920380176),\n"," ('angry', 0.015128878425101421),\n"," ('cannot', 0.01512467127897078),\n"," ('stinker', 0.015117424017513686),\n"," ('types', 0.015097306608066985),\n"," ('hype', 0.01507628836552431),\n"," ('responsible', 0.01499135627656159),\n"," ('peter', 0.014969127137333019),\n"," ('putting', 0.014910707254937245),\n"," ('over', 0.014897181020826433),\n"," ('cardboard', 0.014888714204149051),\n"," ('interspersed', 0.014883165331874145),\n"," ('haired', 0.014880449676198558),\n"," ('spend', 0.014876094316227653),\n"," ('elvis', 0.014854709844151744),\n"," ('indulgent', 0.0148472321323872),\n"," ('catholic', 0.014843519648135947),\n"," ('downhill', 0.014807184967767806),\n"," ('lazy', 0.01478151469522973),\n"," ('aged', 0.0147733158291986),\n"," ('exist', 0.014753607788843276),\n"," ('torture', 0.014733998799388375),\n"," ('prove', 0.014729418674653005),\n"," ('tolerable', 0.0146808801042558),\n"," ('four', 0.01465454759263252),\n"," ('acceptable', 0.014651730694965857),\n"," ('chick', 0.014641428398798832),\n"," ('unimaginative', 0.014629366067627067),\n"," ('whiny', 0.014626751487134581),\n"," ('artsy', 0.01459792134916728),\n"," ('decide', 0.014596087755808975),\n"," ('unpleasant', 0.0145392579630972),\n"," ('rotten', 0.014526987482368667),\n"," ('racist', 0.014521318292204644),\n"," ('air', 0.014513999400043531),\n"," ('flimsy', 0.014510298364381136),\n"," ('baldwin', 0.014458793249711605),\n"," ('merely', 0.014423588430956457),\n"," ('wood', 0.014405182128559192),\n"," ('thinking', 0.014365675477621548),\n"," ('earth', 0.014352953870200823),\n"," ('kidding', 0.014337420788166334),\n"," ('unintentionally', 0.014336443850996718),\n"," ('vampires', 0.01432590543097523),\n"," ('generic', 0.014319871170399822),\n"," ('defense', 0.014290336242912224),\n"," ('saif', 0.014289573796132722),\n"," ('asleep', 0.01428901243557695),\n"," ('execution', 0.014283962008273412),\n"," ('figure', 0.014283770855230159),\n"," ('lackluster', 0.014273058981901452),\n"," ('hoped', 0.014264724762345842),\n"," ('nonsense', 0.014261341497203128),\n"," ('horrid', 0.014253216604458423),\n"," ('god', 0.014237363547447925),\n"," ('l', 0.014187296773742579),\n"," ('caricatures', 0.014181564208326647),\n"," ('starts', 0.014153430344591595),\n"," ('dry', 0.014133935534427955),\n"," ('display', 0.014128179969827098),\n"," ('button', 0.014116471162614748),\n"," ('bore', 0.014116389381443271),\n"," ('empty', 0.014096772700681909),\n"," ('harold', 0.014052130896646567),\n"," ('incomprehensible', 0.014009428713655195),\n"," ('annie', 0.014008405850952515),\n"," ('thrown', 0.014007462594894689),\n"," ('incredibly', 0.014005185007294354),\n"," ('renting', 0.01392668760863047),\n"," ('connect', 0.013922471736926735),\n"," ('younger', 0.013921148395141759),\n"," ('author', 0.013908729139553403),\n"," ('mistakes', 0.01390206066202472),\n"," ('vague', 0.013900188409028461),\n"," ('susan', 0.013899718009237956),\n"," ('obvious', 0.013862928310275255),\n"," ('public', 0.013848261281553184),\n"," ('porn', 0.013842110384054574),\n"," ('trash', 0.013803990572178484),\n"," ('stevens', 0.013796967244647433),\n"," ('sequels', 0.013782463861472694),\n"," ('hurt', 0.013769543921240137),\n"," ('desert', 0.013763619124969734),\n"," ('behave', 0.013719767167839493),\n"," ('served', 0.013714838239223712),\n"," ('claims', 0.013706886269650513),\n"," ('did', 0.013703146040161415),\n"," ('ultimately', 0.013697643591100145),\n"," ('wide', 0.013685211021307759),\n"," ('wow', 0.013679184770624813),\n"," ('worthless', 0.01367053329629829),\n"," ('dear', 0.01365359137960015),\n"," ('plodding', 0.01362284584085525),\n"," ('mike', 0.013594086031988716),\n"," ('favor', 0.013578310381078493),\n"," ('call', 0.013577646631327944),\n"," ('biggest', 0.013529947586389583),\n"," ('worthy', 0.013524754842185316),\n"," ('meaning', 0.01351799753190056),\n"," ('scientific', 0.013515396653842864),\n"," ('hanks', 0.013467213376215896),\n"," ('ads', 0.013463653421760929),\n"," ('gay', 0.013414840808688228),\n"," ('embarrassingly', 0.013401336286973738),\n"," ('literary', 0.013389208999321039),\n"," ('playing', 0.013329954634726372),\n"," ('bo', 0.01331289056468251),\n"," ('manipulative', 0.013287016941406334),\n"," ('dressed', 0.013285092423656561),\n"," ('embarrassment', 0.01326953031919822),\n"," ('regarding', 0.01323325021163166),\n"," ('stilted', 0.01321553922014192),\n"," ('sleeve', 0.013215085161586725),\n"," ('rating', 0.013203442200940883),\n"," ('kills', 0.01318391946735874),\n"," ('sounds', 0.013178727878711724),\n"," ('ali', 0.013173031266866373),\n"," ('non', 0.013162603751805243),\n"," ('pie', 0.01316149262925385),\n"," ('populated', 0.013152746747459271),\n"," ('killing', 0.01311186085315181),\n"," ('else', 0.013110592541316699),\n"," ('schneider', 0.013093514941690407),\n"," ('priest', 0.013071537555948207),\n"," ('hollow', 0.013068001463175464),\n"," ('shower', 0.013029604174841074),\n"," ('ruins', 0.013021597567104505),\n"," ('this', 0.013009778169664532),\n"," ('pregnant', 0.012997074834619553),\n"," ('make', 0.012992851916498648),\n"," ('mental', 0.01298520283491305),\n"," ('timberlake', 0.012979689860020448),\n"," ('saves', 0.012915795355367861),\n"," ('vastly', 0.012914828969565762),\n"," ('swear', 0.012901059475490072),\n"," ('stella', 0.012883911119651207),\n"," ('grave', 0.012882555040277136),\n"," ('thats', 0.012861061812910341),\n"," ('drinking', 0.012860129471019706),\n"," ('boom', 0.01285177959469419),\n"," ('introduction', 0.012831129197335468),\n"," ('programming', 0.012796219757750261),\n"," ('career', 0.012773059501084118),\n"," ('stereotype', 0.012769447626661476),\n"," ('attractive', 0.012765873120010148),\n"," ('victims', 0.012749299245502178),\n"," ('pass', 0.012735021821089284),\n"," ('experiment', 0.012716112941788918),\n"," ('retarded', 0.012713099529852417),\n"," ('stuck', 0.012709332698253265),\n"," ('akshay', 0.012684273069877872),\n"," ('cut', 0.012676285239015476),\n"," ('shoddy', 0.012674792040888049),\n"," ('damme', 0.01266653641765667),\n"," ('inaccurate', 0.012653687577536552),\n"," ('ray', 0.012649818023510177),\n"," ('woman', 0.012646521945546328),\n"," ('research', 0.012640494662864566),\n"," ('mile', 0.01262724569371673),\n"," ('place', 0.012624645831509409),\n"," ('demon', 0.012621688470792602),\n"," ('vulgar', 0.012612150302693317),\n"," ('engage', 0.012602272831074856),\n"," ('wives', 0.012601890190118308),\n"," ('mention', 0.012581598480006468),\n"," ('if', 0.012569631262234721),\n"," ('cartoon', 0.012561864177985762),\n"," ('unbelievably', 0.012550391668315845),\n"," ('only', 0.01251710772785915),\n"," ('ended', 0.012507282716729797),\n"," ('stereotypical', 0.012506426536204353),\n"," ('spent', 0.012503032775055224),\n"," ('thing', 0.012483110991541434),\n"," ('phone', 0.012464039991489142),\n"," ('stock', 0.01244674214755662),\n"," ('drop', 0.012432978683590465),\n"," ('self', 0.012432059211520801),\n"," ('headache', 0.012424495134195477),\n"," ('escapes', 0.012419211298248922),\n"," ('conceived', 0.012392639977060707),\n"," ('required', 0.01239226094704284),\n"," ('assassin', 0.012332404091910098),\n"," ('meat', 0.012327751187890432),\n"," ('therefore', 0.0123161387296296),\n"," ('struggling', 0.012308628353572298),\n"," ('ho', 0.012307714936265706),\n"," ('ta', 0.01229940964932024),\n"," ('cold', 0.012289510775209261),\n"," ('expects', 0.012271684887263195),\n"," ('furthermore', 0.012263298696316207),\n"," ('remote', 0.012254529263879228),\n"," ('cgi', 0.012250569964074174),\n"," ('arab', 0.012230232115225255),\n"," ('feminist', 0.012220004405980549),\n"," ('hair', 0.012213792907949599),\n"," ('intelligence', 0.012203964889416783),\n"," ('destroy', 0.012190213907023972),\n"," ('cameo', 0.012186034087855126),\n"," ('claus', 0.012181510618531248),\n"," ('awake', 0.012171290237450146),\n"," ('sums', 0.01213994590925191),\n"," ('auto', 0.012126012687040626),\n"," ('cue', 0.012120943623008971),\n"," ('speak', 0.0121177848156181),\n"," ('stereotypes', 0.012106976159466584),\n"," ('footage', 0.012103658001584292),\n"," ('maker', 0.012093369539270368),\n"," ('rental', 0.012083052888147334),\n"," ('proper', 0.012063210621690407),\n"," ('mercifully', 0.012047936344961966),\n"," ('gimmick', 0.012041001769926648),\n"," ('coherent', 0.012027899920693622),\n"," ('inane', 0.01199317587757883),\n"," ('relies', 0.011992345660343809),\n"," ('nomination', 0.011982252573531254),\n"," ('segal', 0.011947340234058409),\n"," ('christians', 0.01194639890548991),\n"," ('overrated', 0.011926101166626011),\n"," ('don', 0.011924357980777274),\n"," ('severely', 0.011916168552237325),\n"," ('phony', 0.011913822393121729),\n"," ('selfish', 0.011900529017180252),\n"," ('resume', 0.011897346320859061),\n"," ('another', 0.011877684431361649),\n"," ('sean', 0.011876040214137615),\n"," ('hepburn', 0.011869243078008906),\n"," ('secondly', 0.011863109334450278),\n"," ('ups', 0.011859394818287423),\n"," ('planet', 0.011852030247443603),\n"," ('changed', 0.011845335611887489),\n"," ('amused', 0.011842962845878574),\n"," ('lowest', 0.011831634819501924),\n"," ('fools', 0.01182411623284237),\n"," ('spelling', 0.011821902194872625),\n"," ('repressed', 0.011821527286346356),\n"," ('unlikeable', 0.011818760110586485),\n"," ('failure', 0.01181651990170905),\n"," ('hyped', 0.01178466654468431),\n"," ('anti', 0.01176408631553916),\n"," ('line', 0.011761945162307125),\n"," ('promise', 0.011749711660046623),\n"," ('observe', 0.011739608959278624),\n"," ('mindless', 0.011729368774426888),\n"," ('lacked', 0.011718485221863714),\n"," ('acting', 0.011717854904638602),\n"," ('rather', 0.011704535222487905),\n"," ('ed', 0.011700096242496993),\n"," ('significant', 0.01169617650193993),\n"," ('talks', 0.01167810147608689),\n"," ('arty', 0.011674972481678902),\n"," ('spit', 0.011671408526135135),\n"," ('ilk', 0.011661568455359032),\n"," ('unoriginal', 0.011651107245840888),\n"," ('forward', 0.011646719533106099),\n"," ('toilet', 0.011635522207639075),\n"," ('suppose', 0.011633258510072195),\n"," ('feed', 0.011617447517425163),\n"," ('surrounded', 0.011607897169523129),\n"," ('wanted', 0.011604506869089721),\n"," ('tashan', 0.011596205445299112),\n"," ('dr', 0.011543949281335644),\n"," ('scare', 0.011543316667712923),\n"," ('murderer', 0.011535350571639676),\n"," ('explained', 0.011466329649783221),\n"," ('cheated', 0.011455846970137708),\n"," ('whats', 0.011451443577230852),\n"," ('romance', 0.011445558616225343),\n"," ('jewish', 0.011441564163643681),\n"," ('sexual', 0.01143868279725569),\n"," ('books', 0.011419811777535172),\n"," ('throwing', 0.011404165894740248),\n"," ('nose', 0.011395583651720628),\n"," ('parking', 0.011390688400833916),\n"," ('pick', 0.01135767144538218),\n"," ('chose', 0.011354353327826115),\n"," ('improve', 0.011350584813053921),\n"," ('kapoor', 0.011340767814074912),\n"," ('costs', 0.011325900726890981),\n"," ('saying', 0.01132561762955133),\n"," ('early', 0.011320525734188094),\n"," ('technically', 0.011317672837061947),\n"," ('hackman', 0.011288294849240653),\n"," ('birthday', 0.011282785404027754),\n"," ('cinematography', 0.011263572785831694),\n"," ('hurts', 0.01125015430309153),\n"," ('saturday', 0.011247837147971243),\n"," ('meaningless', 0.011239510238506716),\n"," ('mannered', 0.01123904420797226),\n"," ('screaming', 0.01123862031022238),\n"," ('should', 0.011236648355832376),\n"," ('crazed', 0.011236418275421326),\n"," ('dignity', 0.011236150963786547),\n"," ('mate', 0.011216700009844502),\n"," ('letters', 0.011208675517174487),\n"," ('recycled', 0.011206236378205581),\n"," ('promptly', 0.011202237607822144),\n"," ('inexplicably', 0.011161321811546259),\n"," ('or', 0.01115296534330534),\n"," ('simply', 0.011146233896835908),\n"," ('too', 0.011130044921930277),\n"," ('nerd', 0.011122543127721443),\n"," ('chris', 0.011116119389820142),\n"," ('proceedings', 0.011111786695547105),\n"," ('lived', 0.011100598930695585),\n"," ('code', 0.011095425242701427),\n"," ('potentially', 0.011093285835678524),\n"," ('open', 0.011075631889800958),\n"," ('faster', 0.011074177906888305),\n"," ('moore', 0.011070458274337771),\n"," ('bowl', 0.011060417562531434),\n"," ('absolutely', 0.011044130796846892),\n"," ('just', 0.01103335685499156),\n"," ('suspension', 0.011031781173072127),\n"," ('enemy', 0.011025820754518648),\n"," ('conclusion', 0.010986051066943347),\n"," ('romances', 0.010962761722118314),\n"," ('spoke', 0.010962116403553658),\n"," ('hardly', 0.010960545391113465),\n"," ('olds', 0.010951344004097446),\n"," ('creek', 0.010950023924322873),\n"," ('shouting', 0.010943727502542747),\n"," ('hospital', 0.010943001436111948),\n"," ('originality', 0.010912963822714923),\n"," ('bollywood', 0.010911409137577788),\n"," ('cape', 0.010902326129518287),\n"," ('teeth', 0.010900502046002621),\n"," ('backdrop', 0.010885688008708731),\n"," ('turn', 0.010880478059425661),\n"," ('mason', 0.010866951716170659),\n"," ('grace', 0.01084840625738232),\n"," ('valley', 0.010845180425875851),\n"," ('depressing', 0.0108278180867385),\n"," ('superficial', 0.010826403237558537),\n"," ('invested', 0.010812488716640862),\n"," ('bomb', 0.010811727591767125),\n"," ('embarrass', 0.010778451069403575),\n"," ('sided', 0.010773707983617684),\n"," ('sticking', 0.01076229243554771),\n"," ('common', 0.010754536408451018),\n"," ('boat', 0.010750196487059145),\n"," ('promised', 0.010746025901289744),\n"," ('wayans', 0.010744338945929416),\n"," ('sheer', 0.010734103279474511),\n"," ('wrestling', 0.010724515540975414),\n"," ('staff', 0.010715523520497061),\n"," ('apollo', 0.010711377643774772),\n"," ('leigh', 0.01070208059867856),\n"," ('virtually', 0.010691942663824006),\n"," ('seagal', 0.010677324100672117),\n"," ('comes', 0.010674899719725501),\n"," ('edition', 0.010673353805904201),\n"," ('predictably', 0.010666551243955746),\n"," ('stuff', 0.010664915811483261),\n"," ('gang', 0.010664441184213124),\n"," ('cancer', 0.010643225900463578),\n"," ('obviously', 0.010641670080654534),\n"," ('would', 0.010623530922231152),\n"," ('totally', 0.01061609299514789),\n"," ('profile', 0.010596003501785217),\n"," ('spacey', 0.010595967407784396),\n"," ('ability', 0.010584592521360155),\n"," ('horrendous', 0.01058021332853209),\n"," ('blood', 0.010579520401095308),\n"," ('imitation', 0.010568550630572961),\n"," ('bikini', 0.0105680433719311),\n"," ('talented', 0.010566001035979438),\n"," ('basis', 0.010564729746933203),\n"," ('dialogs', 0.010551191397294012),\n"," ('showing', 0.010548613564454235),\n"," ('door', 0.010544563357219781),\n"," ('portray', 0.01052779962849062),\n"," ('strictly', 0.010526959295132301),\n"," ('mexican', 0.010508731517822341),\n"," ('stick', 0.010465961443388678),\n"," ('east', 0.010455324716016769),\n"," ('anywhere', 0.010431532734666276),\n"," ('remake', 0.010419869194952837),\n"," ('am', 0.010410414209203925),\n"," ('attempting', 0.01038639399862738),\n"," ('disturbing', 0.010381152608581445),\n"," ('jude', 0.010377136500506756),\n"," ('wondering', 0.010363512690012212),\n"," ('celebrated', 0.010360111769075867),\n"," ('use', 0.010350554074714654),\n"," ('wreck', 0.010344734410393921),\n"," ('appear', 0.01034443835153917),\n"," ('entitled', 0.010335246001593067),\n"," ('youth', 0.010323214445994806),\n"," ('letdown', 0.010318553446258684),\n"," ('moran', 0.010305507693633364),\n"," ('mediocrity', 0.01030282714069538),\n"," ('news', 0.010292874788426103),\n"," ('bits', 0.010276065293631167),\n"," ('alone', 0.010268492053981967),\n"," ('accents', 0.01026385209453469),\n"," ('inhabited', 0.01024411769302482),\n"," ('mock', 0.010244061360675908),\n"," ('g', 0.010223458175403786),\n"," ('box', 0.010203304329265759),\n"," ('term', 0.010199983044386102),\n"," ('behavior', 0.010198776124373256),\n"," ('tedium', 0.01019009220150722),\n"," ('intent', 0.010190038120698575),\n"," ('husband', 0.010189502265957842),\n"," ('presence', 0.010187192336074171),\n"," ('z', 0.010184318583214764),\n"," ('unappealing', 0.010146391189444368),\n"," ('much', 0.01013679011769715),\n"," ('tree', 0.010113534581593916),\n"," ('doctors', 0.010099854380484191),\n"," ('pi', 0.010095099419111344),\n"," ('rodney', 0.01009081979808239),\n"," ('franchise', 0.010089650929674204),\n"," ('piece', 0.010086011549585345),\n"," ('company', 0.010083539582601048),\n"," ('choppy', 0.010079223420593735),\n"," ('turned', 0.010069855547990126),\n"," ('test', 0.010041505355613904),\n"," ('ball', 0.010040944323609524),\n"," ('hated', 0.01003550905894585),\n"," ('bear', 0.010034272465057465),\n"," ('serves', 0.010027495172169233),\n"," ('leonard', 0.0100227513901647),\n"," ('deserved', 0.010022334081283375),\n"," ('part', 0.010016360436147438),\n"," ('opportunity', 0.010013126012646692),\n"," ('turning', 0.010011850960865779),\n"," ('overacting', 0.010008994714980209),\n"," ('refer', 0.010006488920574088),\n"," ('flies', 0.010006418749637631),\n"," ('uninvolving', 0.009999133897620822),\n"," ('produce', 0.009996201403801377),\n"," ('jumpy', 0.009994785580841518),\n"," ('die', 0.009991412905867103),\n"," ('root', 0.009974713500112831),\n"," ('insomnia', 0.00997446425552851),\n"," ('blatant', 0.009959662000566392),\n"," ('larry', 0.00995569053679025),\n"," ('threw', 0.009947396538844968),\n"," ('billed', 0.009928581875367094),\n"," ('bullets', 0.009928175897100594),\n"," ('intellectually', 0.00990813882787862),\n"," ('rip', 0.00990132339960409),\n"," ('stretching', 0.009901296969917268),\n"," ('protest', 0.009898455267562362),\n"," ('soldiers', 0.009893692382244922),\n"," ('flick', 0.009887063364977659),\n"," ('justin', 0.009862246602717563),\n"," ('highlights', 0.00985890880205863),\n"," ('move', 0.009853989980954034),\n"," ('merit', 0.009843120594996684),\n"," ('russian', 0.009841171721984112),\n"," ('security', 0.009837345033883104),\n"," ('idiotic', 0.009834123428814462),\n"," ('produced', 0.009829430757425808),\n"," ('king', 0.009826687234317573),\n"," ('magically', 0.009822884247682566),\n"," ('united', 0.00980708478907078),\n"," ('missile', 0.009799057819334852),\n"," ('unlikable', 0.009786915898648087),\n"," ('ignorant', 0.009773274317346104),\n"," ('amateur', 0.009767405987056119),\n"," ('bachelor', 0.009767342945540571),\n"," ('asylum', 0.009762733851977996),\n"," ('screw', 0.009756809857392721),\n"," ('report', 0.009747923269917247),\n"," ('dracula', 0.009746732339320564),\n"," ('removed', 0.009741651949942212),\n"," ('confess', 0.009716292521157327),\n"," ('brand', 0.009715253466090767),\n"," ('conspiracy', 0.0097116972290397),\n"," ('horribly', 0.009708378556425252),\n"," ('switch', 0.009702684093379554),\n"," ('jaws', 0.009687745551371313),\n"," ('unsuspecting', 0.009685342503584646),\n"," ('betty', 0.009677035213332474),\n"," ('forwarding', 0.00967111968931928),\n"," ('university', 0.009663671587814962),\n"," ('star', 0.009662325493180041),\n"," ('crawl', 0.009646431896859054),\n"," ('dopey', 0.009646086331585863),\n"," ('ruin', 0.009623010638545721),\n"," ('lifeless', 0.009622880727487999),\n"," ('flash', 0.009619362535965006),\n"," ('whoever', 0.009617412891587546),\n"," ('coincidence', 0.009602459974140214),\n"," ('choosing', 0.009595110005106931),\n"," ('avid', 0.009590091328422265),\n"," ('intended', 0.00958469870416763),\n"," ('remained', 0.009583962817858388),\n"," ('c', 0.009573267668176254),\n"," ('waiting', 0.009556225869434883),\n"," ('cassie', 0.009548135444223808),\n"," ('garage', 0.009534954458783029),\n"," ('clarke', 0.009534544585569868),\n"," ('fortune', 0.009533039664830203),\n"," ('interminable', 0.009532815956355262),\n"," ('incessant', 0.009523548502684638),\n"," ('plots', 0.009522580549062472),\n"," ('danger', 0.009517120565469302),\n"," ('costumes', 0.009498014466752438),\n"," ('evidently', 0.009495215846701223),\n"," ('minus', 0.009491149517466123),\n"," ('reporters', 0.009483681104099088),\n"," ('israeli', 0.009475007718336467),\n"," ('failing', 0.009471184131397692),\n"," ('paying', 0.009469234406685133),\n"," ('godzilla', 0.009458691554843789),\n"," ('dumber', 0.009458290309292487),\n"," ('earn', 0.009447622492842499),\n"," ('slows', 0.009446746387248761),\n"," ('held', 0.009445273681791478),\n"," ('chase', 0.009443836261194646),\n"," ('lies', 0.009438396984503343),\n"," ('hands', 0.009438178161458928),\n"," ('grief', 0.009423849453410288),\n"," ('brains', 0.009418215341663214),\n"," ('tom', 0.009413043338434714),\n"," ('resurrected', 0.009408342343729057),\n"," ('asking', 0.009402102940345334),\n"," ('sleeps', 0.009401795188265833),\n"," ('porno', 0.009390720141396513),\n"," ('somehow', 0.00938892612708605),\n"," ('sarcasm', 0.009388606439390415),\n"," ('tie', 0.00938560093663116),\n"," ('fall', 0.00938016400089311),\n"," ('bring', 0.00937912735457615),\n"," ('rape', 0.009376085123074637),\n"," ('village', 0.009368451331861406),\n"," ('kitchen', 0.009364907146010962),\n"," ('concerned', 0.009361135323881126),\n"," ('republic', 0.009349942694876432),\n"," ('hell', 0.00934003607053172),\n"," ('inducing', 0.00933821297925535),\n"," ('stomach', 0.009337828638515861),\n"," ('shambles', 0.009333545732982977),\n"," ('virgin', 0.009331200133905598),\n"," ('extraneous', 0.009325041380035131),\n"," ('cameras', 0.00932294602679772),\n"," ('suffers', 0.009320492992483005),\n"," ('justified', 0.009316321747936316),\n"," ('plummer', 0.009294827328510398),\n"," ('ponderous', 0.009288034423722337),\n"," ('player', 0.009280229634544366),\n"," ('survivor', 0.009276702647212571),\n"," ('rainy', 0.009269703421813748),\n"," ('graces', 0.009262094496329129),\n"," ...]"]},"metadata":{},"execution_count":85}],"metadata":{"id":"s8PpNCgrNFmA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629337933477,"user_tz":300,"elapsed":298,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"d6d57004-1166-41b4-a3ef-9a0d92e0bc70"}},{"cell_type":"code","execution_count":null,"source":["import matplotlib.colors as colors\n","\n","words_to_visualize = list()\n","for word, ratio in pos_neg_ratios.most_common(500):\n","    if(word in mlp_full.word2index.keys()):\n","        words_to_visualize.append(word)\n","    \n","for word, ratio in list(reversed(pos_neg_ratios.most_common()))[0:500]:\n","    if(word in mlp_full.word2index.keys()):\n","        words_to_visualize.append(word)"],"outputs":[],"metadata":{"collapsed":true,"id":"chM8xx-KNFmA"}},{"cell_type":"code","execution_count":null,"source":["pos = 0\n","neg = 0\n","\n","colors_list = list()\n","vectors_list = list()\n","for word in words_to_visualize:\n","    if word in pos_neg_ratios.keys():\n","        vectors_list.append(mlp_full.weights_0_1[mlp_full.word2index[word]])\n","        if(pos_neg_ratios[word] > 0):\n","            pos+=1\n","            colors_list.append(\"#00ff00\")\n","        else:\n","            neg+=1\n","            colors_list.append(\"#000000\")"],"outputs":[],"metadata":{"collapsed":true,"id":"fwxlwwF7NFmB"}},{"cell_type":"code","execution_count":null,"source":["from sklearn.manifold import TSNE\n","tsne = TSNE(n_components=2, random_state=0)\n","words_top_ted_tsne = tsne.fit_transform(vectors_list)"],"outputs":[],"metadata":{"collapsed":true,"id":"Pa4PQuVcNFmB"}},{"cell_type":"code","execution_count":null,"source":["p = figure(tools=\"pan,wheel_zoom,reset,save\",\n","           toolbar_location=\"above\",\n","           title=\"vector T-SNE for most polarized words\")\n","\n","source = ColumnDataSource(data=dict(x1=words_top_ted_tsne[:,0],\n","                                    x2=words_top_ted_tsne[:,1],\n","                                    names=words_to_visualize))\n","\n","p.scatter(x=\"x1\", y=\"x2\", size=8, source=source,color=colors_list)\n","\n","word_labels = LabelSet(x=\"x1\", y=\"x2\", text=\"names\", y_offset=6,\n","                  text_font_size=\"8pt\", text_color=\"#555555\",\n","                  source=source, text_align='center')\n","p.add_layout(word_labels)\n","\n","show(p)\n","\n","# green indicates positive words, black indicates negative words"],"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-89-84ad58e224e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                                     names=words_to_visualize))\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolors_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m word_labels = LabelSet(x=\"x1\", y=\"x2\", text=\"names\", y_offset=6,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bokeh/plotting/figure.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcircle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1126\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmarker_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhexbin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pointytop\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Viridis256\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_color\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_color\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bokeh/plotting/_decorators.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglyphclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__signature__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bokeh/plotting/_renderer.py\u001b[0m in \u001b[0;36mcreate_renderer\u001b[0;34m(glyphclass, plot, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mincompatible_literal_spec_values\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0m_process_sequence_literals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglyphclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglyph_visuals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_user_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincompatible_literal_spec_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_GLYPH_SOURCE_MSG\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnice_join\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincompatible_literal_spec_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconjuction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"and\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# handle the nonselection glyph, we always set one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: \n\nExpected line_color and fill_color to reference fields in the supplied data source.\n\nWhen a 'source' argument is passed to a glyph method, values that are sequences\n(like lists or arrays) must come from references to data columns in the source.\n\nFor instance, as an example:\n\n    source = ColumnDataSource(data=dict(x=a_list, y=an_array))\n\n    p.circle(x='x', y='y', source=source, ...) # pass column names and a source\n\nAlternatively, *all* data sequences may be provided as literals as long as a\nsource is *not* provided:\n\n    p.circle(x=a_list, y=an_array, ...)  # pass actual sequences and no source\n\n"]}],"metadata":{"id":"u8LZV_dkNFmB","colab":{"base_uri":"https://localhost:8080/","height":663},"executionInfo":{"status":"error","timestamp":1629337940614,"user_tz":300,"elapsed":1233,"user":{"displayName":"Luis Fernando Leal Hernandez","photoUrl":"","userId":"08643725771405988586"}},"outputId":"ed708b24-790f-4ab7-c968-d43b71403a4b"}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{"collapsed":true,"id":"YO2e3GzhNFmB"}}]}